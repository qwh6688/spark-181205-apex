[INFO][2021-06-12 22:45:50,888][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-12 22:45:51,265][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-12 22:45:51,267][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-12 22:45:51,268][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-12 22:45:51,269][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-12 22:45:51,270][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-12 22:45:52,186][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49770.
[INFO][2021-06-12 22:45:52,208][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-12 22:45:52,229][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-12 22:45:52,233][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-12 22:45:52,234][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-12 22:45:52,245][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-0fb94ff5-0046-4ae6-817b-1f42ea67d019
[INFO][2021-06-12 22:45:52,259][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-12 22:45:52,299][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-12 22:45:52,397][org.spark_project.jetty.util.log:186] - Logging initialized @5254ms
[INFO][2021-06-12 22:45:52,509][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-12 22:45:52,532][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7c251f90{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,533][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@51841ac6{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,533][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ba26eb0{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,534][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@435e60ff{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,534][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17d32e9b{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,534][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@66f0548d{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,535][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2e6f610d{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,535][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e86a5a7{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,536][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@10afe71a{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,536][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,536][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@212dfd39{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,537][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a2ddf26{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,537][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@65d57e4e{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,538][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6daf7d37{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,538][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@23a5818e{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,538][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4715ae33{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,539][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@9fc9f91{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,539][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1fac1d5c{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,540][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@108a46d6{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,540][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8406c2{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,548][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17690e14{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,548][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6850b758{/,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,549][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2ef072{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,549][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@704641e3{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,549][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,557][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@7661b5a{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-12 22:45:52,557][org.spark_project.jetty.server.Server:379] - Started @5415ms
[INFO][2021-06-12 22:45:52,558][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-12 22:45:52,562][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-12 22:45:52,635][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-12 22:45:52,675][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49811.
[INFO][2021-06-12 22:45:52,675][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:49811
[INFO][2021-06-12 22:45:52,677][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-12 22:45:52,680][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 22:45:52,684][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:49811 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 22:45:52,690][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 22:45:52,691][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 22:45:52,894][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6232ffdb{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,939][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-12 22:45:52,947][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2629d5dc{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,947][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@42a0501e{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,948][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6abdec0e{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,948][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b5c4f17{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:52,950][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@177c41d7{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-12 22:45:53,031][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-12 22:45:53,191][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-12 22:45:53,191][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-12 22:45:53,192][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-12 22:45:53,192][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-12 22:45:53,192][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-12 22:45:53,193][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-12 22:45:53,193][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-12 22:45:53,193][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-12 22:45:53,568][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-12 22:45:53,608][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-12 22:45:54,877][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-12 22:45:55,075][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/26420738-23ba-46e8-b90d-88c27ee765f5_resources
[INFO][2021-06-12 22:45:55,093][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/26420738-23ba-46e8-b90d-88c27ee765f5
[INFO][2021-06-12 22:45:55,103][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/26420738-23ba-46e8-b90d-88c27ee765f5
[INFO][2021-06-12 22:45:55,110][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/26420738-23ba-46e8-b90d-88c27ee765f5/_tmp_space.db
[INFO][2021-06-12 22:45:55,119][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-12 22:45:55,341][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-12 22:45:56,223][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,232][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,233][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-12 22:45:56,233][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-12 22:45:56,234][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,234][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,235][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,235][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:56,236][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:45:58,908][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-12 22:45:59,103][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-12 22:45:59,106][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 22:45:59,112][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-12 22:45:59,909][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 296.5576 ms
[INFO][2021-06-12 22:46:00,073][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.9184 ms
[INFO][2021-06-12 22:46:00,260][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-12 22:46:00,399][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-12 22:46:00,438][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-12 22:46:00,439][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:00,441][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 22:46:00,444][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 22:46:00,514][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 22:46:00,540][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:00,557][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:00,558][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:49811 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:00,561][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:00,568][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:00,572][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-12 22:46:00,677][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-12 22:46:00,699][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-12 22:46:00,753][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-12 22:46:00,766][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-12 22:46:00,767][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-12 22:46:00,767][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-12 22:46:00,767][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-12 22:46:00,767][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-12 22:46:00,832][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.0432 ms
[INFO][2021-06-12 22:46:01,464][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155603 bytes result sent to driver
[INFO][2021-06-12 22:46:01,505][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 875 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:01,507][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:01,509][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 0.910 s
[INFO][2021-06-12 22:46:01,514][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 1.114775 s
[INFO][2021-06-12 22:46:01,614][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-12 22:46:01,617][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:01,618][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-12 22:46:01,618][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:01,618][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-12 22:46:01,618][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-12 22:46:01,619][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 22:46:01,631][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:01,635][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:01,636][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:49811 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:01,637][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:01,638][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:01,638][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-12 22:46:01,640][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-12 22:46:01,641][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-12 22:46:01,656][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-12 22:46:03,624][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1848 bytes result sent to driver
[INFO][2021-06-12 22:46:03,630][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 1990 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:03,630][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:03,631][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 1.992 s
[INFO][2021-06-12 22:46:03,631][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-12 22:46:03,632][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-12 22:46:03,633][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-12 22:46:03,633][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-12 22:46:03,639][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 22:46:03,674][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:03,677][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:03,678][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:03,678][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:03,680][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 22:46:03,680][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-12 22:46:03,682][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,684][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,684][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,685][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,686][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,686][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,687][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,689][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,690][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,691][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,692][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,692][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,693][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,694][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,695][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,695][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,696][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-12 22:46:03,696][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-12 22:46:03,697][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-12 22:46:03,697][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-12 22:46:03,696][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-12 22:46:03,699][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-12 22:46:03,700][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-12 22:46:03,700][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-12 22:46:03,703][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-12 22:46:03,704][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-12 22:46:03,704][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-12 22:46:03,705][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-12 22:46:03,704][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-12 22:46:03,706][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-12 22:46:03,704][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-12 22:46:03,709][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-12 22:46:03,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,743][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,745][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,747][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,747][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,754][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,754][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 23 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 22 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 17 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 23 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 22 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
[INFO][2021-06-12 22:46:03,756][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 13 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 22:46:03,755][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
[INFO][2021-06-12 22:46:03,802][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.9731 ms
[INFO][2021-06-12 22:46:03,848][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:03,849][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2283 bytes result sent to driver
[INFO][2021-06-12 22:46:03,849][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2356 bytes result sent to driver
[INFO][2021-06-12 22:46:03,850][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2377 bytes result sent to driver
[INFO][2021-06-12 22:46:03,851][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2456 bytes result sent to driver
[INFO][2021-06-12 22:46:03,851][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:03,851][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2338 bytes result sent to driver
[INFO][2021-06-12 22:46:03,852][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:03,852][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2363 bytes result sent to driver
[INFO][2021-06-12 22:46:03,852][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,852][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,853][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-12 22:46:03,855][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,855][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,855][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,853][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2317 bytes result sent to driver
[INFO][2021-06-12 22:46:03,856][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,856][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-12 22:46:03,856][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2438 bytes result sent to driver
[INFO][2021-06-12 22:46:03,857][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 163 ms on localhost (executor driver) (1/200)
[INFO][2021-06-12 22:46:03,857][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2343 bytes result sent to driver
[INFO][2021-06-12 22:46:03,858][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,859][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,860][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,860][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 179 ms on localhost (executor driver) (2/200)
[INFO][2021-06-12 22:46:03,860][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 175 ms on localhost (executor driver) (3/200)
[INFO][2021-06-12 22:46:03,861][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,861][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,862][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-12 22:46:03,863][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,864][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-12 22:46:03,865][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,866][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,867][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-12 22:46:03,868][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,868][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2286 bytes result sent to driver
[INFO][2021-06-12 22:46:03,869][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,870][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-12 22:46:03,871][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-12 22:46:03,871][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,872][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,872][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,874][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,872][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,875][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2374 bytes result sent to driver
[INFO][2021-06-12 22:46:03,874][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,874][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-12 22:46:03,874][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-12 22:46:03,876][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,875][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-12 22:46:03,878][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2253 bytes result sent to driver
[INFO][2021-06-12 22:46:03,879][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,879][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,882][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,898][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-12 22:46:03,901][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2428 bytes result sent to driver
[INFO][2021-06-12 22:46:03,901][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2354 bytes result sent to driver
[INFO][2021-06-12 22:46:03,901][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,902][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,902][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,902][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,903][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,904][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,904][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2354 bytes result sent to driver
[INFO][2021-06-12 22:46:03,905][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,907][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,907][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-12 22:46:03,908][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,909][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,909][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-12 22:46:03,910][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,909][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2349 bytes result sent to driver
[INFO][2021-06-12 22:46:03,911][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 228 ms on localhost (executor driver) (4/200)
[INFO][2021-06-12 22:46:03,912][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 222 ms on localhost (executor driver) (5/200)
[INFO][2021-06-12 22:46:03,911][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,913][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-12 22:46:03,911][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-12 22:46:03,911][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-12 22:46:03,915][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2342 bytes result sent to driver
[INFO][2021-06-12 22:46:03,913][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,913][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 222 ms on localhost (executor driver) (6/200)
[INFO][2021-06-12 22:46:03,920][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2523 bytes result sent to driver
[INFO][2021-06-12 22:46:03,913][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 237 ms on localhost (executor driver) (7/200)
[INFO][2021-06-12 22:46:03,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 234 ms on localhost (executor driver) (8/200)
[INFO][2021-06-12 22:46:03,920][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2526 bytes result sent to driver
[INFO][2021-06-12 22:46:03,922][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 229 ms on localhost (executor driver) (9/200)
[INFO][2021-06-12 22:46:03,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,923][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:03,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,923][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:03,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 22:46:03,918][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,923][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 233 ms on localhost (executor driver) (10/200)
[INFO][2021-06-12 22:46:03,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 240 ms on localhost (executor driver) (11/200)
[INFO][2021-06-12 22:46:03,927][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,927][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 234 ms on localhost (executor driver) (12/200)
[INFO][2021-06-12 22:46:03,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-12 22:46:03,929][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 244 ms on localhost (executor driver) (13/200)
[INFO][2021-06-12 22:46:03,931][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,932][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-12 22:46:03,934][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,934][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2361 bytes result sent to driver
[INFO][2021-06-12 22:46:03,936][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,936][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-12 22:46:03,937][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-12 22:46:03,938][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,939][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2276 bytes result sent to driver
[INFO][2021-06-12 22:46:03,939][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,938][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,940][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,939][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-12 22:46:03,941][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,943][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-12 22:46:03,943][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:03,945][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,946][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,947][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2369 bytes result sent to driver
[INFO][2021-06-12 22:46:03,941][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2253 bytes result sent to driver
[INFO][2021-06-12 22:46:03,945][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,948][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,950][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,950][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,951][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,952][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2343 bytes result sent to driver
[INFO][2021-06-12 22:46:03,952][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-12 22:46:03,952][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-12 22:46:03,953][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-12 22:46:03,954][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:03,955][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:03,955][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,955][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2268 bytes result sent to driver
[INFO][2021-06-12 22:46:03,955][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-12 22:46:03,956][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,956][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-12 22:46:03,957][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,956][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,958][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,959][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,959][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,959][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,960][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:03,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,960][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,959][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-12 22:46:03,959][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-12 22:46:03,959][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:03,964][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-12 22:46:03,964][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2377 bytes result sent to driver
[INFO][2021-06-12 22:46:03,965][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,966][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,966][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,965][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,966][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,967][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-12 22:46:03,967][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,966][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,968][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,968][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-12 22:46:03,968][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2285 bytes result sent to driver
[INFO][2021-06-12 22:46:03,968][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,969][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2276 bytes result sent to driver
[INFO][2021-06-12 22:46:03,969][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,970][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,971][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2353 bytes result sent to driver
[INFO][2021-06-12 22:46:03,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,972][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,973][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-12 22:46:03,973][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-12 22:46:03,975][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2334 bytes result sent to driver
[INFO][2021-06-12 22:46:03,975][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,977][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-12 22:46:03,977][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 285 ms on localhost (executor driver) (14/200)
[INFO][2021-06-12 22:46:03,978][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 125 ms on localhost (executor driver) (15/200)
[INFO][2021-06-12 22:46:03,977][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:03,979][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,980][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-12 22:46:03,977][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:03,977][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:03,980][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,980][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2358 bytes result sent to driver
[INFO][2021-06-12 22:46:03,980][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,983][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-12 22:46:03,979][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:03,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:03,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,983][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,986][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,986][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,986][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,987][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,987][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-12 22:46:03,988][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,982][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:03,989][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-12 22:46:03,989][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,990][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,989][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-12 22:46:03,991][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:03,991][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-12 22:46:03,986][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-12 22:46:03,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,991][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:03,995][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:03,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:03,996][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:03,996][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:03,996][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 309 ms on localhost (executor driver) (16/200)
[INFO][2021-06-12 22:46:03,996][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-12 22:46:03,997][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 148 ms on localhost (executor driver) (17/200)
[INFO][2021-06-12 22:46:03,999][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 134 ms on localhost (executor driver) (18/200)
[INFO][2021-06-12 22:46:04,000][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:49811 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:03,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,001][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 138 ms on localhost (executor driver) (19/200)
[INFO][2021-06-12 22:46:04,000][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2273 bytes result sent to driver
[INFO][2021-06-12 22:46:04,002][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 135 ms on localhost (executor driver) (20/200)
[INFO][2021-06-12 22:46:04,003][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 145 ms on localhost (executor driver) (21/200)
[INFO][2021-06-12 22:46:04,004][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 132 ms on localhost (executor driver) (22/200)
[INFO][2021-06-12 22:46:04,004][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 309 ms on localhost (executor driver) (23/200)
[INFO][2021-06-12 22:46:04,005][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 130 ms on localhost (executor driver) (24/200)
[INFO][2021-06-12 22:46:04,006][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 96 ms on localhost (executor driver) (25/200)
[INFO][2021-06-12 22:46:04,006][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 100 ms on localhost (executor driver) (26/200)
[INFO][2021-06-12 22:46:04,006][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2277 bytes result sent to driver
[INFO][2021-06-12 22:46:04,006][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2266 bytes result sent to driver
[INFO][2021-06-12 22:46:04,006][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2355 bytes result sent to driver
[INFO][2021-06-12 22:46:04,006][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 136 ms on localhost (executor driver) (27/200)
[INFO][2021-06-12 22:46:04,007][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2342 bytes result sent to driver
[INFO][2021-06-12 22:46:04,007][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 124 ms on localhost (executor driver) (28/200)
[INFO][2021-06-12 22:46:04,008][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 101 ms on localhost (executor driver) (29/200)
[INFO][2021-06-12 22:46:04,008][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,009][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2359 bytes result sent to driver
[INFO][2021-06-12 22:46:04,009][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,010][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-12 22:46:04,010][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,011][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-12 22:46:04,012][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:04,012][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,012][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:49811 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,013][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,013][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,014][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-12 22:46:04,014][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,015][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,016][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-12 22:46:04,017][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-12 22:46:04,017][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,018][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,018][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,018][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,019][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-12 22:46:04,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,020][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,018][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-12 22:46:04,020][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,021][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,019][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,023][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,023][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,023][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-12 22:46:04,024][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,025][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,025][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,026][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,025][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-12 22:46:04,027][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-12 22:46:04,026][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,027][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2273 bytes result sent to driver
[INFO][2021-06-12 22:46:04,027][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,027][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,029][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-12 22:46:04,029][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,029][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,029][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,029][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,031][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,031][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-12 22:46:04,031][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,032][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,031][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,032][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,032][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-12 22:46:04,031][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2259 bytes result sent to driver
[INFO][2021-06-12 22:46:04,031][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,035][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,036][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,032][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,037][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,037][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-12 22:46:04,038][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,037][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,037][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:04,039][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,037][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,040][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,040][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,041][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,040][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-12 22:46:04,039][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-12 22:46:04,037][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,042][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,042][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-12 22:46:04,044][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,044][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,045][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,044][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2341 bytes result sent to driver
[INFO][2021-06-12 22:46:04,043][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-12 22:46:04,043][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2279 bytes result sent to driver
[INFO][2021-06-12 22:46:04,045][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,047][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,045][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-12 22:46:04,044][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 176 ms on localhost (executor driver) (30/200)
[INFO][2021-06-12 22:46:04,048][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 118 ms on localhost (executor driver) (31/200)
[INFO][2021-06-12 22:46:04,049][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 117 ms on localhost (executor driver) (32/200)
[INFO][2021-06-12 22:46:04,049][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,049][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 112 ms on localhost (executor driver) (33/200)
[INFO][2021-06-12 22:46:04,051][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 112 ms on localhost (executor driver) (34/200)
[INFO][2021-06-12 22:46:04,050][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,051][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,051][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 100 ms on localhost (executor driver) (35/200)
[INFO][2021-06-12 22:46:04,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 98 ms on localhost (executor driver) (36/200)
[INFO][2021-06-12 22:46:04,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 97 ms on localhost (executor driver) (37/200)
[INFO][2021-06-12 22:46:04,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 112 ms on localhost (executor driver) (38/200)
[INFO][2021-06-12 22:46:04,053][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 89 ms on localhost (executor driver) (39/200)
[INFO][2021-06-12 22:46:04,053][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 96 ms on localhost (executor driver) (40/200)
[INFO][2021-06-12 22:46:04,053][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 97 ms on localhost (executor driver) (41/200)
[INFO][2021-06-12 22:46:04,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 95 ms on localhost (executor driver) (42/200)
[INFO][2021-06-12 22:46:04,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 104 ms on localhost (executor driver) (43/200)
[INFO][2021-06-12 22:46:04,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 88 ms on localhost (executor driver) (44/200)
[INFO][2021-06-12 22:46:04,055][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 82 ms on localhost (executor driver) (45/200)
[INFO][2021-06-12 22:46:04,053][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2359 bytes result sent to driver
[INFO][2021-06-12 22:46:04,056][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 83 ms on localhost (executor driver) (46/200)
[INFO][2021-06-12 22:46:04,056][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,057][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,059][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2372 bytes result sent to driver
[INFO][2021-06-12 22:46:04,059][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,059][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,059][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2370 bytes result sent to driver
[INFO][2021-06-12 22:46:04,059][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 81 ms on localhost (executor driver) (47/200)
[INFO][2021-06-12 22:46:04,060][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 196 ms on localhost (executor driver) (48/200)
[INFO][2021-06-12 22:46:04,061][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 73 ms on localhost (executor driver) (49/200)
[INFO][2021-06-12 22:46:04,061][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 81 ms on localhost (executor driver) (50/200)
[INFO][2021-06-12 22:46:04,063][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,063][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2268 bytes result sent to driver
[INFO][2021-06-12 22:46:04,064][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-12 22:46:04,065][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,067][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-12 22:46:04,067][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,068][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,068][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-12 22:46:04,068][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,069][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,070][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,070][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,070][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,071][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-12 22:46:04,071][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,071][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 161 ms on localhost (executor driver) (51/200)
[INFO][2021-06-12 22:46:04,071][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-12 22:46:04,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 87 ms on localhost (executor driver) (52/200)
[INFO][2021-06-12 22:46:04,074][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,075][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,074][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,075][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 107 ms on localhost (executor driver) (53/200)
[INFO][2021-06-12 22:46:04,075][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-12 22:46:04,078][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 89 ms on localhost (executor driver) (54/200)
[INFO][2021-06-12 22:46:04,078][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2369 bytes result sent to driver
[INFO][2021-06-12 22:46:04,078][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 95 ms on localhost (executor driver) (55/200)
[INFO][2021-06-12 22:46:04,078][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 143 ms on localhost (executor driver) (56/200)
[INFO][2021-06-12 22:46:04,078][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 69 ms on localhost (executor driver) (57/200)
[INFO][2021-06-12 22:46:04,077][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,079][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,080][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-12 22:46:04,081][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,082][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,083][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,083][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,084][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-12 22:46:04,084][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2253 bytes result sent to driver
[INFO][2021-06-12 22:46:04,084][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-12 22:46:04,084][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,089][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:04,091][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,092][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,092][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,092][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-12 22:46:04,093][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-12 22:46:04,093][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,093][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,094][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-12 22:46:04,095][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,094][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 107 ms on localhost (executor driver) (58/200)
[INFO][2021-06-12 22:46:04,096][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,096][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 106 ms on localhost (executor driver) (59/200)
[INFO][2021-06-12 22:46:04,095][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,095][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,094][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,097][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,097][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,098][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,099][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2268 bytes result sent to driver
[INFO][2021-06-12 22:46:04,098][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,099][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-12 22:46:04,100][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,099][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,102][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,102][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,103][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2349 bytes result sent to driver
[INFO][2021-06-12 22:46:04,101][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,103][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-12 22:46:04,104][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-12 22:46:04,105][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2275 bytes result sent to driver
[INFO][2021-06-12 22:46:04,104][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,105][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,106][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,106][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,106][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-12 22:46:04,107][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,107][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-12 22:46:04,107][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,108][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,110][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,111][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2375 bytes result sent to driver
[INFO][2021-06-12 22:46:04,112][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2276 bytes result sent to driver
[INFO][2021-06-12 22:46:04,112][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-12 22:46:04,112][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,112][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,113][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,113][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-12 22:46:04,112][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,114][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,114][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,115][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,116][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,115][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,115][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-12 22:46:04,117][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,116][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,117][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-12 22:46:04,118][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 107 ms on localhost (executor driver) (60/200)
[INFO][2021-06-12 22:46:04,119][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 109 ms on localhost (executor driver) (61/200)
[INFO][2021-06-12 22:46:04,119][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 94 ms on localhost (executor driver) (62/200)
[INFO][2021-06-12 22:46:04,119][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,120][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,121][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,121][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,120][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 104 ms on localhost (executor driver) (63/200)
[INFO][2021-06-12 22:46:04,122][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 99 ms on localhost (executor driver) (64/200)
[INFO][2021-06-12 22:46:04,123][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 95 ms on localhost (executor driver) (65/200)
[INFO][2021-06-12 22:46:04,123][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 108 ms on localhost (executor driver) (66/200)
[INFO][2021-06-12 22:46:04,123][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 105 ms on localhost (executor driver) (67/200)
[INFO][2021-06-12 22:46:04,124][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2291 bytes result sent to driver
[INFO][2021-06-12 22:46:04,124][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 93 ms on localhost (executor driver) (68/200)
[INFO][2021-06-12 22:46:04,124][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 107 ms on localhost (executor driver) (69/200)
[INFO][2021-06-12 22:46:04,125][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 85 ms on localhost (executor driver) (70/200)
[INFO][2021-06-12 22:46:04,125][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 93 ms on localhost (executor driver) (71/200)
[INFO][2021-06-12 22:46:04,124][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2260 bytes result sent to driver
[INFO][2021-06-12 22:46:04,126][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 96 ms on localhost (executor driver) (72/200)
[INFO][2021-06-12 22:46:04,124][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,126][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,127][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 88 ms on localhost (executor driver) (73/200)
[INFO][2021-06-12 22:46:04,127][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 114 ms on localhost (executor driver) (74/200)
[INFO][2021-06-12 22:46:04,127][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-12 22:46:04,128][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 66 ms on localhost (executor driver) (75/200)
[INFO][2021-06-12 22:46:04,128][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 64 ms on localhost (executor driver) (76/200)
[INFO][2021-06-12 22:46:04,128][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,129][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 63 ms on localhost (executor driver) (77/200)
[INFO][2021-06-12 22:46:04,129][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,130][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2364 bytes result sent to driver
[INFO][2021-06-12 22:46:04,128][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,129][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 60 ms on localhost (executor driver) (78/200)
[INFO][2021-06-12 22:46:04,131][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,131][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,132][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,132][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-12 22:46:04,132][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 88 ms on localhost (executor driver) (79/200)
[INFO][2021-06-12 22:46:04,133][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2265 bytes result sent to driver
[INFO][2021-06-12 22:46:04,134][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,134][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 97 ms on localhost (executor driver) (80/200)
[INFO][2021-06-12 22:46:04,134][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-12 22:46:04,134][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 64 ms on localhost (executor driver) (81/200)
[INFO][2021-06-12 22:46:04,135][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 94 ms on localhost (executor driver) (82/200)
[INFO][2021-06-12 22:46:04,135][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 54 ms on localhost (executor driver) (83/200)
[INFO][2021-06-12 22:46:04,135][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,135][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,136][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,136][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-12 22:46:04,136][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 57 ms on localhost (executor driver) (84/200)
[INFO][2021-06-12 22:46:04,137][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 55 ms on localhost (executor driver) (85/200)
[INFO][2021-06-12 22:46:04,137][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,137][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,137][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,138][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2372 bytes result sent to driver
[INFO][2021-06-12 22:46:04,138][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-12 22:46:04,138][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,139][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,139][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,139][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-12 22:46:04,140][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,141][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,141][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-12 22:46:04,142][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,142][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,141][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 50 ms on localhost (executor driver) (86/200)
[INFO][2021-06-12 22:46:04,143][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 63 ms on localhost (executor driver) (87/200)
[INFO][2021-06-12 22:46:04,143][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,142][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,143][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,144][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,144][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,145][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,145][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-12 22:46:04,146][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,147][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,147][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2285 bytes result sent to driver
[INFO][2021-06-12 22:46:04,147][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-12 22:46:04,148][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-12 22:46:04,149][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,150][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,150][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-12 22:46:04,150][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,150][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,151][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,151][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,151][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,151][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-12 22:46:04,152][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2371 bytes result sent to driver
[INFO][2021-06-12 22:46:04,151][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,153][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,153][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,152][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-12 22:46:04,151][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,155][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-12 22:46:04,153][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2335 bytes result sent to driver
[INFO][2021-06-12 22:46:04,153][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,155][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,157][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,157][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,159][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,159][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,160][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,160][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,157][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,161][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2263 bytes result sent to driver
[INFO][2021-06-12 22:46:04,162][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-12 22:46:04,162][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,162][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-12 22:46:04,157][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-12 22:46:04,162][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2372 bytes result sent to driver
[INFO][2021-06-12 22:46:04,161][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,161][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,164][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,165][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,165][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,165][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,165][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,165][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,165][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,166][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,166][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-12 22:46:04,165][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-12 22:46:04,167][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2276 bytes result sent to driver
[INFO][2021-06-12 22:46:04,167][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,167][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,168][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-12 22:46:04,169][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2358 bytes result sent to driver
[INFO][2021-06-12 22:46:04,170][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,171][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,168][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2375 bytes result sent to driver
[INFO][2021-06-12 22:46:04,171][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,171][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,171][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-12 22:46:04,169][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,173][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:04,173][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-12 22:46:04,173][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,177][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:04,177][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,177][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,172][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2253 bytes result sent to driver
[INFO][2021-06-12 22:46:04,177][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,173][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,179][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-12 22:46:04,179][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,180][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,181][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,179][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,181][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,181][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,182][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,182][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-12 22:46:04,181][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-12 22:46:04,181][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-12 22:46:04,180][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,182][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2287 bytes result sent to driver
[INFO][2021-06-12 22:46:04,184][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,185][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,182][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,184][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,187][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,187][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,187][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,187][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2265 bytes result sent to driver
[INFO][2021-06-12 22:46:04,188][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,188][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,191][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,191][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-12 22:46:04,191][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,188][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-12 22:46:04,187][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-12 22:46:04,192][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,192][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-12 22:46:04,191][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2362 bytes result sent to driver
[INFO][2021-06-12 22:46:04,190][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2267 bytes result sent to driver
[INFO][2021-06-12 22:46:04,195][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-12 22:46:04,190][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,194][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,194][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,196][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,196][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,196][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,197][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,198][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,198][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,195][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,197][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-12 22:46:04,197][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,200][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,200][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,201][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,201][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2367 bytes result sent to driver
[INFO][2021-06-12 22:46:04,201][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,202][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,202][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-12 22:46:04,203][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2277 bytes result sent to driver
[INFO][2021-06-12 22:46:04,204][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,201][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,205][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,203][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-12 22:46:04,206][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,206][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,207][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-12 22:46:04,205][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-12 22:46:04,207][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,207][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,207][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,207][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,212][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,212][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,211][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-12 22:46:04,211][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,213][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,210][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,213][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,215][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,213][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2447 bytes result sent to driver
[INFO][2021-06-12 22:46:04,212][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-12 22:46:04,212][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,215][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 109 ms on localhost (executor driver) (88/200)
[INFO][2021-06-12 22:46:04,216][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 105 ms on localhost (executor driver) (89/200)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,218][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,218][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,215][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2371 bytes result sent to driver
[INFO][2021-06-12 22:46:04,214][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:04,218][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,219][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,216][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 124 ms on localhost (executor driver) (90/200)
[INFO][2021-06-12 22:46:04,215][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,220][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 117 ms on localhost (executor driver) (91/200)
[INFO][2021-06-12 22:46:04,220][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 105 ms on localhost (executor driver) (92/200)
[INFO][2021-06-12 22:46:04,221][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 120 ms on localhost (executor driver) (93/200)
[INFO][2021-06-12 22:46:04,220][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,221][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,222][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 109 ms on localhost (executor driver) (94/200)
[INFO][2021-06-12 22:46:04,222][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,223][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2359 bytes result sent to driver
[INFO][2021-06-12 22:46:04,223][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 126 ms on localhost (executor driver) (95/200)
[INFO][2021-06-12 22:46:04,223][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 92 ms on localhost (executor driver) (96/200)
[INFO][2021-06-12 22:46:04,224][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 91 ms on localhost (executor driver) (97/200)
[INFO][2021-06-12 22:46:04,225][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 90 ms on localhost (executor driver) (98/200)
[INFO][2021-06-12 22:46:04,225][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2447 bytes result sent to driver
[INFO][2021-06-12 22:46:04,225][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 86 ms on localhost (executor driver) (99/200)
[INFO][2021-06-12 22:46:04,227][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,228][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-12 22:46:04,228][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,229][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,229][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-12 22:46:04,229][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2257 bytes result sent to driver
[INFO][2021-06-12 22:46:04,230][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,230][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2323 bytes result sent to driver
[INFO][2021-06-12 22:46:04,230][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-12 22:46:04,231][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,231][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,231][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2287 bytes result sent to driver
[INFO][2021-06-12 22:46:04,231][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-12 22:46:04,231][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 105 ms on localhost (executor driver) (100/200)
[INFO][2021-06-12 22:46:04,231][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,231][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,232][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,232][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 95 ms on localhost (executor driver) (101/200)
[INFO][2021-06-12 22:46:04,233][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,233][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,233][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-12 22:46:04,233][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,234][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,234][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,235][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,235][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,236][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-12 22:46:04,236][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,237][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-12 22:46:04,237][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,238][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-12 22:46:04,238][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,239][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,234][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-12 22:46:04,238][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,239][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,239][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,238][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,241][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,241][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,241][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,238][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,236][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,242][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-12 22:46:04,242][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,242][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2357 bytes result sent to driver
[INFO][2021-06-12 22:46:04,244][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,242][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,245][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,241][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-12 22:46:04,241][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2363 bytes result sent to driver
[INFO][2021-06-12 22:46:04,245][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-12 22:46:04,245][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,245][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,245][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-12 22:46:04,243][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 22:46:04,246][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,246][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,247][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-12 22:46:04,247][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2254 bytes result sent to driver
[INFO][2021-06-12 22:46:04,248][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,248][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,248][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,249][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,249][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-12 22:46:04,250][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,247][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,250][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,250][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,250][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,250][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,251][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,251][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,252][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,248][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,252][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-12 22:46:04,252][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,253][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2358 bytes result sent to driver
[INFO][2021-06-12 22:46:04,254][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,254][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,255][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,255][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-12 22:46:04,255][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,255][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-12 22:46:04,258][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-12 22:46:04,258][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,259][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,260][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,260][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,259][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,261][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,261][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,261][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,263][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,265][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-12 22:46:04,265][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,265][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 164 ms on localhost (executor driver) (102/200)
[INFO][2021-06-12 22:46:04,266][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 117 ms on localhost (executor driver) (103/200)
[INFO][2021-06-12 22:46:04,266][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-12 22:46:04,267][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,267][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,268][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,268][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,270][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,266][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2444 bytes result sent to driver
[INFO][2021-06-12 22:46:04,270][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 124 ms on localhost (executor driver) (104/200)
[INFO][2021-06-12 22:46:04,270][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,270][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2352 bytes result sent to driver
[INFO][2021-06-12 22:46:04,267][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2268 bytes result sent to driver
[INFO][2021-06-12 22:46:04,271][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 126 ms on localhost (executor driver) (105/200)
[INFO][2021-06-12 22:46:04,271][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 164 ms on localhost (executor driver) (106/200)
[INFO][2021-06-12 22:46:04,271][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,272][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,271][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 120 ms on localhost (executor driver) (107/200)
[INFO][2021-06-12 22:46:04,272][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2285 bytes result sent to driver
[INFO][2021-06-12 22:46:04,273][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,273][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-12 22:46:04,274][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,274][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,275][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,277][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,278][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,275][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-12 22:46:04,279][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,280][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,280][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,281][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-12 22:46:04,281][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-12 22:46:04,277][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2371 bytes result sent to driver
[INFO][2021-06-12 22:46:04,276][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-12 22:46:04,275][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,281][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,281][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-12 22:46:04,283][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-12 22:46:04,281][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,284][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,284][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,279][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-12 22:46:04,285][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,285][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,284][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,284][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,283][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,286][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,287][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-12 22:46:04,287][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,288][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,288][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,282][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 22:46:04,289][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-12 22:46:04,289][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,289][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,288][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,292][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,293][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-12 22:46:04,293][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,294][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,294][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,294][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2371 bytes result sent to driver
[INFO][2021-06-12 22:46:04,295][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-12 22:46:04,296][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,286][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,297][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-12 22:46:04,297][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-12 22:46:04,298][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,299][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2347 bytes result sent to driver
[INFO][2021-06-12 22:46:04,286][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,300][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,296][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,300][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:04,294][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,301][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,302][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,291][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-12 22:46:04,303][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,300][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,303][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,303][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-12 22:46:04,303][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-12 22:46:04,304][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,305][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,306][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-12 22:46:04,306][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,307][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-12 22:46:04,307][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,306][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-12 22:46:04,309][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,309][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,308][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-12 22:46:04,307][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,310][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,312][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,312][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,312][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,310][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-12 22:46:04,310][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,310][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,310][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,314][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 22:46:04,313][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,315][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,315][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,316][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,313][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,313][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2260 bytes result sent to driver
[INFO][2021-06-12 22:46:04,313][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2373 bytes result sent to driver
[INFO][2021-06-12 22:46:04,318][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-12 22:46:04,319][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2361 bytes result sent to driver
[INFO][2021-06-12 22:46:04,320][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2361 bytes result sent to driver
[INFO][2021-06-12 22:46:04,318][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,315][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2287 bytes result sent to driver
[INFO][2021-06-12 22:46:04,322][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-12 22:46:04,322][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,323][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2368 bytes result sent to driver
[INFO][2021-06-12 22:46:04,323][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,320][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2267 bytes result sent to driver
[INFO][2021-06-12 22:46:04,323][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2370 bytes result sent to driver
[INFO][2021-06-12 22:46:04,324][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-12 22:46:04,324][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,325][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-12 22:46:04,323][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-12 22:46:04,322][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,325][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2268 bytes result sent to driver
[INFO][2021-06-12 22:46:04,326][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 181 ms on localhost (executor driver) (108/200)
[INFO][2021-06-12 22:46:04,324][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,327][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 189 ms on localhost (executor driver) (109/200)
[INFO][2021-06-12 22:46:04,326][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 22:46:04,327][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 170 ms on localhost (executor driver) (110/200)
[INFO][2021-06-12 22:46:04,327][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 166 ms on localhost (executor driver) (111/200)
[INFO][2021-06-12 22:46:04,327][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 22:46:04,328][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,328][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,327][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,328][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,328][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,328][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 165 ms on localhost (executor driver) (112/200)
[INFO][2021-06-12 22:46:04,329][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,329][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 179 ms on localhost (executor driver) (113/200)
[INFO][2021-06-12 22:46:04,329][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 181 ms on localhost (executor driver) (114/200)
[INFO][2021-06-12 22:46:04,330][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 162 ms on localhost (executor driver) (115/200)
[INFO][2021-06-12 22:46:04,330][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 165 ms on localhost (executor driver) (116/200)
[INFO][2021-06-12 22:46:04,330][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 151 ms on localhost (executor driver) (117/200)
[INFO][2021-06-12 22:46:04,331][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 177 ms on localhost (executor driver) (118/200)
[INFO][2021-06-12 22:46:04,333][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,335][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,335][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-12 22:46:04,335][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,336][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,336][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-12 22:46:04,338][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,339][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,336][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,340][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2331 bytes result sent to driver
[INFO][2021-06-12 22:46:04,341][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,342][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 176 ms on localhost (executor driver) (119/200)
[INFO][2021-06-12 22:46:04,343][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 162 ms on localhost (executor driver) (120/200)
[INFO][2021-06-12 22:46:04,343][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 172 ms on localhost (executor driver) (121/200)
[INFO][2021-06-12 22:46:04,344][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2360 bytes result sent to driver
[INFO][2021-06-12 22:46:04,339][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,344][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 152 ms on localhost (executor driver) (122/200)
[INFO][2021-06-12 22:46:04,344][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-12 22:46:04,344][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 172 ms on localhost (executor driver) (123/200)
[INFO][2021-06-12 22:46:04,345][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 159 ms on localhost (executor driver) (124/200)
[INFO][2021-06-12 22:46:04,344][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-12 22:46:04,344][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,345][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 165 ms on localhost (executor driver) (125/200)
[INFO][2021-06-12 22:46:04,346][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,346][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,347][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 159 ms on localhost (executor driver) (126/200)
[INFO][2021-06-12 22:46:04,348][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 157 ms on localhost (executor driver) (127/200)
[INFO][2021-06-12 22:46:04,348][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 143 ms on localhost (executor driver) (128/200)
[INFO][2021-06-12 22:46:04,348][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,349][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,349][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,348][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,350][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,350][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-12 22:46:04,352][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,352][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-12 22:46:04,353][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2280 bytes result sent to driver
[INFO][2021-06-12 22:46:04,353][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,354][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-12 22:46:04,355][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,356][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,356][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,356][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,356][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,357][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-12 22:46:04,356][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2288 bytes result sent to driver
[INFO][2021-06-12 22:46:04,357][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,358][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,357][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,358][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-12 22:46:04,360][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,361][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-12 22:46:04,360][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,362][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,362][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,364][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,362][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-12 22:46:04,362][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2433 bytes result sent to driver
[INFO][2021-06-12 22:46:04,365][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2355 bytes result sent to driver
[INFO][2021-06-12 22:46:04,361][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,366][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2447 bytes result sent to driver
[INFO][2021-06-12 22:46:04,366][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,366][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-12 22:46:04,366][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,368][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,368][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,370][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,367][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-12 22:46:04,369][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,370][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-12 22:46:04,371][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,371][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,371][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2351 bytes result sent to driver
[INFO][2021-06-12 22:46:04,372][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,372][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 22:46:04,373][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,374][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,375][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,377][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,377][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,378][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2283 bytes result sent to driver
[INFO][2021-06-12 22:46:04,378][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-12 22:46:04,378][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,378][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-12 22:46:04,380][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-12 22:46:04,378][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2287 bytes result sent to driver
[INFO][2021-06-12 22:46:04,381][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,382][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,381][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,382][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,380][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-12 22:46:04,383][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2259 bytes result sent to driver
[INFO][2021-06-12 22:46:04,383][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 201 ms on localhost (executor driver) (129/200)
[INFO][2021-06-12 22:46:04,384][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 175 ms on localhost (executor driver) (130/200)
[INFO][2021-06-12 22:46:04,384][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:04,384][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 169 ms on localhost (executor driver) (131/200)
[INFO][2021-06-12 22:46:04,384][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 172 ms on localhost (executor driver) (132/200)
[INFO][2021-06-12 22:46:04,385][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 189 ms on localhost (executor driver) (133/200)
[INFO][2021-06-12 22:46:04,385][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,383][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,385][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 22:46:04,385][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-12 22:46:04,385][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 184 ms on localhost (executor driver) (134/200)
[INFO][2021-06-12 22:46:04,386][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 158 ms on localhost (executor driver) (135/200)
[INFO][2021-06-12 22:46:04,385][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2284 bytes result sent to driver
[INFO][2021-06-12 22:46:04,386][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 160 ms on localhost (executor driver) (136/200)
[INFO][2021-06-12 22:46:04,387][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 22:46:04,387][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,388][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 22:46:04,388][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 182 ms on localhost (executor driver) (137/200)
[INFO][2021-06-12 22:46:04,388][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 188 ms on localhost (executor driver) (138/200)
[INFO][2021-06-12 22:46:04,389][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 153 ms on localhost (executor driver) (139/200)
[INFO][2021-06-12 22:46:04,389][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2282 bytes result sent to driver
[INFO][2021-06-12 22:46:04,389][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 159 ms on localhost (executor driver) (140/200)
[INFO][2021-06-12 22:46:04,390][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 161 ms on localhost (executor driver) (141/200)
[INFO][2021-06-12 22:46:04,390][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 196 ms on localhost (executor driver) (142/200)
[INFO][2021-06-12 22:46:04,391][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 158 ms on localhost (executor driver) (143/200)
[INFO][2021-06-12 22:46:04,392][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2278 bytes result sent to driver
[INFO][2021-06-12 22:46:04,392][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 158 ms on localhost (executor driver) (144/200)
[INFO][2021-06-12 22:46:04,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 152 ms on localhost (executor driver) (145/200)
[INFO][2021-06-12 22:46:04,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 156 ms on localhost (executor driver) (146/200)
[INFO][2021-06-12 22:46:04,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 161 ms on localhost (executor driver) (147/200)
[INFO][2021-06-12 22:46:04,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 146 ms on localhost (executor driver) (148/200)
[INFO][2021-06-12 22:46:04,394][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2367 bytes result sent to driver
[INFO][2021-06-12 22:46:04,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 152 ms on localhost (executor driver) (149/200)
[INFO][2021-06-12 22:46:04,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 141 ms on localhost (executor driver) (150/200)
[INFO][2021-06-12 22:46:04,395][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 143 ms on localhost (executor driver) (151/200)
[INFO][2021-06-12 22:46:04,395][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 141 ms on localhost (executor driver) (152/200)
[INFO][2021-06-12 22:46:04,395][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 150 ms on localhost (executor driver) (153/200)
[INFO][2021-06-12 22:46:04,395][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 146 ms on localhost (executor driver) (154/200)
[INFO][2021-06-12 22:46:04,396][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 152 ms on localhost (executor driver) (155/200)
[INFO][2021-06-12 22:46:04,396][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 158 ms on localhost (executor driver) (156/200)
[INFO][2021-06-12 22:46:04,397][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 132 ms on localhost (executor driver) (157/200)
[INFO][2021-06-12 22:46:04,397][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 141 ms on localhost (executor driver) (158/200)
[INFO][2021-06-12 22:46:04,398][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 123 ms on localhost (executor driver) (159/200)
[INFO][2021-06-12 22:46:04,398][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 123 ms on localhost (executor driver) (160/200)
[INFO][2021-06-12 22:46:04,398][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 116 ms on localhost (executor driver) (161/200)
[INFO][2021-06-12 22:46:04,399][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 120 ms on localhost (executor driver) (162/200)
[INFO][2021-06-12 22:46:04,399][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 127 ms on localhost (executor driver) (163/200)
[INFO][2021-06-12 22:46:04,400][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 127 ms on localhost (executor driver) (164/200)
[INFO][2021-06-12 22:46:04,400][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 119 ms on localhost (executor driver) (165/200)
[INFO][2021-06-12 22:46:04,400][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 113 ms on localhost (executor driver) (166/200)
[INFO][2021-06-12 22:46:04,401][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 125 ms on localhost (executor driver) (167/200)
[INFO][2021-06-12 22:46:04,401][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 113 ms on localhost (executor driver) (168/200)
[INFO][2021-06-12 22:46:04,401][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 123 ms on localhost (executor driver) (169/200)
[INFO][2021-06-12 22:46:04,402][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 108 ms on localhost (executor driver) (170/200)
[INFO][2021-06-12 22:46:04,402][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 108 ms on localhost (executor driver) (171/200)
[INFO][2021-06-12 22:46:04,402][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 110 ms on localhost (executor driver) (172/200)
[INFO][2021-06-12 22:46:04,403][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 96 ms on localhost (executor driver) (173/200)
[INFO][2021-06-12 22:46:04,403][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 99 ms on localhost (executor driver) (174/200)
[INFO][2021-06-12 22:46:04,403][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 101 ms on localhost (executor driver) (175/200)
[INFO][2021-06-12 22:46:04,404][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 96 ms on localhost (executor driver) (176/200)
[INFO][2021-06-12 22:46:04,404][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 98 ms on localhost (executor driver) (177/200)
[INFO][2021-06-12 22:46:04,405][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 95 ms on localhost (executor driver) (178/200)
[INFO][2021-06-12 22:46:04,405][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 88 ms on localhost (executor driver) (179/200)
[INFO][2021-06-12 22:46:04,406][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 84 ms on localhost (executor driver) (180/200)
[INFO][2021-06-12 22:46:04,407][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 83 ms on localhost (executor driver) (181/200)
[INFO][2021-06-12 22:46:04,407][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 83 ms on localhost (executor driver) (182/200)
[INFO][2021-06-12 22:46:04,408][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 75 ms on localhost (executor driver) (183/200)
[INFO][2021-06-12 22:46:04,408][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 73 ms on localhost (executor driver) (184/200)
[INFO][2021-06-12 22:46:04,408][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 72 ms on localhost (executor driver) (185/200)
[INFO][2021-06-12 22:46:04,408][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 57 ms on localhost (executor driver) (186/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 69 ms on localhost (executor driver) (187/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 60 ms on localhost (executor driver) (188/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 52 ms on localhost (executor driver) (189/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 56 ms on localhost (executor driver) (190/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 55 ms on localhost (executor driver) (191/200)
[INFO][2021-06-12 22:46:04,409][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 51 ms on localhost (executor driver) (192/200)
[INFO][2021-06-12 22:46:04,410][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 43 ms on localhost (executor driver) (193/200)
[INFO][2021-06-12 22:46:04,410][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 54 ms on localhost (executor driver) (194/200)
[INFO][2021-06-12 22:46:04,410][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 44 ms on localhost (executor driver) (195/200)
[INFO][2021-06-12 22:46:04,410][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 49 ms on localhost (executor driver) (196/200)
[INFO][2021-06-12 22:46:04,410][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 34 ms on localhost (executor driver) (197/200)
[INFO][2021-06-12 22:46:04,411][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 33 ms on localhost (executor driver) (198/200)
[INFO][2021-06-12 22:46:04,411][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 36 ms on localhost (executor driver) (199/200)
[INFO][2021-06-12 22:46:04,411][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 32 ms on localhost (executor driver) (200/200)
[INFO][2021-06-12 22:46:04,411][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:04,411][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.730 s
[INFO][2021-06-12 22:46:04,412][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 2.797779 s
[INFO][2021-06-12 22:46:04,446][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.9354 ms
[INFO][2021-06-12 22:46:04,467][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,473][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,475][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,476][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-12 22:46:04,477][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,481][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,482][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,482][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-12 22:46:04,483][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-12 22:46:04,485][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-12 22:46:04,520][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-12 22:46:04,526][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-12 22:46:04,527][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,528][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:354
[INFO][2021-06-12 22:46:04,538][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-12 22:46:04,544][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-12 22:46:04,545][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,546][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:323
[INFO][2021-06-12 22:46:04,721][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 22:46:04,728][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-12 22:46:04,728][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 22:46:04,875][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.3978 ms
[INFO][2021-06-12 22:46:04,886][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-12 22:46:04,887][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-12 22:46:04,887][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 22:46:04,887][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 22:46:04,888][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 22:46:04,888][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-12 22:46:04,900][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,903][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:04,904][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:49811 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:04,904][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:04,905][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 22:46:04,905][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-12 22:46:04,906][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 22:46:04,907][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-12 22:46:04,953][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 22:46:04,956][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2281 bytes result sent to driver
[INFO][2021-06-12 22:46:04,956][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 51 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:04,956][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:04,956][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.051 s
[INFO][2021-06-12 22:46:04,957][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.070341 s
[INFO][2021-06-12 22:46:05,000][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 34.6678 ms
[INFO][2021-06-12 22:46:05,014][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-12 22:46:05,068][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 22:46:05,072][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-12 22:46:05,072][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 22:46:05,151][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 26.1078 ms
[INFO][2021-06-12 22:46:05,167][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-12 22:46:05,168][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-12 22:46:05,168][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 22:46:05,168][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 22:46:05,168][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 22:46:05,169][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-12 22:46:05,170][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,182][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,183][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:49811 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:05,183][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:05,184][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 22:46:05,184][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-12 22:46:05,186][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 22:46:05,187][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-12 22:46:05,196][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4926
[INFO][2021-06-12 22:46:05,196][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.52.10:49811 in memory (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:05,197][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4927
[INFO][2021-06-12 22:46:05,224][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 22:46:05,227][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2377 bytes result sent to driver
[INFO][2021-06-12 22:46:05,228][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 44 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:05,228][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:05,228][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.044 s
[INFO][2021-06-12 22:46:05,229][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.061271 s
[INFO][2021-06-12 22:46:05,233][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-12 22:46:05,267][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:46:05,268][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,268][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,269][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,269][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 22:46:05,269][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 22:46:05,270][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 22:46:05,270][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 22:46:05,270][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 22:46:05,270][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,270][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,271][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,271][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,271][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,271][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,272][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,272][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,272][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-12 22:46:05,273][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,273][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-12 22:46:05,273][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,273][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-12 22:46:05,274][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,275][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,275][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,275][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,275][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,289][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.0754 ms
[INFO][2021-06-12 22:46:05,291][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-12 22:46:05,302][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk from sparktxggl
[INFO][2021-06-12 22:46:05,320][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 22:46:05,323][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:137] -  
[INFO][2021-06-12 22:46:05,323][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 22:46:05,384][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.6433 ms
[INFO][2021-06-12 22:46:05,389][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:138
[INFO][2021-06-12 22:46:05,389][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at DemoMoveFinfo.java:138) with 1 output partitions
[INFO][2021-06-12 22:46:05,390][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 22:46:05,390][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 22:46:05,390][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 22:46:05,390][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138), which has no missing parents
[INFO][2021-06-12 22:46:05,391][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 20.0 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,394][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.4 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,395][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.52.10:49811 (size: 8.4 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:05,395][org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:05,395][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 22:46:05,395][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
[INFO][2021-06-12 22:46:05,396][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 22:46:05,397][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 204)
[INFO][2021-06-12 22:46:05,433][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 22:46:05,435][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 204). 2366 bytes result sent to driver
[INFO][2021-06-12 22:46:05,435][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 204) in 39 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:05,435][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:05,436][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (show at DemoMoveFinfo.java:138) finished in 0.039 s
[INFO][2021-06-12 22:46:05,436][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at DemoMoveFinfo.java:138, took 0.047310 s
[INFO][2021-06-12 22:46:05,459][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.2162 ms
[INFO][2021-06-12 22:46:05,462][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-12 22:46:05,470][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_txggl select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,JYS,SSBK from sparktxggl
[INFO][2021-06-12 22:46:05,495][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 22:46:05,495][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,495][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,495][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,495][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,496][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,497][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,497][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,497][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,497][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 22:46:05,497][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,498][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 22:46:05,499][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,499][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 22:46:05,704][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 22:46:05,779][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 22:46:05,780][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 22:46:05,807][org.apache.spark.SparkContext:54] - Starting job: sql at DemoMoveFinfo.java:145
[INFO][2021-06-12 22:46:05,808][org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (sql at DemoMoveFinfo.java:145) with 1 output partitions
[INFO][2021-06-12 22:46:05,808][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 22:46:05,808][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 22:46:05,808][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 22:46:05,808][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[26] at sql at DemoMoveFinfo.java:145), which has no missing parents
[INFO][2021-06-12 22:46:05,817][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 78.2 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,819][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 29.3 KB, free 3.8 GB)
[INFO][2021-06-12 22:46:05,820][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.52.10:49811 (size: 29.3 KB, free: 3.8 GB)
[INFO][2021-06-12 22:46:05,820][org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 22:46:05,820][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 22:46:05,820][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
[INFO][2021-06-12 22:46:05,821][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5816 bytes)
[INFO][2021-06-12 22:46:05,822][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 205)
[INFO][2021-06-12 22:46:05,827][org.apache.hadoop.conf.Configuration.deprecation:840] - mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
[INFO][2021-06-12 22:46:05,831][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-12 22:46:05,831][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
[INFO][2021-06-12 22:46:05,832][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-12 22:46:05,863][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 22:46:05,864][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 22:46:05,866][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 22:46:05,868][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 22:46:05,872][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-12 22:46:05,872][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-12 22:46:05,872][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-12 22:46:05,872][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-12 22:46:05,873][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-12 22:46:05,873][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-12 22:46:05,873][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-12 22:46:05,893][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "comment" : "ID",
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "gpdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "gpjc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "sgdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "fxzs",
    "type" : "decimal(16,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(16,2)"
    }
  }, {
    "name" : "wsfx",
    "type" : "decimal(16,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(16,2)"
    }
  }, {
    "name" : "dgsgsz",
    "type" : "decimal(12,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "??????",
      "HIVE_TYPE_STRING" : "decimal(12,2)"
    }
  }, {
    "name" : "sgsx",
    "type" : "decimal(12,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,2)"
    }
  }, {
    "name" : "sgzjsx",
    "type" : "decimal(9,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "??????",
      "HIVE_TYPE_STRING" : "decimal(9,4)"
    }
  }, {
    "name" : "fxj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "zxj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "srspj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "sgrq",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "zqgbr",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "ssrq",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "fxsyl",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "hysyl",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "zql",
    "type" : "decimal(7,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(7,4)"
    }
  }, {
    "name" : "mzyqy",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "djzj",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(7,2)"
    }
  }, {
    "name" : "xjljbjbs",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "psdxbjjs",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????????",
      "HIVE_TYPE_STRING" : "decimal(6,0)"
    }
  }, {
    "name" : "dxsy",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "lxyzbsl",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zzf",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "jys",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "ssbk",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary gpdm (UTF8);
  optional binary gpjc (UTF8);
  optional binary sgdm (UTF8);
  optional fixed_len_byte_array(7) fxzs (DECIMAL(16,2));
  optional fixed_len_byte_array(7) wsfx (DECIMAL(16,2));
  optional fixed_len_byte_array(6) dgsgsz (DECIMAL(12,2));
  optional fixed_len_byte_array(6) sgsx (DECIMAL(12,2));
  optional fixed_len_byte_array(4) sgzjsx (DECIMAL(9,4));
  optional fixed_len_byte_array(4) fxj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) zxj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) srspj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) sgrq (DECIMAL(8,0));
  optional fixed_len_byte_array(4) zqgbr (DECIMAL(8,0));
  optional fixed_len_byte_array(4) ssrq (DECIMAL(8,0));
  optional fixed_len_byte_array(4) fxsyl (DECIMAL(9,2));
  optional fixed_len_byte_array(4) hysyl (DECIMAL(9,2));
  optional fixed_len_byte_array(4) zql (DECIMAL(7,4));
  optional fixed_len_byte_array(4) mzyqy (DECIMAL(9,2));
  optional fixed_len_byte_array(4) djzj (DECIMAL(7,2));
  optional fixed_len_byte_array(4) xjljbjbs (DECIMAL(9,2));
  optional fixed_len_byte_array(3) psdxbjjs (DECIMAL(6,0));
  optional fixed_len_byte_array(4) dxsy (DECIMAL(9,2));
  optional binary lxyzbsl (UTF8);
  optional fixed_len_byte_array(4) zzf (DECIMAL(9,2));
  optional binary jys (UTF8);
  optional binary ssbk (UTF8);
}

       
[INFO][2021-06-12 22:46:05,930][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-12 22:46:06,188][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 22:46:06,188][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 578,143
[INFO][2021-06-12 22:46:06,271][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 11,077B for [id] INT32: 2,759 values, 11,043B raw, 11,039B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,271][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,945B for [gpdm] BINARY: 2,759 values, 27,597B raw, 10,903B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,272][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 26,546B for [gpjc] BINARY: 2,759 values, 42,578B raw, 26,494B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,272][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,910B for [sgdm] BINARY: 2,759 values, 27,571B raw, 10,874B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,273][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,873B for [fxzs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 19,320B raw, 9,829B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,273][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,730B for [wsfx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 19,320B raw, 10,686B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,274][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,111B for [dgsgsz] FIXED_LEN_BYTE_ARRAY: 2,759 values, 16,561B raw, 6,070B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,274][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,327B for [sgsx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 16,561B raw, 6,286B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,274][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,462B for [sgzjsx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 10,424B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,275][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 8,956B for [fxj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 8,918B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,275][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,478B for [zxj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,440B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,275][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,798B for [srspj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,760B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,275][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,429B for [sgrq] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,392B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,407B for [zqgbr] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,370B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,516B for [ssrq] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,479B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,926B for [fxsyl] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,889B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,307B for [hysyl] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,270B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,132B for [zql] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,094B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,276][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,690B for [mzyqy] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 10,652B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,277][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 4,842B for [djzj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 4,805B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,277][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,055B for [xjljbjbs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,017B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,277][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 5,429B for [psdxbjjs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 8,284B raw, 5,394B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,277][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 4,084B for [dxsy] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 4,047B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,279][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 1,243B for [lxyzbsl] BINARY: 2,759 values, 1,216B raw, 1,214B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 28 entries, 157B raw, 28B comp}
[INFO][2021-06-12 22:46:06,279][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,786B for [zzf] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,749B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 22:46:06,280][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 727B for [jys] BINARY: 2,759 values, 695B raw, 697B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 3 entries, 15B raw, 3B comp}
[INFO][2021-06-12 22:46:06,280][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 1,081B for [ssbk] BINARY: 2,759 values, 1,045B raw, 1,050B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 7 entries, 44B raw, 7B comp}
[INFO][2021-06-12 22:46:06,515][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210612224605_0006_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/info_txggl/_temporary/0/task_20210612224605_0006_m_000000
[INFO][2021-06-12 22:46:06,516][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210612224605_0006_m_000000_0: Committed
[INFO][2021-06-12 22:46:06,519][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 205). 1514 bytes result sent to driver
[INFO][2021-06-12 22:46:06,520][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 205) in 699 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 22:46:06,521][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 22:46:06,521][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (sql at DemoMoveFinfo.java:145) finished in 0.701 s
[INFO][2021-06-12 22:46:06,521][org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: sql at DemoMoveFinfo.java:145, took 0.714027 s
[INFO][2021-06-12 22:46:06,542][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[WARN][2021-06-12 23:04:33,254][org.apache.spark.HeartbeatReceiver:66] - Removing executor driver with no recent heartbeats: 1120330 ms exceeds timeout 120000 ms
[ERROR][2021-06-12 23:04:39,361][org.apache.spark.scheduler.TaskSchedulerImpl:70] - Lost executor driver on localhost: Executor heartbeat timed out after 1120330 ms
[INFO][2021-06-12 23:04:43,060][org.apache.spark.scheduler.DAGScheduler:54] - Executor lost: driver (epoch 1)
[INFO][2021-06-12 23:06:17,569][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Trying to remove executor driver from BlockManagerMaster.
[WARN][2021-06-12 23:06:17,571][org.apache.spark.SparkContext:66] - Killing executors is only supported in coarse-grained mode
[INFO][2021-06-12 23:06:17,572][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Removing block manager BlockManagerId(driver, 192.168.52.10, 49811, None)
[WARN][2021-06-12 23:06:17,573][org.apache.spark.rpc.netty.NettyRpcEnv:66] - Ignored message: HeartbeatResponse(true)
[WARN][2021-06-12 23:06:17,573][org.apache.spark.rpc.netty.NettyRpcEndpointRef:87] - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@31535240,BlockManagerId(driver, 192.168.52.10, 49811, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:689)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:718)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:718)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:718)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:718)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[INFO][2021-06-12 23:06:17,573][org.apache.spark.storage.BlockManagerMaster:54] - Removed driver successfully in removeExecutor
[INFO][2021-06-12 23:06:17,577][org.apache.spark.scheduler.DAGScheduler:54] - Shuffle files lost for executor: driver (epoch 1)
[INFO][2021-06-12 23:06:17,579][org.apache.spark.scheduler.DAGScheduler:54] - Host added was in lost list earlier: localhost
[INFO][2021-06-12 23:06:17,648][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:06:17,652][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-12 23:06:17,652][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:06:17,689][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.7402 ms
[INFO][2021-06-12 23:06:17,696][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-12 23:06:17,697][org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-12 23:06:17,697][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:06:17,697][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:06:17,697][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:06:17,697][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[31] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-12 23:06:17,700][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 10.7 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:17,703][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:17,704][org.apache.spark.storage.BlockManager:54] - Got told to re-register updating block broadcast_12_piece0
[INFO][2021-06-12 23:06:17,706][org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:06:17,707][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:06:17,707][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
[INFO][2021-06-12 23:06:17,707][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:17,707][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:17,708][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:49811 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:17,708][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:06:17,708][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:17,709][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 206)
[INFO][2021-06-12 23:06:17,710][org.apache.spark.storage.BlockManager:54] - Reporting 20 blocks to the master.
[INFO][2021-06-12 23:06:17,712][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.52.10:49811 (size: 8.4 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,713][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:49811 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,714][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,716][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,717][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,719][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,719][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.52.10:49811 (size: 5.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,721][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.52.10:49811 (size: 29.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,721][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,723][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,730][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:06:17,733][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 206). 2208 bytes result sent to driver
[INFO][2021-06-12 23:06:17,734][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 206) in 27 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:06:17,734][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:06:17,735][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (show at DemoMoveFinfo.java:130) finished in 0.027 s
[INFO][2021-06-12 23:06:17,735][org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at DemoMoveFinfo.java:130, took 0.038488 s
[INFO][2021-06-12 23:06:17,757][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.538 ms
[INFO][2021-06-12 23:06:17,761][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,tranMarketCode(JYS) as JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-12 23:06:17,771][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:06:17,775][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-12 23:06:17,775][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:06:17,835][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.8353 ms
[INFO][2021-06-12 23:06:17,843][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-12 23:06:17,843][org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-12 23:06:17,843][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:06:17,844][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:06:17,844][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:06:17,844][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[35] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-12 23:06:17,846][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 15.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:17,850][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.0 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:17,851][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.52.10:49811 (size: 7.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:17,851][org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:06:17,852][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:06:17,852][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
[INFO][2021-06-12 23:06:17,854][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:06:17,854][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 207)
[INFO][2021-06-12 23:06:17,875][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:06:17,877][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 207). 2204 bytes result sent to driver
[INFO][2021-06-12 23:06:17,878][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 207) in 25 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:06:17,878][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:06:17,878][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (show at DemoMoveFinfo.java:134) finished in 0.025 s
[INFO][2021-06-12 23:06:17,878][org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: show at DemoMoveFinfo.java:134, took 0.035311 s
[INFO][2021-06-12 23:06:17,880][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_tzqdmbg
[INFO][2021-06-12 23:06:17,920][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,921][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,921][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,921][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,921][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-12 23:06:17,922][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:17,923][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:06:17,923][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:06:17,934][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg
[INFO][2021-06-12 23:06:17,940][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as string) as id,cast(jys as string) as jys,cast(zqdm as string) as zqdm,cast(zqmc as string) as zqmc,cast(zqlb as string) as zqlb,cast(bgdm as string) as bgdm,cast(bgmc as string) as bgmc,cast(blzh as decimal(12,9)) as blzh,cast(bgsm as string) as bgsm,cast(bglb as decimal(12,0)) as bglb,cast(whsj as string) as whsj,cast(bgrq as int) as bgrq,cast(zxj as decimal(9,4)) as zxj from sparktzqdmbg
[INFO][2021-06-12 23:06:17,948][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:06:17,952][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:137] -  
[INFO][2021-06-12 23:06:17,952][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:06:17,991][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.5804 ms
[INFO][2021-06-12 23:06:17,997][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:138
[INFO][2021-06-12 23:06:17,998][org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (show at DemoMoveFinfo.java:138) with 1 output partitions
[INFO][2021-06-12 23:06:17,998][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:06:17,998][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:06:17,998][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:06:17,998][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (MapPartitionsRDD[40] at show at DemoMoveFinfo.java:138), which has no missing parents
[INFO][2021-06-12 23:06:17,999][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 15.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:18,002][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:18,002][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.52.10:49811 (size: 7.1 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,003][org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:06:18,003][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:06:18,003][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
[INFO][2021-06-12 23:06:18,004][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:06:18,005][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 208)
[INFO][2021-06-12 23:06:18,065][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:06:18,067][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 208). 2208 bytes result sent to driver
[INFO][2021-06-12 23:06:18,068][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 208) in 65 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:06:18,068][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:06:18,069][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (show at DemoMoveFinfo.java:138) finished in 0.066 s
[INFO][2021-06-12 23:06:18,069][org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: show at DemoMoveFinfo.java:138, took 0.072506 s
[INFO][2021-06-12 23:06:18,090][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.9401 ms
[INFO][2021-06-12 23:06:18,093][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg
[INFO][2021-06-12 23:06:18,103][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_tzqdmbg select ID,JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-12 23:06:18,134][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,134][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,135][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,135][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,136][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,136][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,137][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,137][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-12 23:06:18,137][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,138][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-12 23:06:18,138][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:06:18,138][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:06:18,139][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:06:18,292][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:06:18,306][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:06:18,306][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:06:18,329][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.2731 ms
[INFO][2021-06-12 23:06:18,350][org.apache.spark.SparkContext:54] - Starting job: sql at DemoMoveFinfo.java:145
[INFO][2021-06-12 23:06:18,351][org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (sql at DemoMoveFinfo.java:145) with 1 output partitions
[INFO][2021-06-12 23:06:18,351][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:06:18,351][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:06:18,351][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:06:18,351][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[42] at sql at DemoMoveFinfo.java:145), which has no missing parents
[INFO][2021-06-12 23:06:18,363][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 69.8 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:18,369][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 27.3 KB, free 3.8 GB)
[INFO][2021-06-12 23:06:18,370][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,370][org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:06:18,370][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:06:18,370][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
[INFO][2021-06-12 23:06:18,372][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 5817 bytes)
[INFO][2021-06-12 23:06:18,373][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 209)
[INFO][2021-06-12 23:06:18,410][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5026
[INFO][2021-06-12 23:06:18,443][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.52.10:49811 in memory (size: 5.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,444][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5076
[INFO][2021-06-12 23:06:18,444][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4976
[INFO][2021-06-12 23:06:18,445][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5227
[INFO][2021-06-12 23:06:18,445][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.52.10:49811 in memory (size: 7.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,446][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5027
[INFO][2021-06-12 23:06:18,446][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5226
[INFO][2021-06-12 23:06:18,446][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5127
[INFO][2021-06-12 23:06:18,446][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.52.10:49811 in memory (size: 7.1 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,448][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.52.10:49811 in memory (size: 29.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,449][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.52.10:49811 in memory (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,450][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5126
[INFO][2021-06-12 23:06:18,450][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4977
[INFO][2021-06-12 23:06:18,450][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.52.10:49811 in memory (size: 8.4 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:18,450][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5177
[INFO][2021-06-12 23:06:18,450][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5176
[INFO][2021-06-12 23:06:18,451][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5077
[INFO][2021-06-12 23:06:18,470][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:06:18,470][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:06:18,471][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:06:18,471][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:06:18,471][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-12 23:06:18,472][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-12 23:06:18,474][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : false,
    "metadata" : {
      "comment" : "ID",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "jys",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqlb",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "blzh",
    "type" : "decimal(12,9)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,9)"
    }
  }, {
    "name" : "bgsm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bglb",
    "type" : "decimal(12,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,0)"
    }
  }, {
    "name" : "whsj",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgrq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "zxj",
    "type" : "decimal(9,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,4)"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required binary id (UTF8);
  optional binary jys (UTF8);
  optional binary zqdm (UTF8);
  optional binary zqmc (UTF8);
  optional binary zqlb (UTF8);
  optional binary bgdm (UTF8);
  optional binary bgmc (UTF8);
  optional fixed_len_byte_array(6) blzh (DECIMAL(12,9));
  optional binary bgsm (UTF8);
  optional fixed_len_byte_array(6) bglb (DECIMAL(12,0));
  optional binary whsj (UTF8);
  optional int32 bgrq;
  optional fixed_len_byte_array(4) zxj (DECIMAL(9,4));
}

       
[INFO][2021-06-12 23:06:18,478][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-12 23:06:18,486][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:06:18,486][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 7,751
[INFO][2021-06-12 23:06:18,490][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 220B for [id] BINARY: 47 values, 275B raw, 191B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,491][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 55B for [jys] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 5 entries, 25B raw, 5B comp}
[INFO][2021-06-12 23:06:18,491][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 359B for [zqdm] BINARY: 47 values, 466B raw, 320B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,491][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 93B for [zqmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 42 entries, 605B raw, 42B comp}
[INFO][2021-06-12 23:06:18,492][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 46B for [zqlb] BINARY: 47 values, 15B raw, 17B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 2 entries, 12B raw, 2B comp}
[INFO][2021-06-12 23:06:18,492][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 280B for [bgdm] BINARY: 47 values, 467B raw, 241B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,492][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 84B for [bgmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 41 entries, 539B raw, 41B comp}
[INFO][2021-06-12 23:06:18,492][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 92B for [blzh] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 54B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,493][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 105B for [bgsm] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 7 entries, 172B raw, 7B comp}
[INFO][2021-06-12 23:06:18,493][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 81B for [bglb] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 43B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,493][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 87B for [whsj] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [RLE, BIT_PACKED, PLAIN_DICTIONARY], dic { 41 entries, 492B raw, 41B comp}
[INFO][2021-06-12 23:06:18,493][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 29B for [bgrq] INT32: 47 values, 6B raw, 8B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,493][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 168B for [zxj] FIXED_LEN_BYTE_ARRAY: 47 values, 194B raw, 133B comp, 1 pages, encodings: [RLE, PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:06:18,524][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210612230618_0010_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/info_tzqdmbg/_temporary/0/task_20210612230618_0010_m_000000
[INFO][2021-06-12 23:06:18,525][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210612230618_0010_m_000000_0: Committed
[INFO][2021-06-12 23:06:18,527][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 209). 1500 bytes result sent to driver
[INFO][2021-06-12 23:06:18,528][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 209) in 157 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:06:18,528][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:06:18,529][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (sql at DemoMoveFinfo.java:145) finished in 0.157 s
[INFO][2021-06-12 23:06:18,529][org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: sql at DemoMoveFinfo.java:145, took 0.178340 s
[INFO][2021-06-12 23:06:18,549][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[INFO][2021-06-12 23:06:34,466][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,466][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,466][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,466][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,466][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,468][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,468][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,469][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,470][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,471][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,472][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,472][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,473][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,473][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,473][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,473][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,473][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,473][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,474][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,475][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,475][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,476][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,477][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,477][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,477][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,477][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,477][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,478][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,478][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,478][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,479][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,479][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,480][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,481][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,481][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,481][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,482][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,482][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,482][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,482][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,482][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,483][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,484][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,484][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,484][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,485][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,486][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,486][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,487][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,487][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,487][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,487][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,487][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,488][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,489][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,489][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,489][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,490][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,491][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,491][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,491][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,491][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,492][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,492][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,492][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,493][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,493][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,493][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,494][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,495][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,495][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,496][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,496][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,497][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,497][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,497][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,497][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,497][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,498][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,498][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,498][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,499][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,500][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,500][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,501][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,501][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,501][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,501][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,502][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,502][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,502][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,503][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,504][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,504][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,505][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,505][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,506][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,506][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,506][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,506][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,507][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,507][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,507][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,508][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,509][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,509][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,510][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,511][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,512][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,512][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,512][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,513][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,513][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,513][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,514][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,515][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-12 23:06:34,516][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,517][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,518][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,519][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,519][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,520][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,520][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,520][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,521][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,521][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,521][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,522][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,523][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,524][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,525][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,526][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@7661b5a{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-12 23:06:34,527][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,528][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,529][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,529][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,529][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,530][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,530][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,530][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,531][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@704641e3{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,531][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,531][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2a2ef072{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,532][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6850b758{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,532][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,533][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17690e14{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,533][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8406c2{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,533][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,534][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@108a46d6{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,535][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1fac1d5c{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,535][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,535][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@9fc9f91{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,536][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4715ae33{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,536][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,537][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@23a5818e{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,538][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,538][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6daf7d37{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,539][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@65d57e4e{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,539][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,539][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a2ddf26{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,540][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,540][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@212dfd39{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,540][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,541][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@741f8dbe{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,541][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,541][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@10afe71a{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,541][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,542][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1e86a5a7{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,542][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,542][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2e6f610d{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,543][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@66f0548d{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,543][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17d32e9b{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,543][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,544][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@435e60ff{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,545][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ba26eb0{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,545][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,545][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@51841ac6{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,545][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7c251f90{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:06:34,545][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,546][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,547][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,547][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-12 23:06:34,547][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,549][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,549][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,549][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,549][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,549][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,550][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,550][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,551][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,552][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,553][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:06:34,553][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,555][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_15_piece0,StorageLevel(memory, 1 replicas),27967,0))
[INFO][2021-06-12 23:06:34,556][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,556][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_6_piece0,StorageLevel(memory, 1 replicas),167,0))
[INFO][2021-06-12 23:06:34,557][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,557][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[INFO][2021-06-12 23:06:34,557][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-12 23:06:34,557][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None) re-registering with master
[INFO][2021-06-12 23:06:34,557][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[ERROR][2021-06-12 23:06:34,557][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1623510394557,BlockManagerId(driver, 192.168.52.10, 49811, None),4041757163)
[INFO][2021-06-12 23:06:34,558][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 49811, None)
[INFO][2021-06-12 23:06:34,559][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-12 23:06:34,559][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:49811 (size: 16.2 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,560][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_0_piece0,StorageLevel(memory, 1 replicas),16571,0))
[INFO][2021-06-12 23:06:34,561][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:49811 (size: 17.2 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,561][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_4_piece0,StorageLevel(memory, 1 replicas),17581,0))
[INFO][2021-06-12 23:06:34,561][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:49811 (size: 8.6 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,562][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_3_piece0,StorageLevel(memory, 1 replicas),8793,0))
[INFO][2021-06-12 23:06:34,562][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:49811 (size: 124.0 B, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,563][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_7_piece0,StorageLevel(memory, 1 replicas),124,0))
[INFO][2021-06-12 23:06:34,563][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:49811 (size: 27.3 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,563][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_15_piece0,StorageLevel(memory, 1 replicas),27967,0))
[INFO][2021-06-12 23:06:34,563][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:49811 (size: 167.0 B, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,564][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_6_piece0,StorageLevel(memory, 1 replicas),167,0))
[INFO][2021-06-12 23:06:34,565][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:49811 (size: 12.0 KB, free: 3.8 GB)
[ERROR][2021-06-12 23:06:34,565][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 49811, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[INFO][2021-06-12 23:06:34,567][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-12 23:06:34,646][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-12 23:06:34,647][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-12 23:06:34,649][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-12 23:06:34,652][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-12 23:06:34,657][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-12 23:06:34,658][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-12 23:06:34,659][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-0a59ac80-7d00-4efe-9a99-c31ef6011911
[INFO][2021-06-12 23:20:36,390][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-12 23:20:36,662][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-12 23:20:36,663][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-12 23:20:36,664][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-12 23:20:36,665][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-12 23:20:36,666][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-12 23:20:37,480][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 55782.
[INFO][2021-06-12 23:20:37,503][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-12 23:20:37,523][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-12 23:20:37,529][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-12 23:20:37,530][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-12 23:20:37,555][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-4e49984d-a23f-4c0c-9d35-cc8ad7733db5
[INFO][2021-06-12 23:20:37,587][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-12 23:20:37,654][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-12 23:20:37,734][org.spark_project.jetty.util.log:186] - Logging initialized @3767ms
[INFO][2021-06-12 23:20:37,828][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-12 23:20:37,845][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,845][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,846][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,846][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,847][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@10afe71a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,847][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,848][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,848][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,849][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,849][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,849][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@23a5818e{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,850][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,851][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,851][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,852][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@108a46d6{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,852][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,853][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17690e14{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,853][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,853][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,854][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,860][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f00f851{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,860][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4207609e{/,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,861][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,861][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,862][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:37,868][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-12 23:20:37,869][org.spark_project.jetty.server.Server:379] - Started @3904ms
[INFO][2021-06-12 23:20:37,869][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-12 23:20:37,871][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-12 23:20:37,930][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-12 23:20:37,970][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55823.
[INFO][2021-06-12 23:20:37,971][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:55823
[INFO][2021-06-12 23:20:37,973][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-12 23:20:37,975][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 55823, None)
[INFO][2021-06-12 23:20:37,978][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:55823 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 55823, None)
[INFO][2021-06-12 23:20:37,985][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 55823, None)
[INFO][2021-06-12 23:20:37,985][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 55823, None)
[INFO][2021-06-12 23:20:38,162][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6056232d{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,195][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-12 23:20:38,201][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6e4599c0{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,202][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3d1f558a{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,202][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@69f0b0f4{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,203][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f7efd0b{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,204][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@d2291de{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-12 23:20:38,274][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-12 23:20:38,413][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-12 23:20:38,413][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-12 23:20:38,414][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-12 23:20:38,414][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-12 23:20:38,414][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-12 23:20:38,414][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-12 23:20:38,415][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-12 23:20:38,415][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-12 23:20:38,653][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-12 23:20:38,685][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-12 23:20:39,511][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-12 23:20:39,661][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/11fa3d00-5eb5-4e8e-8eaa-5a18698fea7f_resources
[INFO][2021-06-12 23:20:39,674][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/11fa3d00-5eb5-4e8e-8eaa-5a18698fea7f
[INFO][2021-06-12 23:20:39,684][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/11fa3d00-5eb5-4e8e-8eaa-5a18698fea7f
[INFO][2021-06-12 23:20:39,689][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/11fa3d00-5eb5-4e8e-8eaa-5a18698fea7f/_tmp_space.db
[INFO][2021-06-12 23:20:39,696][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-12 23:20:39,871][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-12 23:20:40,644][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,650][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,650][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-12 23:20:40,651][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-12 23:20:40,651][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,652][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,652][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,652][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:40,653][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:42,797][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:43,008][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:43,011][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:55823 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:43,018][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-12 23:20:43,706][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 261.9823 ms
[INFO][2021-06-12 23:20:43,896][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.2202 ms
[INFO][2021-06-12 23:20:44,056][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-12 23:20:44,165][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-12 23:20:44,205][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-12 23:20:44,206][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:44,207][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:20:44,210][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:20:44,224][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 23:20:44,261][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:44,285][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:44,285][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:55823 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:44,286][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:44,290][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:44,292][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-12 23:20:44,354][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-12 23:20:44,365][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-12 23:20:44,433][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-12 23:20:44,440][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-12 23:20:44,440][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-12 23:20:44,440][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-12 23:20:44,440][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-12 23:20:44,441][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-12 23:20:44,482][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.2003 ms
[INFO][2021-06-12 23:20:45,020][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155676 bytes result sent to driver
[INFO][2021-06-12 23:20:45,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 726 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:45,056][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:45,058][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 0.748 s
[INFO][2021-06-12 23:20:45,065][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 0.899946 s
[INFO][2021-06-12 23:20:45,144][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-12 23:20:45,149][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:45,150][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-12 23:20:45,150][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:45,150][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-12 23:20:45,150][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-12 23:20:45,152][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 23:20:45,164][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:45,168][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:45,169][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:55823 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:45,170][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:45,171][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:45,172][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-12 23:20:45,175][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-12 23:20:45,175][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-12 23:20:45,192][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-12 23:20:47,319][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1848 bytes result sent to driver
[INFO][2021-06-12 23:20:47,325][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 2153 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:47,325][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:47,326][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 2.154 s
[INFO][2021-06-12 23:20:47,327][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-12 23:20:47,327][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-12 23:20:47,328][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-12 23:20:47,329][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-12 23:20:47,335][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-12 23:20:47,366][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:47,369][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:47,370][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:55823 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:47,370][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:47,371][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-12 23:20:47,371][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-12 23:20:47,374][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,376][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,376][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,377][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,378][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,378][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,379][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,380][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,381][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,382][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,383][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,384][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,385][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,386][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,387][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,388][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,388][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-12 23:20:47,389][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-12 23:20:47,389][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-12 23:20:47,390][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-12 23:20:47,395][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-12 23:20:47,398][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-12 23:20:47,397][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-12 23:20:47,397][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-12 23:20:47,395][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-12 23:20:47,399][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-12 23:20:47,399][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-12 23:20:47,409][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-12 23:20:47,410][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-12 23:20:47,416][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-12 23:20:47,419][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-12 23:20:47,420][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-12 23:20:47,442][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,442][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 23:20:47,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-12 23:20:47,447][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-12 23:20:47,490][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.1223 ms
[INFO][2021-06-12 23:20:47,534][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2450 bytes result sent to driver
[INFO][2021-06-12 23:20:47,537][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2374 bytes result sent to driver
[INFO][2021-06-12 23:20:47,537][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2343 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2428 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2456 bytes result sent to driver
[INFO][2021-06-12 23:20:47,539][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2362 bytes result sent to driver
[INFO][2021-06-12 23:20:47,540][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,541][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2238 bytes result sent to driver
[INFO][2021-06-12 23:20:47,541][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-12 23:20:47,541][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2371 bytes result sent to driver
[INFO][2021-06-12 23:20:47,541][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2371 bytes result sent to driver
[INFO][2021-06-12 23:20:47,543][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2443 bytes result sent to driver
[INFO][2021-06-12 23:20:47,543][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,545][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-12 23:20:47,543][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2364 bytes result sent to driver
[INFO][2021-06-12 23:20:47,546][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2269 bytes result sent to driver
[INFO][2021-06-12 23:20:47,546][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,547][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,545][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,549][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,549][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-12 23:20:47,550][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,551][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-12 23:20:47,552][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,551][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,554][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,554][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 172 ms on localhost (executor driver) (1/200)
[INFO][2021-06-12 23:20:47,555][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 175 ms on localhost (executor driver) (2/200)
[INFO][2021-06-12 23:20:47,554][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-12 23:20:47,557][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 178 ms on localhost (executor driver) (3/200)
[INFO][2021-06-12 23:20:47,558][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,558][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,558][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 178 ms on localhost (executor driver) (4/200)
[INFO][2021-06-12 23:20:47,559][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 182 ms on localhost (executor driver) (5/200)
[INFO][2021-06-12 23:20:47,559][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,560][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,561][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 174 ms on localhost (executor driver) (6/200)
[INFO][2021-06-12 23:20:47,561][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,562][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,563][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2373 bytes result sent to driver
[INFO][2021-06-12 23:20:47,564][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 181 ms on localhost (executor driver) (7/200)
[INFO][2021-06-12 23:20:47,562][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-12 23:20:47,565][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,565][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-12 23:20:47,567][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2374 bytes result sent to driver
[INFO][2021-06-12 23:20:47,566][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,570][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2269 bytes result sent to driver
[INFO][2021-06-12 23:20:47,566][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-12 23:20:47,571][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-12 23:20:47,573][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,573][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,571][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2253 bytes result sent to driver
[INFO][2021-06-12 23:20:47,569][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,569][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,574][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,574][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,572][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,575][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,575][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,577][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,578][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,579][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,582][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,583][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-12 23:20:47,583][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,583][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-12 23:20:47,584][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-12 23:20:47,584][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,585][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,586][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,587][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-12 23:20:47,587][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,587][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,589][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,589][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,575][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,594][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-12 23:20:47,594][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-12 23:20:47,594][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-12 23:20:47,587][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,610][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-12 23:20:47,611][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,586][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,611][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 25 ms
[INFO][2021-06-12 23:20:47,585][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-12 23:20:47,585][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,612][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 27 ms
[INFO][2021-06-12 23:20:47,576][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-12 23:20:47,613][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,614][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,615][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,615][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,615][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,615][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,611][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,610][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,618][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,618][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-12 23:20:47,619][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2340 bytes result sent to driver
[INFO][2021-06-12 23:20:47,609][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:47,608][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
[INFO][2021-06-12 23:20:47,620][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,618][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,625][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-12 23:20:47,625][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,625][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,614][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,627][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 13 ms
[INFO][2021-06-12 23:20:47,629][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,624][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,630][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,627][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-12 23:20:47,627][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,630][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:47,631][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:47,631][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-12 23:20:47,632][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,633][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,634][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-12 23:20:47,634][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,634][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-12 23:20:47,635][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-12 23:20:47,635][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,636][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-12 23:20:47,636][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,637][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,637][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,637][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-12 23:20:47,637][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,635][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:47,639][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-12 23:20:47,639][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,640][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,635][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,643][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,643][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,646][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,646][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,642][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,646][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-12 23:20:47,647][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,647][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2263 bytes result sent to driver
[INFO][2021-06-12 23:20:47,647][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,642][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:47,648][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,649][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,649][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,649][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,639][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-12 23:20:47,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,648][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-12 23:20:47,654][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,655][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,648][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,655][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:47,648][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,657][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-12 23:20:47,657][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,658][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,658][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,659][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,659][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,660][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,660][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2364 bytes result sent to driver
[INFO][2021-06-12 23:20:47,660][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,660][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,661][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-12 23:20:47,661][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,661][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,660][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,660][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-12 23:20:47,662][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,663][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,664][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,663][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-12 23:20:47,664][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-12 23:20:47,664][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,665][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,664][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,665][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,666][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,666][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,667][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-12 23:20:47,667][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,667][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,668][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-12 23:20:47,668][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-12 23:20:47,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,670][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,667][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,671][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,671][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,672][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,672][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-12 23:20:47,673][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,668][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-12 23:20:47,675][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,678][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,678][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,672][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,672][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-12 23:20:47,679][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,680][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-12 23:20:47,680][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,669][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:47,681][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-12 23:20:47,680][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,678][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2344 bytes result sent to driver
[INFO][2021-06-12 23:20:47,682][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,683][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,684][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,682][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2345 bytes result sent to driver
[INFO][2021-06-12 23:20:47,706][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-12 23:20:47,684][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,707][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 23 ms
[INFO][2021-06-12 23:20:47,684][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,683][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-12 23:20:47,708][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-12 23:20:47,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 24 ms
[INFO][2021-06-12 23:20:47,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,711][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2358 bytes result sent to driver
[INFO][2021-06-12 23:20:47,707][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2405 bytes result sent to driver
[INFO][2021-06-12 23:20:47,707][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,707][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,707][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,712][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,713][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-12 23:20:47,711][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2440 bytes result sent to driver
[INFO][2021-06-12 23:20:47,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,714][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,715][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 23:20:47,716][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,716][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,709][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-12 23:20:47,719][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2354 bytes result sent to driver
[INFO][2021-06-12 23:20:47,709][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 23:20:47,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,713][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,720][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2350 bytes result sent to driver
[INFO][2021-06-12 23:20:47,720][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,720][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2336 bytes result sent to driver
[INFO][2021-06-12 23:20:47,720][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-12 23:20:47,721][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2339 bytes result sent to driver
[INFO][2021-06-12 23:20:47,721][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,723][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,723][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-12 23:20:47,724][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-12 23:20:47,724][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,726][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,726][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,724][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,727][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,727][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,728][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,728][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-12 23:20:47,727][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2259 bytes result sent to driver
[INFO][2021-06-12 23:20:47,726][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-12 23:20:47,731][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2363 bytes result sent to driver
[INFO][2021-06-12 23:20:47,728][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2364 bytes result sent to driver
[INFO][2021-06-12 23:20:47,728][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,731][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2357 bytes result sent to driver
[INFO][2021-06-12 23:20:47,731][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,732][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,733][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,733][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,734][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-12 23:20:47,735][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,735][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-12 23:20:47,736][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,738][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,734][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2346 bytes result sent to driver
[INFO][2021-06-12 23:20:47,738][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2359 bytes result sent to driver
[INFO][2021-06-12 23:20:47,738][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,736][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,735][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-12 23:20:47,739][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,740][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,740][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-12 23:20:47,740][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,735][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,740][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-12 23:20:47,741][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,742][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,742][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,738][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,742][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-12 23:20:47,743][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-12 23:20:47,742][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,742][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2262 bytes result sent to driver
[INFO][2021-06-12 23:20:47,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,745][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-12 23:20:47,746][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,749][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,743][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,749][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,750][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,750][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2291 bytes result sent to driver
[INFO][2021-06-12 23:20:47,751][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-12 23:20:47,749][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,752][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,752][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,749][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,754][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,755][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,745][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,757][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-12 23:20:47,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,758][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,756][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,757][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-12 23:20:47,761][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,762][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,765][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,765][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-12 23:20:47,765][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-12 23:20:47,763][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,766][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-12 23:20:47,767][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,767][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-12 23:20:47,768][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,768][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,768][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:47,768][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-12 23:20:47,769][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,769][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,769][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,769][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,770][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,771][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-12 23:20:47,771][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,769][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,768][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,771][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,774][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,775][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-12 23:20:47,776][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,777][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,777][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,778][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-12 23:20:47,778][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,779][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2279 bytes result sent to driver
[INFO][2021-06-12 23:20:47,777][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,777][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2375 bytes result sent to driver
[INFO][2021-06-12 23:20:47,777][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-12 23:20:47,780][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,779][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2340 bytes result sent to driver
[INFO][2021-06-12 23:20:47,780][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-12 23:20:47,781][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,781][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,782][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-12 23:20:47,783][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,784][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-12 23:20:47,785][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2444 bytes result sent to driver
[INFO][2021-06-12 23:20:47,785][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,785][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,786][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-12 23:20:47,786][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,787][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-12 23:20:47,787][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,788][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-12 23:20:47,788][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,789][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-12 23:20:47,789][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,790][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 406 ms on localhost (executor driver) (8/200)
[INFO][2021-06-12 23:20:47,791][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-12 23:20:47,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,791][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 419 ms on localhost (executor driver) (9/200)
[INFO][2021-06-12 23:20:47,792][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2370 bytes result sent to driver
[INFO][2021-06-12 23:20:47,792][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 407 ms on localhost (executor driver) (10/200)
[INFO][2021-06-12 23:20:47,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,794][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,794][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,794][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,795][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2369 bytes result sent to driver
[INFO][2021-06-12 23:20:47,797][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2434 bytes result sent to driver
[INFO][2021-06-12 23:20:47,795][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2363 bytes result sent to driver
[INFO][2021-06-12 23:20:47,795][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2346 bytes result sent to driver
[INFO][2021-06-12 23:20:47,799][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,799][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,797][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,800][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,795][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 421 ms on localhost (executor driver) (11/200)
[INFO][2021-06-12 23:20:47,801][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2355 bytes result sent to driver
[INFO][2021-06-12 23:20:47,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 416 ms on localhost (executor driver) (12/200)
[INFO][2021-06-12 23:20:47,802][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 419 ms on localhost (executor driver) (13/200)
[INFO][2021-06-12 23:20:47,803][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2276 bytes result sent to driver
[INFO][2021-06-12 23:20:47,804][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,805][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-12 23:20:47,806][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2350 bytes result sent to driver
[INFO][2021-06-12 23:20:47,800][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:47,806][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,807][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,806][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,805][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,810][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,810][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-12 23:20:47,810][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,811][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 433 ms on localhost (executor driver) (14/200)
[INFO][2021-06-12 23:20:47,811][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 269 ms on localhost (executor driver) (15/200)
[INFO][2021-06-12 23:20:47,812][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 261 ms on localhost (executor driver) (16/200)
[INFO][2021-06-12 23:20:47,813][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2291 bytes result sent to driver
[INFO][2021-06-12 23:20:47,814][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-12 23:20:47,815][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2265 bytes result sent to driver
[INFO][2021-06-12 23:20:47,813][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 268 ms on localhost (executor driver) (17/200)
[INFO][2021-06-12 23:20:47,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,813][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,817][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 269 ms on localhost (executor driver) (18/200)
[INFO][2021-06-12 23:20:47,816][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2359 bytes result sent to driver
[INFO][2021-06-12 23:20:47,818][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2367 bytes result sent to driver
[INFO][2021-06-12 23:20:47,818][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 254 ms on localhost (executor driver) (19/200)
[INFO][2021-06-12 23:20:47,819][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 441 ms on localhost (executor driver) (20/200)
[INFO][2021-06-12 23:20:47,820][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,821][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-12 23:20:47,822][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,823][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-12 23:20:47,823][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:55823 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:47,823][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,824][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,824][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-12 23:20:47,824][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-12 23:20:47,824][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,825][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,825][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,825][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,825][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,826][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-12 23:20:47,825][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,825][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,826][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,827][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,827][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,827][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,828][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-12 23:20:47,828][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-12 23:20:47,828][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,829][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,830][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,831][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,831][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,831][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,827][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,828][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,832][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,833][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:55823 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:47,834][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-12 23:20:47,834][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:47,834][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,835][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,835][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-12 23:20:47,836][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,836][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-12 23:20:47,837][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,834][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2364 bytes result sent to driver
[INFO][2021-06-12 23:20:47,838][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,839][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,837][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-12 23:20:47,839][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,839][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,839][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-12 23:20:47,840][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-12 23:20:47,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,840][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,840][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,842][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,842][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,842][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-12 23:20:47,839][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,843][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,843][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2263 bytes result sent to driver
[INFO][2021-06-12 23:20:47,845][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-12 23:20:47,842][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,846][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,847][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,846][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-12 23:20:47,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,847][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2453 bytes result sent to driver
[INFO][2021-06-12 23:20:47,847][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,847][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,852][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-12 23:20:47,853][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,853][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,851][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,854][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,855][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2343 bytes result sent to driver
[INFO][2021-06-12 23:20:47,853][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,856][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,852][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2359 bytes result sent to driver
[INFO][2021-06-12 23:20:47,852][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2256 bytes result sent to driver
[INFO][2021-06-12 23:20:47,857][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,856][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,857][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,856][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-12 23:20:47,858][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,855][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-12 23:20:47,860][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,861][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,861][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,861][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-12 23:20:47,855][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,861][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-12 23:20:47,862][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,863][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,863][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,861][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,860][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:47,857][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-12 23:20:47,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,866][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,864][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,863][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-12 23:20:47,867][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,863][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,862][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-12 23:20:47,869][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,870][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,870][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,870][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2377 bytes result sent to driver
[INFO][2021-06-12 23:20:47,871][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,871][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,868][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,872][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2347 bytes result sent to driver
[INFO][2021-06-12 23:20:47,871][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-12 23:20:47,870][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-12 23:20:47,870][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2373 bytes result sent to driver
[INFO][2021-06-12 23:20:47,870][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,873][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:47,873][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-12 23:20:47,874][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,874][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2368 bytes result sent to driver
[INFO][2021-06-12 23:20:47,875][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,875][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,876][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,876][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2267 bytes result sent to driver
[INFO][2021-06-12 23:20:47,877][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-12 23:20:47,878][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,879][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,879][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,875][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,880][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-12 23:20:47,879][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,876][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,881][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,881][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-12 23:20:47,881][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,875][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-12 23:20:47,883][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,883][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,881][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,880][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,884][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2356 bytes result sent to driver
[INFO][2021-06-12 23:20:47,885][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,884][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,886][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,886][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,885][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2344 bytes result sent to driver
[INFO][2021-06-12 23:20:47,885][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-12 23:20:47,886][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,887][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,888][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-12 23:20:47,888][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,889][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 351 ms on localhost (executor driver) (21/200)
[INFO][2021-06-12 23:20:47,889][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 308 ms on localhost (executor driver) (22/200)
[INFO][2021-06-12 23:20:47,890][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-12 23:20:47,890][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:47,888][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-12 23:20:47,890][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 325 ms on localhost (executor driver) (23/200)
[INFO][2021-06-12 23:20:47,889][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,891][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2277 bytes result sent to driver
[INFO][2021-06-12 23:20:47,891][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,891][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,891][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 309 ms on localhost (executor driver) (24/200)
[INFO][2021-06-12 23:20:47,891][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,892][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 333 ms on localhost (executor driver) (25/200)
[INFO][2021-06-12 23:20:47,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,895][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,894][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 316 ms on localhost (executor driver) (26/200)
[INFO][2021-06-12 23:20:47,896][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,896][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 310 ms on localhost (executor driver) (27/200)
[INFO][2021-06-12 23:20:47,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 326 ms on localhost (executor driver) (28/200)
[INFO][2021-06-12 23:20:47,897][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,897][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2447 bytes result sent to driver
[INFO][2021-06-12 23:20:47,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 320 ms on localhost (executor driver) (29/200)
[INFO][2021-06-12 23:20:47,899][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:47,899][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:47,899][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 288 ms on localhost (executor driver) (30/200)
[INFO][2021-06-12 23:20:47,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 317 ms on localhost (executor driver) (31/200)
[INFO][2021-06-12 23:20:47,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 523 ms on localhost (executor driver) (32/200)
[INFO][2021-06-12 23:20:47,901][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 325 ms on localhost (executor driver) (33/200)
[INFO][2021-06-12 23:20:47,901][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 276 ms on localhost (executor driver) (34/200)
[INFO][2021-06-12 23:20:47,902][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 340 ms on localhost (executor driver) (35/200)
[INFO][2021-06-12 23:20:47,902][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,902][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2374 bytes result sent to driver
[INFO][2021-06-12 23:20:47,902][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2244 bytes result sent to driver
[INFO][2021-06-12 23:20:47,903][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,903][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 267 ms on localhost (executor driver) (36/200)
[INFO][2021-06-12 23:20:47,904][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 271 ms on localhost (executor driver) (37/200)
[INFO][2021-06-12 23:20:47,904][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-12 23:20:47,904][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 320 ms on localhost (executor driver) (38/200)
[INFO][2021-06-12 23:20:47,904][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 283 ms on localhost (executor driver) (39/200)
[INFO][2021-06-12 23:20:47,904][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 269 ms on localhost (executor driver) (40/200)
[INFO][2021-06-12 23:20:47,905][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,906][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 271 ms on localhost (executor driver) (41/200)
[INFO][2021-06-12 23:20:47,906][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-12 23:20:47,906][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 275 ms on localhost (executor driver) (42/200)
[INFO][2021-06-12 23:20:47,906][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 268 ms on localhost (executor driver) (43/200)
[INFO][2021-06-12 23:20:47,907][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,907][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,907][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,908][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 260 ms on localhost (executor driver) (44/200)
[INFO][2021-06-12 23:20:47,908][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-12 23:20:47,908][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 244 ms on localhost (executor driver) (45/200)
[INFO][2021-06-12 23:20:47,908][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 246 ms on localhost (executor driver) (46/200)
[INFO][2021-06-12 23:20:47,908][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,908][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 271 ms on localhost (executor driver) (47/200)
[INFO][2021-06-12 23:20:47,908][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,909][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 322 ms on localhost (executor driver) (48/200)
[INFO][2021-06-12 23:20:47,909][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 263 ms on localhost (executor driver) (49/200)
[INFO][2021-06-12 23:20:47,909][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 253 ms on localhost (executor driver) (50/200)
[INFO][2021-06-12 23:20:47,909][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 229 ms on localhost (executor driver) (51/200)
[INFO][2021-06-12 23:20:47,910][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,910][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,910][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,911][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 248 ms on localhost (executor driver) (52/200)
[INFO][2021-06-12 23:20:47,911][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-12 23:20:47,911][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 240 ms on localhost (executor driver) (53/200)
[INFO][2021-06-12 23:20:47,912][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 246 ms on localhost (executor driver) (54/200)
[INFO][2021-06-12 23:20:47,912][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 252 ms on localhost (executor driver) (55/200)
[INFO][2021-06-12 23:20:47,913][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 233 ms on localhost (executor driver) (56/200)
[INFO][2021-06-12 23:20:47,913][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 230 ms on localhost (executor driver) (57/200)
[INFO][2021-06-12 23:20:47,913][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,913][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,913][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 231 ms on localhost (executor driver) (58/200)
[INFO][2021-06-12 23:20:47,914][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 208 ms on localhost (executor driver) (59/200)
[INFO][2021-06-12 23:20:47,914][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 255 ms on localhost (executor driver) (60/200)
[INFO][2021-06-12 23:20:47,915][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2280 bytes result sent to driver
[INFO][2021-06-12 23:20:47,915][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2371 bytes result sent to driver
[INFO][2021-06-12 23:20:47,915][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,916][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-12 23:20:47,916][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 244 ms on localhost (executor driver) (61/200)
[INFO][2021-06-12 23:20:47,917][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2257 bytes result sent to driver
[INFO][2021-06-12 23:20:47,917][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 205 ms on localhost (executor driver) (62/200)
[INFO][2021-06-12 23:20:47,917][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 250 ms on localhost (executor driver) (63/200)
[INFO][2021-06-12 23:20:47,918][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 196 ms on localhost (executor driver) (64/200)
[INFO][2021-06-12 23:20:47,918][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 237 ms on localhost (executor driver) (65/200)
[INFO][2021-06-12 23:20:47,919][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 257 ms on localhost (executor driver) (66/200)
[INFO][2021-06-12 23:20:47,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,919][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 185 ms on localhost (executor driver) (67/200)
[INFO][2021-06-12 23:20:47,919][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 199 ms on localhost (executor driver) (68/200)
[INFO][2021-06-12 23:20:47,919][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,920][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,921][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-12 23:20:47,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 186 ms on localhost (executor driver) (69/200)
[INFO][2021-06-12 23:20:47,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 198 ms on localhost (executor driver) (70/200)
[INFO][2021-06-12 23:20:47,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 181 ms on localhost (executor driver) (71/200)
[INFO][2021-06-12 23:20:47,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 192 ms on localhost (executor driver) (72/200)
[INFO][2021-06-12 23:20:47,922][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 189 ms on localhost (executor driver) (73/200)
[INFO][2021-06-12 23:20:47,922][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 166 ms on localhost (executor driver) (74/200)
[INFO][2021-06-12 23:20:47,923][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 169 ms on localhost (executor driver) (75/200)
[INFO][2021-06-12 23:20:47,923][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,923][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,923][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 196 ms on localhost (executor driver) (76/200)
[INFO][2021-06-12 23:20:47,925][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,925][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 163 ms on localhost (executor driver) (77/200)
[INFO][2021-06-12 23:20:47,925][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-12 23:20:47,925][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 185 ms on localhost (executor driver) (78/200)
[INFO][2021-06-12 23:20:47,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 185 ms on localhost (executor driver) (79/200)
[INFO][2021-06-12 23:20:47,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 166 ms on localhost (executor driver) (80/200)
[INFO][2021-06-12 23:20:47,927][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2434 bytes result sent to driver
[INFO][2021-06-12 23:20:47,927][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,928][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 149 ms on localhost (executor driver) (81/200)
[INFO][2021-06-12 23:20:47,928][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,928][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-12 23:20:47,928][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,928][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 180 ms on localhost (executor driver) (82/200)
[INFO][2021-06-12 23:20:47,929][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,930][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 168 ms on localhost (executor driver) (83/200)
[INFO][2021-06-12 23:20:47,930][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-12 23:20:47,930][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2371 bytes result sent to driver
[INFO][2021-06-12 23:20:47,931][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,931][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-12 23:20:47,931][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 155 ms on localhost (executor driver) (84/200)
[INFO][2021-06-12 23:20:47,932][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 165 ms on localhost (executor driver) (85/200)
[INFO][2021-06-12 23:20:47,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,932][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 155 ms on localhost (executor driver) (86/200)
[INFO][2021-06-12 23:20:47,933][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,933][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,933][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,933][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 167 ms on localhost (executor driver) (87/200)
[INFO][2021-06-12 23:20:47,934][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-12 23:20:47,934][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 160 ms on localhost (executor driver) (88/200)
[INFO][2021-06-12 23:20:47,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 148 ms on localhost (executor driver) (89/200)
[INFO][2021-06-12 23:20:47,934][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 191 ms on localhost (executor driver) (90/200)
[INFO][2021-06-12 23:20:47,935][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:47,935][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,936][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 148 ms on localhost (executor driver) (91/200)
[INFO][2021-06-12 23:20:47,937][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,937][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 148 ms on localhost (executor driver) (92/200)
[INFO][2021-06-12 23:20:47,937][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,938][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 158 ms on localhost (executor driver) (93/200)
[INFO][2021-06-12 23:20:47,938][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 152 ms on localhost (executor driver) (94/200)
[INFO][2021-06-12 23:20:47,939][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2278 bytes result sent to driver
[INFO][2021-06-12 23:20:47,939][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 135 ms on localhost (executor driver) (95/200)
[INFO][2021-06-12 23:20:47,939][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:47,940][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,940][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-12 23:20:47,941][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 162 ms on localhost (executor driver) (96/200)
[INFO][2021-06-12 23:20:47,941][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 202 ms on localhost (executor driver) (97/200)
[INFO][2021-06-12 23:20:47,942][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 138 ms on localhost (executor driver) (98/200)
[INFO][2021-06-12 23:20:47,942][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 133 ms on localhost (executor driver) (99/200)
[INFO][2021-06-12 23:20:47,943][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,943][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-12 23:20:47,943][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 120 ms on localhost (executor driver) (100/200)
[INFO][2021-06-12 23:20:47,944][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2368 bytes result sent to driver
[INFO][2021-06-12 23:20:47,944][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 123 ms on localhost (executor driver) (101/200)
[INFO][2021-06-12 23:20:47,944][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2447 bytes result sent to driver
[INFO][2021-06-12 23:20:47,944][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 124 ms on localhost (executor driver) (102/200)
[INFO][2021-06-12 23:20:47,945][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,947][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 122 ms on localhost (executor driver) (103/200)
[INFO][2021-06-12 23:20:47,948][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-12 23:20:47,948][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 109 ms on localhost (executor driver) (104/200)
[INFO][2021-06-12 23:20:47,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,953][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,952][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,951][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 115 ms on localhost (executor driver) (105/200)
[INFO][2021-06-12 23:20:47,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-12 23:20:47,956][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 130 ms on localhost (executor driver) (106/200)
[INFO][2021-06-12 23:20:47,956][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 133 ms on localhost (executor driver) (107/200)
[INFO][2021-06-12 23:20:47,956][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 128 ms on localhost (executor driver) (108/200)
[INFO][2021-06-12 23:20:47,958][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,959][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-12 23:20:47,961][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,963][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-12 23:20:47,963][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,963][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:47,963][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,964][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-12 23:20:47,964][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,966][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2333 bytes result sent to driver
[INFO][2021-06-12 23:20:47,966][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,966][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-12 23:20:47,966][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,967][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,968][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-12 23:20:47,968][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,967][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,969][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:47,969][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,970][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-12 23:20:47,971][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-12 23:20:47,970][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:47,971][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:47,971][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,974][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-12 23:20:47,970][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,976][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-12 23:20:47,974][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,978][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2278 bytes result sent to driver
[INFO][2021-06-12 23:20:47,974][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,978][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,978][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,979][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,979][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-12 23:20:47,980][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,981][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:47,982][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-12 23:20:47,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,981][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-12 23:20:47,988][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,989][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,984][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2347 bytes result sent to driver
[INFO][2021-06-12 23:20:47,981][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,991][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:47,988][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:47,991][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,991][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-12 23:20:47,992][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-12 23:20:47,992][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,992][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2355 bytes result sent to driver
[INFO][2021-06-12 23:20:47,993][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-12 23:20:47,992][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2347 bytes result sent to driver
[INFO][2021-06-12 23:20:47,993][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,994][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,995][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-12 23:20:47,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,995][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,996][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,996][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,996][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:47,997][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-12 23:20:47,997][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,998][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-12 23:20:47,998][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:47,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:47,998][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:47,999][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-12 23:20:47,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,000][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,001][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-12 23:20:48,001][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-12 23:20:48,002][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,002][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,002][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,002][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,003][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-12 23:20:48,003][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,004][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-12 23:20:48,004][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,005][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,006][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-12 23:20:48,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,010][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,012][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2260 bytes result sent to driver
[INFO][2021-06-12 23:20:48,000][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2273 bytes result sent to driver
[INFO][2021-06-12 23:20:48,012][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2347 bytes result sent to driver
[INFO][2021-06-12 23:20:48,012][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 179 ms on localhost (executor driver) (109/200)
[INFO][2021-06-12 23:20:48,013][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-12 23:20:48,013][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 186 ms on localhost (executor driver) (110/200)
[INFO][2021-06-12 23:20:48,013][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 161 ms on localhost (executor driver) (111/200)
[INFO][2021-06-12 23:20:48,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,014][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
[INFO][2021-06-12 23:20:48,000][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,015][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,015][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,014][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 176 ms on localhost (executor driver) (112/200)
[INFO][2021-06-12 23:20:48,013][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-12 23:20:48,009][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2370 bytes result sent to driver
[INFO][2021-06-12 23:20:48,016][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2267 bytes result sent to driver
[INFO][2021-06-12 23:20:48,006][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,017][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-12 23:20:48,006][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,018][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 12 ms
[INFO][2021-06-12 23:20:48,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,002][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-12 23:20:48,020][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,021][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,023][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,023][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,023][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:48,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
[INFO][2021-06-12 23:20:48,024][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:48,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
[INFO][2021-06-12 23:20:48,018][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-12 23:20:48,016][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 161 ms on localhost (executor driver) (113/200)
[INFO][2021-06-12 23:20:48,025][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:48,026][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 166 ms on localhost (executor driver) (114/200)
[INFO][2021-06-12 23:20:48,026][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 182 ms on localhost (executor driver) (115/200)
[INFO][2021-06-12 23:20:48,026][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 169 ms on localhost (executor driver) (116/200)
[INFO][2021-06-12 23:20:48,027][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 167 ms on localhost (executor driver) (117/200)
[INFO][2021-06-12 23:20:48,027][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 166 ms on localhost (executor driver) (118/200)
[INFO][2021-06-12 23:20:48,027][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2363 bytes result sent to driver
[INFO][2021-06-12 23:20:48,027][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 185 ms on localhost (executor driver) (119/200)
[INFO][2021-06-12 23:20:48,028][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 172 ms on localhost (executor driver) (120/200)
[INFO][2021-06-12 23:20:48,028][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 158 ms on localhost (executor driver) (121/200)
[INFO][2021-06-12 23:20:48,028][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 194 ms on localhost (executor driver) (122/200)
[INFO][2021-06-12 23:20:48,029][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 160 ms on localhost (executor driver) (123/200)
[INFO][2021-06-12 23:20:48,030][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 156 ms on localhost (executor driver) (124/200)
[INFO][2021-06-12 23:20:48,031][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2459 bytes result sent to driver
[INFO][2021-06-12 23:20:48,031][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-12 23:20:48,031][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 153 ms on localhost (executor driver) (125/200)
[INFO][2021-06-12 23:20:48,032][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 195 ms on localhost (executor driver) (126/200)
[INFO][2021-06-12 23:20:48,033][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,033][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,034][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 155 ms on localhost (executor driver) (127/200)
[INFO][2021-06-12 23:20:48,034][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-12 23:20:48,034][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2362 bytes result sent to driver
[INFO][2021-06-12 23:20:48,034][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 160 ms on localhost (executor driver) (128/200)
[INFO][2021-06-12 23:20:48,034][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 147 ms on localhost (executor driver) (129/200)
[INFO][2021-06-12 23:20:48,035][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,035][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 173 ms on localhost (executor driver) (130/200)
[INFO][2021-06-12 23:20:48,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 151 ms on localhost (executor driver) (131/200)
[INFO][2021-06-12 23:20:48,036][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-12 23:20:48,036][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 134 ms on localhost (executor driver) (132/200)
[INFO][2021-06-12 23:20:48,037][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,037][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 130 ms on localhost (executor driver) (133/200)
[INFO][2021-06-12 23:20:48,038][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,039][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-12 23:20:48,039][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 158 ms on localhost (executor driver) (134/200)
[INFO][2021-06-12 23:20:48,039][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 134 ms on localhost (executor driver) (135/200)
[INFO][2021-06-12 23:20:48,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 124 ms on localhost (executor driver) (136/200)
[INFO][2021-06-12 23:20:48,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 129 ms on localhost (executor driver) (137/200)
[INFO][2021-06-12 23:20:48,040][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 152 ms on localhost (executor driver) (138/200)
[INFO][2021-06-12 23:20:48,040][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 113 ms on localhost (executor driver) (139/200)
[INFO][2021-06-12 23:20:48,041][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,041][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,041][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,041][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-12 23:20:48,042][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,042][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 109 ms on localhost (executor driver) (140/200)
[INFO][2021-06-12 23:20:48,043][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-12 23:20:48,043][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 113 ms on localhost (executor driver) (141/200)
[INFO][2021-06-12 23:20:48,043][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 104 ms on localhost (executor driver) (142/200)
[INFO][2021-06-12 23:20:48,043][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 119 ms on localhost (executor driver) (143/200)
[INFO][2021-06-12 23:20:48,044][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 102 ms on localhost (executor driver) (144/200)
[INFO][2021-06-12 23:20:48,044][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 87 ms on localhost (executor driver) (145/200)
[INFO][2021-06-12 23:20:48,044][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,044][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,044][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,045][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2268 bytes result sent to driver
[INFO][2021-06-12 23:20:48,045][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,044][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 85 ms on localhost (executor driver) (146/200)
[INFO][2021-06-12 23:20:48,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,046][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 126 ms on localhost (executor driver) (147/200)
[INFO][2021-06-12 23:20:48,047][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 79 ms on localhost (executor driver) (148/200)
[INFO][2021-06-12 23:20:48,048][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 102 ms on localhost (executor driver) (149/200)
[INFO][2021-06-12 23:20:48,048][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:48,049][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,049][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 120 ms on localhost (executor driver) (150/200)
[INFO][2021-06-12 23:20:48,049][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-12 23:20:48,050][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 86 ms on localhost (executor driver) (151/200)
[INFO][2021-06-12 23:20:48,051][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 74 ms on localhost (executor driver) (152/200)
[INFO][2021-06-12 23:20:48,052][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-12 23:20:48,052][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2359 bytes result sent to driver
[INFO][2021-06-12 23:20:48,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 87 ms on localhost (executor driver) (153/200)
[INFO][2021-06-12 23:20:48,052][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 82 ms on localhost (executor driver) (154/200)
[INFO][2021-06-12 23:20:48,052][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,053][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 86 ms on localhost (executor driver) (155/200)
[INFO][2021-06-12 23:20:48,053][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:48,053][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,054][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,054][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 92 ms on localhost (executor driver) (156/200)
[INFO][2021-06-12 23:20:48,054][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-12 23:20:48,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 74 ms on localhost (executor driver) (157/200)
[INFO][2021-06-12 23:20:48,054][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,055][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,056][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-12 23:20:48,057][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,057][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,057][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,058][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-12 23:20:48,058][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,059][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,059][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,060][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,060][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-12 23:20:48,060][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-12 23:20:48,061][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,060][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-12 23:20:48,062][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,062][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,063][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,061][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2252 bytes result sent to driver
[INFO][2021-06-12 23:20:48,062][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-12 23:20:48,065][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,065][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,065][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,065][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,067][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-12 23:20:48,065][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,068][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:48,068][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,068][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,069][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,070][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,070][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2368 bytes result sent to driver
[INFO][2021-06-12 23:20:48,070][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,071][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-12 23:20:48,071][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,071][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 75 ms on localhost (executor driver) (158/200)
[INFO][2021-06-12 23:20:48,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 78 ms on localhost (executor driver) (159/200)
[INFO][2021-06-12 23:20:48,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 80 ms on localhost (executor driver) (160/200)
[INFO][2021-06-12 23:20:48,073][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 75 ms on localhost (executor driver) (161/200)
[INFO][2021-06-12 23:20:48,069][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-12 23:20:48,068][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,073][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 92 ms on localhost (executor driver) (162/200)
[INFO][2021-06-12 23:20:48,073][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,072][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:48,072][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-12 23:20:48,070][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-12 23:20:48,075][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2378 bytes result sent to driver
[INFO][2021-06-12 23:20:48,075][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:48,075][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 102 ms on localhost (executor driver) (163/200)
[INFO][2021-06-12 23:20:48,074][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2370 bytes result sent to driver
[INFO][2021-06-12 23:20:48,076][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 85 ms on localhost (executor driver) (164/200)
[INFO][2021-06-12 23:20:48,077][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,077][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 75 ms on localhost (executor driver) (165/200)
[INFO][2021-06-12 23:20:48,078][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:48,078][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 75 ms on localhost (executor driver) (166/200)
[INFO][2021-06-12 23:20:48,080][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 76 ms on localhost (executor driver) (167/200)
[INFO][2021-06-12 23:20:48,079][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,081][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-12 23:20:48,081][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,082][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,082][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2256 bytes result sent to driver
[INFO][2021-06-12 23:20:48,082][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,083][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-12 23:20:48,083][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,084][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,084][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,084][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-12 23:20:48,086][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,086][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-12 23:20:48,086][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2442 bytes result sent to driver
[INFO][2021-06-12 23:20:48,086][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,086][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,089][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-12 23:20:48,089][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,090][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,089][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2283 bytes result sent to driver
[INFO][2021-06-12 23:20:48,089][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,091][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-12 23:20:48,089][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,092][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,093][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-12 23:20:48,091][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2343 bytes result sent to driver
[INFO][2021-06-12 23:20:48,095][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:48,093][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,097][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,096][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,097][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-12 23:20:48,098][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-12 23:20:48,098][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,100][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2361 bytes result sent to driver
[INFO][2021-06-12 23:20:48,100][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2366 bytes result sent to driver
[INFO][2021-06-12 23:20:48,100][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,100][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-12 23:20:48,101][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,101][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,101][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-12 23:20:48,101][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-12 23:20:48,103][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,103][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,103][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-12 23:20:48,103][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2363 bytes result sent to driver
[INFO][2021-06-12 23:20:48,103][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,104][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,104][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,103][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 110 ms on localhost (executor driver) (168/200)
[INFO][2021-06-12 23:20:48,104][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 99 ms on localhost (executor driver) (169/200)
[INFO][2021-06-12 23:20:48,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 110 ms on localhost (executor driver) (170/200)
[INFO][2021-06-12 23:20:48,105][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2349 bytes result sent to driver
[INFO][2021-06-12 23:20:48,105][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-12 23:20:48,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 72 ms on localhost (executor driver) (171/200)
[INFO][2021-06-12 23:20:48,105][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-12 23:20:48,106][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 109 ms on localhost (executor driver) (172/200)
[INFO][2021-06-12 23:20:48,106][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 106 ms on localhost (executor driver) (173/200)
[INFO][2021-06-12 23:20:48,107][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2278 bytes result sent to driver
[INFO][2021-06-12 23:20:48,107][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 67 ms on localhost (executor driver) (174/200)
[INFO][2021-06-12 23:20:48,107][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 106 ms on localhost (executor driver) (175/200)
[INFO][2021-06-12 23:20:48,108][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 70 ms on localhost (executor driver) (176/200)
[INFO][2021-06-12 23:20:48,109][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 74 ms on localhost (executor driver) (177/200)
[INFO][2021-06-12 23:20:48,109][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2281 bytes result sent to driver
[INFO][2021-06-12 23:20:48,109][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 56 ms on localhost (executor driver) (178/200)
[INFO][2021-06-12 23:20:48,109][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2282 bytes result sent to driver
[INFO][2021-06-12 23:20:48,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 69 ms on localhost (executor driver) (179/200)
[INFO][2021-06-12 23:20:48,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 61 ms on localhost (executor driver) (180/200)
[INFO][2021-06-12 23:20:48,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 54 ms on localhost (executor driver) (181/200)
[INFO][2021-06-12 23:20:48,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 59 ms on localhost (executor driver) (182/200)
[INFO][2021-06-12 23:20:48,111][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 53 ms on localhost (executor driver) (183/200)
[INFO][2021-06-12 23:20:48,112][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 57 ms on localhost (executor driver) (184/200)
[INFO][2021-06-12 23:20:48,112][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 51 ms on localhost (executor driver) (185/200)
[INFO][2021-06-12 23:20:48,113][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2359 bytes result sent to driver
[INFO][2021-06-12 23:20:48,113][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 54 ms on localhost (executor driver) (186/200)
[INFO][2021-06-12 23:20:48,113][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 51 ms on localhost (executor driver) (187/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 49 ms on localhost (executor driver) (188/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 44 ms on localhost (executor driver) (189/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 46 ms on localhost (executor driver) (190/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 33 ms on localhost (executor driver) (191/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 43 ms on localhost (executor driver) (192/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 30 ms on localhost (executor driver) (193/200)
[INFO][2021-06-12 23:20:48,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 31 ms on localhost (executor driver) (194/200)
[INFO][2021-06-12 23:20:48,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 30 ms on localhost (executor driver) (195/200)
[INFO][2021-06-12 23:20:48,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 27 ms on localhost (executor driver) (196/200)
[INFO][2021-06-12 23:20:48,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 19 ms on localhost (executor driver) (197/200)
[INFO][2021-06-12 23:20:48,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 18 ms on localhost (executor driver) (198/200)
[INFO][2021-06-12 23:20:48,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 16 ms on localhost (executor driver) (199/200)
[INFO][2021-06-12 23:20:48,116][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 15 ms on localhost (executor driver) (200/200)
[INFO][2021-06-12 23:20:48,116][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:48,116][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.744 s
[INFO][2021-06-12 23:20:48,116][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 2.971625 s
[INFO][2021-06-12 23:20:48,152][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.0932 ms
[INFO][2021-06-12 23:20:48,170][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,175][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,176][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:55823 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,177][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-12 23:20:48,178][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,182][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,183][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:55823 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,184][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-12 23:20:48,184][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-12 23:20:48,187][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-12 23:20:48,223][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-12 23:20:48,228][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-12 23:20:48,229][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:55823 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,230][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:354
[INFO][2021-06-12 23:20:48,239][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-12 23:20:48,242][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-12 23:20:48,243][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:55823 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,244][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:323
[INFO][2021-06-12 23:20:48,441][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 23:20:48,450][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-12 23:20:48,450][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 23:20:48,592][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.5086 ms
[INFO][2021-06-12 23:20:48,602][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-12 23:20:48,602][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-12 23:20:48,603][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:20:48,603][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:20:48,603][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:20:48,603][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-12 23:20:48,616][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,619][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,619][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:55823 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,620][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:48,620][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:20:48,620][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-12 23:20:48,621][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:20:48,622][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-12 23:20:48,668][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:20:48,670][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2360 bytes result sent to driver
[INFO][2021-06-12 23:20:48,670][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 50 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:48,670][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:48,671][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.050 s
[INFO][2021-06-12 23:20:48,671][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.069101 s
[INFO][2021-06-12 23:20:48,710][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.8008 ms
[INFO][2021-06-12 23:20:48,721][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-12 23:20:48,774][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 23:20:48,778][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-12 23:20:48,778][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 23:20:48,850][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 24.3116 ms
[INFO][2021-06-12 23:20:48,867][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-12 23:20:48,868][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-12 23:20:48,868][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:20:48,868][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:20:48,868][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:20:48,868][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-12 23:20:48,869][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,871][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:48,872][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:55823 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:48,873][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:48,873][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:20:48,873][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-12 23:20:48,874][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:20:48,875][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-12 23:20:48,917][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:20:48,919][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2456 bytes result sent to driver
[INFO][2021-06-12 23:20:48,920][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 46 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:48,920][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:48,920][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.047 s
[INFO][2021-06-12 23:20:48,920][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.053371 s
[INFO][2021-06-12 23:20:48,925][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-12 23:20:48,959][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:48,959][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,960][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,960][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,960][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 23:20:48,961][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 23:20:48,961][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 23:20:48,962][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 23:20:48,963][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:20:48,963][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,964][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,964][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,965][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:48,965][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:48,965][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:48,966][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,966][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,966][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-12 23:20:48,967][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,967][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-12 23:20:48,968][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,968][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-12 23:20:48,969][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,970][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,970][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:48,971][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,971][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:48,988][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.9543 ms
[INFO][2021-06-12 23:20:48,991][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-12 23:20:49,001][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk from sparktxggl
[INFO][2021-06-12 23:20:49,024][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-12 23:20:49,027][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:137] -  
[INFO][2021-06-12 23:20:49,027][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-12 23:20:49,090][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.148 ms
[INFO][2021-06-12 23:20:49,096][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:138
[INFO][2021-06-12 23:20:49,097][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at DemoMoveFinfo.java:138) with 1 output partitions
[INFO][2021-06-12 23:20:49,097][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:20:49,097][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:20:49,098][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:20:49,098][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138), which has no missing parents
[INFO][2021-06-12 23:20:49,099][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 20.0 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:49,103][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:49,103][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.52.10:55823 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:49,103][org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:49,104][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:20:49,104][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
[INFO][2021-06-12 23:20:49,106][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:20:49,107][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 204)
[INFO][2021-06-12 23:20:49,149][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:20:49,151][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 204). 2287 bytes result sent to driver
[INFO][2021-06-12 23:20:49,151][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 204) in 47 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:49,151][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (show at DemoMoveFinfo.java:138) finished in 0.047 s
[INFO][2021-06-12 23:20:49,151][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:49,152][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at DemoMoveFinfo.java:138, took 0.055278 s
[INFO][2021-06-12 23:20:49,190][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4977
[INFO][2021-06-12 23:20:49,190][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4926
[INFO][2021-06-12 23:20:49,190][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4976
[INFO][2021-06-12 23:20:49,190][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4927
[INFO][2021-06-12 23:20:49,191][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.52.10:55823 in memory (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:49,193][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.52.10:55823 in memory (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:49,195][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.52.10:55823 in memory (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:49,198][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 24.5721 ms
[INFO][2021-06-12 23:20:49,200][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-12 23:20:49,208][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_txggl select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,JYS,SSBK from sparktxggl
[INFO][2021-06-12 23:20:49,239][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:20:49,239][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,240][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,240][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,241][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 23:20:49,241][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-12 23:20:49,241][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 23:20:49,241][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-12 23:20:49,241][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-12 23:20:49,242][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,243][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-12 23:20:49,244][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,244][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,244][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-12 23:20:49,244][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,245][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:20:49,429][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:20:49,503][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:20:49,504][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:20:49,535][org.apache.spark.SparkContext:54] - Starting job: sql at DemoMoveFinfo.java:145
[INFO][2021-06-12 23:20:49,536][org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (sql at DemoMoveFinfo.java:145) with 1 output partitions
[INFO][2021-06-12 23:20:49,536][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:20:49,536][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:20:49,536][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:20:49,536][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[26] at sql at DemoMoveFinfo.java:145), which has no missing parents
[INFO][2021-06-12 23:20:49,545][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 78.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:49,547][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 29.3 KB, free 3.8 GB)
[INFO][2021-06-12 23:20:49,548][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.52.10:55823 (size: 29.3 KB, free: 3.8 GB)
[INFO][2021-06-12 23:20:49,548][org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:20:49,549][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:20:49,549][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
[INFO][2021-06-12 23:20:49,549][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5816 bytes)
[INFO][2021-06-12 23:20:49,550][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 205)
[INFO][2021-06-12 23:20:49,557][org.apache.hadoop.conf.Configuration.deprecation:840] - mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
[INFO][2021-06-12 23:20:49,561][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-12 23:20:49,561][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
[INFO][2021-06-12 23:20:49,562][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-12 23:20:49,596][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:20:49,597][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:20:49,599][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:20:49,601][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-12 23:20:49,605][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-12 23:20:49,625][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "comment" : "ID",
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "gpdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "gpjc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "sgdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "fxzs",
    "type" : "decimal(16,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(16,2)"
    }
  }, {
    "name" : "wsfx",
    "type" : "decimal(16,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(16,2)"
    }
  }, {
    "name" : "dgsgsz",
    "type" : "decimal(12,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "??????",
      "HIVE_TYPE_STRING" : "decimal(12,2)"
    }
  }, {
    "name" : "sgsx",
    "type" : "decimal(12,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,2)"
    }
  }, {
    "name" : "sgzjsx",
    "type" : "decimal(9,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "??????",
      "HIVE_TYPE_STRING" : "decimal(9,4)"
    }
  }, {
    "name" : "fxj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "zxj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "srspj",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "sgrq",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "zqgbr",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "ssrq",
    "type" : "decimal(8,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(8,0)"
    }
  }, {
    "name" : "fxsyl",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "hysyl",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "zql",
    "type" : "decimal(7,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(7,4)"
    }
  }, {
    "name" : "mzyqy",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "?????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "djzj",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(7,2)"
    }
  }, {
    "name" : "xjljbjbs",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "psdxbjjs",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????????",
      "HIVE_TYPE_STRING" : "decimal(6,0)"
    }
  }, {
    "name" : "dxsy",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "lxyzbsl",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zzf",
    "type" : "decimal(9,2)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,2)"
    }
  }, {
    "name" : "jys",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "ssbk",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary gpdm (UTF8);
  optional binary gpjc (UTF8);
  optional binary sgdm (UTF8);
  optional fixed_len_byte_array(7) fxzs (DECIMAL(16,2));
  optional fixed_len_byte_array(7) wsfx (DECIMAL(16,2));
  optional fixed_len_byte_array(6) dgsgsz (DECIMAL(12,2));
  optional fixed_len_byte_array(6) sgsx (DECIMAL(12,2));
  optional fixed_len_byte_array(4) sgzjsx (DECIMAL(9,4));
  optional fixed_len_byte_array(4) fxj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) zxj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) srspj (DECIMAL(9,2));
  optional fixed_len_byte_array(4) sgrq (DECIMAL(8,0));
  optional fixed_len_byte_array(4) zqgbr (DECIMAL(8,0));
  optional fixed_len_byte_array(4) ssrq (DECIMAL(8,0));
  optional fixed_len_byte_array(4) fxsyl (DECIMAL(9,2));
  optional fixed_len_byte_array(4) hysyl (DECIMAL(9,2));
  optional fixed_len_byte_array(4) zql (DECIMAL(7,4));
  optional fixed_len_byte_array(4) mzyqy (DECIMAL(9,2));
  optional fixed_len_byte_array(4) djzj (DECIMAL(7,2));
  optional fixed_len_byte_array(4) xjljbjbs (DECIMAL(9,2));
  optional fixed_len_byte_array(3) psdxbjjs (DECIMAL(6,0));
  optional fixed_len_byte_array(4) dxsy (DECIMAL(9,2));
  optional binary lxyzbsl (UTF8);
  optional fixed_len_byte_array(4) zzf (DECIMAL(9,2));
  optional binary jys (UTF8);
  optional binary ssbk (UTF8);
}

       
[INFO][2021-06-12 23:20:49,662][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-12 23:20:49,939][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:20:49,940][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 578,143
[INFO][2021-06-12 23:20:50,043][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 11,077B for [id] INT32: 2,759 values, 11,043B raw, 11,039B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,043][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,945B for [gpdm] BINARY: 2,759 values, 27,597B raw, 10,903B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,044][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 26,546B for [gpjc] BINARY: 2,759 values, 42,578B raw, 26,494B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,045][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,910B for [sgdm] BINARY: 2,759 values, 27,571B raw, 10,874B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,045][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,873B for [fxzs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 19,320B raw, 9,829B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,045][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,730B for [wsfx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 19,320B raw, 10,686B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,046][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,111B for [dgsgsz] FIXED_LEN_BYTE_ARRAY: 2,759 values, 16,561B raw, 6,070B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,046][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,327B for [sgsx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 16,561B raw, 6,286B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,046][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,462B for [sgzjsx] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 10,424B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,047][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 8,956B for [fxj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 8,918B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,047][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,478B for [zxj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,440B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,047][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,798B for [srspj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,760B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,048][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,429B for [sgrq] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,392B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,048][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,407B for [zqgbr] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,370B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,049][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 6,516B for [ssrq] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 6,479B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,049][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,926B for [fxsyl] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,889B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,049][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,307B for [hysyl] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,270B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,049][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,132B for [zql] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,094B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,049][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 10,690B for [mzyqy] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 10,652B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,050][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 4,842B for [djzj] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 4,805B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,050][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 9,055B for [xjljbjbs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 9,017B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,050][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 5,429B for [psdxbjjs] FIXED_LEN_BYTE_ARRAY: 2,759 values, 8,284B raw, 5,394B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,051][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 4,084B for [dxsy] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 4,047B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,052][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 1,243B for [lxyzbsl] BINARY: 2,759 values, 1,216B raw, 1,214B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 28 entries, 157B raw, 28B comp}
[INFO][2021-06-12 23:20:50,053][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 7,786B for [zzf] FIXED_LEN_BYTE_ARRAY: 2,759 values, 11,043B raw, 7,749B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:20:50,053][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 727B for [jys] BINARY: 2,759 values, 695B raw, 697B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 3 entries, 15B raw, 3B comp}
[INFO][2021-06-12 23:20:50,054][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 1,081B for [ssbk] BINARY: 2,759 values, 1,045B raw, 1,050B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 7 entries, 44B raw, 7B comp}
[INFO][2021-06-12 23:20:50,291][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210612232049_0006_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/info_txggl/_temporary/0/task_20210612232049_0006_m_000000
[INFO][2021-06-12 23:20:50,291][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210612232049_0006_m_000000_0: Committed
[INFO][2021-06-12 23:20:50,294][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 205). 1427 bytes result sent to driver
[INFO][2021-06-12 23:20:50,296][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 205) in 747 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:20:50,296][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:20:50,296][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (sql at DemoMoveFinfo.java:145) finished in 0.747 s
[INFO][2021-06-12 23:20:50,297][org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: sql at DemoMoveFinfo.java:145, took 0.761893 s
[INFO][2021-06-12 23:20:50,322][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[INFO][2021-06-12 23:21:26,885][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:21:26,889][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-12 23:21:26,889][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:21:26,931][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.6136 ms
[INFO][2021-06-12 23:21:26,939][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-12 23:21:26,940][org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-12 23:21:26,940][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:21:26,941][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:21:26,941][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:21:26,941][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[31] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-12 23:21:26,943][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 10.7 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:26,947][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:26,947][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.52.10:55823 (size: 5.2 KB, free: 3.8 GB)
[INFO][2021-06-12 23:21:26,948][org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:21:26,948][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-12 23:21:26,949][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
[INFO][2021-06-12 23:21:26,950][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:21:26,951][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 206)
[INFO][2021-06-12 23:21:26,974][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:21:26,976][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 206). 2287 bytes result sent to driver
[INFO][2021-06-12 23:21:26,978][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 206) in 28 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:21:26,978][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (show at DemoMoveFinfo.java:130) finished in 0.029 s
[INFO][2021-06-12 23:21:26,978][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:21:26,979][org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at DemoMoveFinfo.java:130, took 0.038752 s
[INFO][2021-06-12 23:21:26,997][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.6927 ms
[INFO][2021-06-12 23:21:26,999][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,tranMarketCode(JYS) as JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-12 23:21:27,009][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:21:27,013][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-12 23:21:27,013][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:21:27,053][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.0554 ms
[INFO][2021-06-12 23:21:27,061][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-12 23:21:27,062][org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-12 23:21:27,062][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:21:27,062][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:21:27,062][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:21:27,062][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[35] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-12 23:21:27,064][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 15.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,067][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.0 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,068][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.52.10:55823 (size: 7.0 KB, free: 3.8 GB)
[INFO][2021-06-12 23:21:27,069][org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:21:27,069][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-12 23:21:27,069][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
[INFO][2021-06-12 23:21:27,071][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:21:27,071][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 207)
[INFO][2021-06-12 23:21:27,088][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:21:27,089][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 207). 2204 bytes result sent to driver
[INFO][2021-06-12 23:21:27,090][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 207) in 21 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:21:27,090][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (show at DemoMoveFinfo.java:134) finished in 0.021 s
[INFO][2021-06-12 23:21:27,090][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:21:27,090][org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: show at DemoMoveFinfo.java:134, took 0.028751 s
[INFO][2021-06-12 23:21:27,092][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_tzqdmbg
[INFO][2021-06-12 23:21:27,126][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,126][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,126][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,126][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,127][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-12 23:21:27,128][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:21:27,128][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,128][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:21:27,133][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg
[INFO][2021-06-12 23:21:27,138][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as string) as id,cast(jys as string) as jys,cast(zqdm as string) as zqdm,cast(zqmc as string) as zqmc,cast(zqlb as string) as zqlb,cast(bgdm as string) as bgdm,cast(bgmc as string) as bgmc,cast(blzh as decimal(12,9)) as blzh,cast(bgsm as string) as bgsm,cast(bglb as decimal(12,0)) as bglb,cast(bgrq as int) as bgrq,cast(whsj as string) as whsj,cast(zxj as decimal(9,4)) as zxj from sparktzqdmbg
[INFO][2021-06-12 23:21:27,146][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-12 23:21:27,150][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:137] -  
[INFO][2021-06-12 23:21:27,150][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-12 23:21:27,196][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.2403 ms
[INFO][2021-06-12 23:21:27,203][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:138
[INFO][2021-06-12 23:21:27,204][org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (show at DemoMoveFinfo.java:138) with 1 output partitions
[INFO][2021-06-12 23:21:27,204][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:21:27,204][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:21:27,205][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:21:27,206][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (MapPartitionsRDD[40] at show at DemoMoveFinfo.java:138), which has no missing parents
[INFO][2021-06-12 23:21:27,208][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 15.2 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,210][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,211][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.52.10:55823 (size: 7.1 KB, free: 3.8 GB)
[INFO][2021-06-12 23:21:27,212][org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:21:27,212][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at show at DemoMoveFinfo.java:138)
[INFO][2021-06-12 23:21:27,212][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
[INFO][2021-06-12 23:21:27,213][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-12 23:21:27,214][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 208)
[INFO][2021-06-12 23:21:27,231][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:21:27,232][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 208). 2204 bytes result sent to driver
[INFO][2021-06-12 23:21:27,233][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 208) in 21 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:21:27,233][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (show at DemoMoveFinfo.java:138) finished in 0.021 s
[INFO][2021-06-12 23:21:27,233][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:21:27,234][org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: show at DemoMoveFinfo.java:138, took 0.030541 s
[INFO][2021-06-12 23:21:27,251][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.3101 ms
[INFO][2021-06-12 23:21:27,253][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg
[INFO][2021-06-12 23:21:27,260][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_tzqdmbg select ID,JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-12 23:21:27,279][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,280][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,280][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,281][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,281][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,281][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,282][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,282][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-12 23:21:27,282][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,283][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-12 23:21:27,283][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-12 23:21:27,283][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-12 23:21:27,284][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-12 23:21:27,409][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:21:27,423][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:21:27,424][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:21:27,451][org.apache.spark.SparkContext:54] - Starting job: sql at DemoMoveFinfo.java:145
[INFO][2021-06-12 23:21:27,451][org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (sql at DemoMoveFinfo.java:145) with 1 output partitions
[INFO][2021-06-12 23:21:27,452][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:21:27,452][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-12 23:21:27,452][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-12 23:21:27,452][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[42] at sql at DemoMoveFinfo.java:145), which has no missing parents
[INFO][2021-06-12 23:21:27,465][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 69.4 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,467][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 27.1 KB, free 3.8 GB)
[INFO][2021-06-12 23:21:27,468][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.52.10:55823 (size: 27.1 KB, free: 3.8 GB)
[INFO][2021-06-12 23:21:27,469][org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-12 23:21:27,469][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at sql at DemoMoveFinfo.java:145)
[INFO][2021-06-12 23:21:27,469][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
[INFO][2021-06-12 23:21:27,471][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 5817 bytes)
[INFO][2021-06-12 23:21:27,471][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 209)
[INFO][2021-06-12 23:21:27,494][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:21:27,495][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-12 23:21:27,495][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:21:27,495][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-12 23:21:27,496][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-12 23:21:27,499][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : false,
    "metadata" : {
      "comment" : "ID",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "jys",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqlb",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "blzh",
    "type" : "decimal(12,9)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,9)"
    }
  }, {
    "name" : "bgsm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bglb",
    "type" : "decimal(12,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,0)"
    }
  }, {
    "name" : "bgrq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "whsj",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zxj",
    "type" : "decimal(9,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,4)"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required binary id (UTF8);
  optional binary jys (UTF8);
  optional binary zqdm (UTF8);
  optional binary zqmc (UTF8);
  optional binary zqlb (UTF8);
  optional binary bgdm (UTF8);
  optional binary bgmc (UTF8);
  optional fixed_len_byte_array(6) blzh (DECIMAL(12,9));
  optional binary bgsm (UTF8);
  optional fixed_len_byte_array(6) bglb (DECIMAL(12,0));
  optional int32 bgrq;
  optional binary whsj (UTF8);
  optional fixed_len_byte_array(4) zxj (DECIMAL(9,4));
}

       
[INFO][2021-06-12 23:21:27,503][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-12 23:21:27,508][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-12 23:21:27,508][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 8,140
[INFO][2021-06-12 23:21:27,512][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 220B for [id] BINARY: 47 values, 275B raw, 191B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
[INFO][2021-06-12 23:21:27,513][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 55B for [jys] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 5 entries, 25B raw, 5B comp}
[INFO][2021-06-12 23:21:27,513][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 359B for [zqdm] BINARY: 47 values, 466B raw, 320B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,513][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 93B for [zqmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 42 entries, 605B raw, 42B comp}
[INFO][2021-06-12 23:21:27,514][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 46B for [zqlb] BINARY: 47 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 2 entries, 12B raw, 2B comp}
[INFO][2021-06-12 23:21:27,514][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 280B for [bgdm] BINARY: 47 values, 467B raw, 241B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,514][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 84B for [bgmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 41 entries, 539B raw, 41B comp}
[INFO][2021-06-12 23:21:27,514][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 92B for [blzh] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 54B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,515][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 105B for [bgsm] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 7 entries, 172B raw, 7B comp}
[INFO][2021-06-12 23:21:27,515][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 81B for [bglb] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 43B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,515][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 214B for [bgrq] INT32: 47 values, 194B raw, 179B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,516][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 101B for [whsj] BINARY: 47 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 23 entries, 529B raw, 23B comp}
[INFO][2021-06-12 23:21:27,516][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 168B for [zxj] FIXED_LEN_BYTE_ARRAY: 47 values, 194B raw, 133B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-12 23:21:27,552][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210612232127_0010_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/info_tzqdmbg/_temporary/0/task_20210612232127_0010_m_000000
[INFO][2021-06-12 23:21:27,552][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210612232127_0010_m_000000_0: Committed
[INFO][2021-06-12 23:21:27,554][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 209). 1337 bytes result sent to driver
[INFO][2021-06-12 23:21:27,554][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 209) in 84 ms on localhost (executor driver) (1/1)
[INFO][2021-06-12 23:21:27,555][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO][2021-06-12 23:21:27,555][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (sql at DemoMoveFinfo.java:145) finished in 0.086 s
[INFO][2021-06-12 23:21:27,555][org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: sql at DemoMoveFinfo.java:145, took 0.104258 s
[INFO][2021-06-12 23:21:27,575][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[INFO][2021-06-12 23:21:28,466][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-12 23:21:28,473][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-12 23:21:28,476][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,477][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,477][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,477][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4207609e{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,478][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2f00f851{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,478][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,479][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,479][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,479][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17690e14{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,479][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@108a46d6{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@23a5818e{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,480][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,481][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,481][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,481][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,481][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,481][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@10afe71a{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,482][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,482][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,482][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,483][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-12 23:21:28,485][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-12 23:21:28,501][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-12 23:21:28,565][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-12 23:21:28,566][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-12 23:21:28,567][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-12 23:21:28,571][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-12 23:21:28,578][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-12 23:21:28,579][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-12 23:21:28,580][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-70440fed-5e9e-4c92-ad18-d144602a1300
