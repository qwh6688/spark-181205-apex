[INFO][2021-06-08 20:41:00,541][org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
[INFO][2021-06-08 20:41:00,916][org.apache.spark.SparkContext:54] - Submitted application: iDS-Spark::IdsRunner
[INFO][2021-06-08 20:41:00,934][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 20:41:00,934][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 20:41:00,935][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 20:41:00,935][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 20:41:00,936][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 20:41:02,123][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51990.
[INFO][2021-06-08 20:41:02,152][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 20:41:02,176][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 20:41:02,181][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 20:41:02,182][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 20:41:02,190][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-495ff1f3-aa01-403c-affe-e33d0b5369b4
[INFO][2021-06-08 20:41:02,204][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 20:41:02,240][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 20:41:02,303][org.spark_project.jetty.util.log:192] - Logging initialized @3491ms
[INFO][2021-06-08 20:41:02,352][org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
[INFO][2021-06-08 20:41:02,363][org.spark_project.jetty.server.Server:403] - Started @3552ms
[INFO][2021-06-08 20:41:02,383][org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@8828a70{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO][2021-06-08 20:41:02,384][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 20:41:02,404][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e094740{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,405][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@780ec4a5{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,405][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6f70f32f{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,406][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72c927f1{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,407][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3dd69f5a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,407][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1ee4730{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,408][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5003041b{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,409][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@23a9ba52{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,409][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@70ab80e3{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,410][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@67427b69{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,411][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@544630b7{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,412][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1095f122{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,413][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3d6300e8{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,413][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24a1c17f{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,414][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@73511076{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,415][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@532721fd{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,416][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7fb9f71f{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,417][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@51f49060{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,418][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@617fe9e1{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,418][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1cf2fed4{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,422][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,423][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@46ab18da{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,424][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42257bdd{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,425][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@70925b45{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,426][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@aa22f1c{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,428][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://10.168.88.20:4040
[INFO][2021-06-08 20:41:02,482][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 20:41:02,499][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52004.
[INFO][2021-06-08 20:41:02,500][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 10.168.88.20:52004
[INFO][2021-06-08 20:41:02,502][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 20:41:02,503][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 10.168.88.20, 52004, None)
[INFO][2021-06-08 20:41:02,505][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 10.168.88.20:52004 with 3.8 GB RAM, BlockManagerId(driver, 10.168.88.20, 52004, None)
[INFO][2021-06-08 20:41:02,508][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 10.168.88.20, 52004, None)
[INFO][2021-06-08 20:41:02,509][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 10.168.88.20, 52004, None)
[INFO][2021-06-08 20:41:02,655][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@33a630fa{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,690][org.apache.spark.sql.internal.SharedState:54] - loading hive config file: file:/D:/develop/IntelliJ%20IDEA%202019.1.2/ideaWorkspace/spark-181205/target/classes/hive-site.xml
[INFO][2021-06-08 20:41:02,707][org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('/user/hive/warehouse') to the value of spark.sql.warehouse.dir ('hdfs://node01:8020/user/hive/warehouse').
[INFO][2021-06-08 20:41:02,707][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://node01:8020/user/hive/warehouse'.
[INFO][2021-06-08 20:41:02,712][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4159e81b{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,713][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@23cd4ff2{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,714][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a94b64e{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,714][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@12477988{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:02,716][org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@d400943{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:41:03,211][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 20:41:03,709][hive.metastore:376] - Trying to connect to metastore with URI thrift://node01:9083
[INFO][2021-06-08 20:41:03,748][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 20:41:04,511][org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory:117] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 20:41:04,595][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/ec2f1eb8-9d13-4fa0-9632-e162b787851d_resources
[INFO][2021-06-08 20:41:04,602][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/ec2f1eb8-9d13-4fa0-9632-e162b787851d
[INFO][2021-06-08 20:41:04,606][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/ec2f1eb8-9d13-4fa0-9632-e162b787851d
[INFO][2021-06-08 20:41:04,610][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/ec2f1eb8-9d13-4fa0-9632-e162b787851d/_tmp_space.db
[INFO][2021-06-08 20:41:04,614][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://node01:8020/user/hive/warehouse
[INFO][2021-06-08 20:41:04,751][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/99e26cf3-b921-4c38-bc46-58271ec3f183_resources
[INFO][2021-06-08 20:41:04,754][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/99e26cf3-b921-4c38-bc46-58271ec3f183
[INFO][2021-06-08 20:41:04,757][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/99e26cf3-b921-4c38-bc46-58271ec3f183
[INFO][2021-06-08 20:41:04,761][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/99e26cf3-b921-4c38-bc46-58271ec3f183/_tmp_space.db
[INFO][2021-06-08 20:41:04,762][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://node01:8020/user/hive/warehouse
[INFO][2021-06-08 20:41:04,801][org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
[INFO][2021-06-08 20:41:04,807][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: myhive.parquet_test1
[INFO][2021-06-08 20:41:04,971][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:41:04,977][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:41:04,987][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: array<string>
[INFO][2021-06-08 20:41:05,107][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:41:05,107][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:41:05,216][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 20:41:05,221][org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@8828a70{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO][2021-06-08 20:41:05,223][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://10.168.88.20:4040
[INFO][2021-06-08 20:41:05,234][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 20:41:05,241][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 20:41:05,241][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 20:41:05,248][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 20:41:05,252][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 20:41:05,255][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 20:41:05,256][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 20:41:05,257][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-2f694954-a8fe-485a-82dc-fd06372f1b2c
[INFO][2021-06-08 20:43:59,923][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 20:44:00,218][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 20:44:00,221][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 20:44:00,222][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 20:44:00,223][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 20:44:00,224][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 20:44:01,504][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51998.
[INFO][2021-06-08 20:44:01,521][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 20:44:01,533][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 20:44:01,536][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 20:44:01,537][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 20:44:01,549][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-af6144ca-bef1-430b-9181-f2ff9c038de3
[INFO][2021-06-08 20:44:01,560][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 20:44:01,597][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 20:44:01,663][org.spark_project.jetty.util.log:186] - Logging initialized @3750ms
[INFO][2021-06-08 20:44:01,738][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 20:44:01,755][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@71b3bc45{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,755][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a8c1f44{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,755][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@150ab4ed{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,756][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3c435123{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,756][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@50fe837a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,756][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a62c01e{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,757][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8fa663{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,757][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ce33a58{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,758][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@78a287ed{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,758][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@546ccad7{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,758][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5357c287{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,759][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1623134f{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,759][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a527389{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,759][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@485a3466{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,760][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@25748410{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,760][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b43529a{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,760][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4264b240{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,760][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5b04476e{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,760][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ad10c1a{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,761][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6bb75258{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,765][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@c260bdc{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,765][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75e01201{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,766][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2783717b{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,766][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@76f7d241{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,767][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4a335fa8{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:01,773][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@74cadd41{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 20:44:01,773][org.spark_project.jetty.server.Server:379] - Started @3862ms
[INFO][2021-06-08 20:44:01,774][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 20:44:01,776][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://10.168.88.20:4040
[INFO][2021-06-08 20:44:01,838][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 20:44:01,887][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52039.
[INFO][2021-06-08 20:44:01,888][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 10.168.88.20:52039
[INFO][2021-06-08 20:44:01,890][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 20:44:01,892][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 10.168.88.20, 52039, None)
[INFO][2021-06-08 20:44:01,895][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 10.168.88.20:52039 with 3.8 GB RAM, BlockManagerId(driver, 10.168.88.20, 52039, None)
[INFO][2021-06-08 20:44:01,899][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 10.168.88.20, 52039, None)
[INFO][2021-06-08 20:44:01,899][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 10.168.88.20, 52039, None)
[INFO][2021-06-08 20:44:02,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5949eba8{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,070][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 20:44:02,074][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e53135d{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,075][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a7704c{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,075][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4acf72b6{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,076][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3301500b{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,077][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a45c42a{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:44:02,123][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 20:44:02,270][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 20:44:02,271][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 20:44:02,271][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 20:44:02,272][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 20:44:02,273][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 20:44:02,273][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 20:44:02,274][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 20:44:02,274][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 20:44:02,529][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 20:44:02,575][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 20:44:03,363][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 20:44:03,466][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/4a88e25b-3b11-429e-96e6-bd2643119efb_resources
[INFO][2021-06-08 20:44:03,478][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/4a88e25b-3b11-429e-96e6-bd2643119efb
[INFO][2021-06-08 20:44:03,486][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/4a88e25b-3b11-429e-96e6-bd2643119efb
[INFO][2021-06-08 20:44:03,492][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/4a88e25b-3b11-429e-96e6-bd2643119efb/_tmp_space.db
[INFO][2021-06-08 20:44:03,497][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 20:44:03,615][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.parquet_test1
[INFO][2021-06-08 20:44:04,306][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:44:04,317][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:44:06,357][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
[INFO][2021-06-08 20:44:06,360][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
[INFO][2021-06-08 20:44:06,361][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<id: int, name: string>
[INFO][2021-06-08 20:44:06,362][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pushed Filters: 
[INFO][2021-06-08 20:44:07,041][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 307.388 ms
[INFO][2021-06-08 20:44:07,187][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 145.9 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:07,535][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.5 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:07,540][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 10.168.88.20:52039 (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:07,545][org.apache.spark.SparkContext:54] - Created broadcast 0 from show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:44:07,566][org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO][2021-06-08 20:44:07,657][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:44:07,685][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (show at JavaParquetOverwrite.java:18) with 1 output partitions
[INFO][2021-06-08 20:44:07,686][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:44:07,687][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:44:07,689][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:44:07,699][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18), which has no missing parents
[INFO][2021-06-08 20:44:07,800][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:07,821][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:07,822][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 10.168.88.20:52039 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:07,824][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:44:07,830][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:44:07,833][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 20:44:07,925][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6496 bytes)
[INFO][2021-06-08 20:44:07,941][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 20:44:08,065][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:44:09,016][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:09,985][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,060][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1517 bytes result sent to driver
[INFO][2021-06-08 20:44:10,079][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 2201 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:44:10,080][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:44:10,085][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (show at JavaParquetOverwrite.java:18) finished in 2.228 s
[INFO][2021-06-08 20:44:10,091][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: show at JavaParquetOverwrite.java:18, took 2.432887 s
[INFO][2021-06-08 20:44:10,098][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:44:10,100][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at JavaParquetOverwrite.java:18) with 1 output partitions
[INFO][2021-06-08 20:44:10,100][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:44:10,100][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:44:10,100][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:44:10,101][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18), which has no missing parents
[INFO][2021-06-08 20:44:10,103][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,110][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,112][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 10.168.88.20:52039 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,113][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:44:10,114][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:44:10,114][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 20:44:10,116][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, ANY, 6503 bytes)
[INFO][2021-06-08 20:44:10,117][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 20:44:10,124][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0_copy_1, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:44:10,133][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,140][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,145][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1348 bytes result sent to driver
[INFO][2021-06-08 20:44:10,153][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:44:10,153][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:44:10,153][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at JavaParquetOverwrite.java:18) finished in 0.039 s
[INFO][2021-06-08 20:44:10,154][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at JavaParquetOverwrite.java:18, took 0.055597 s
[INFO][2021-06-08 20:44:10,181][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.6998 ms
[INFO][2021-06-08 20:44:10,202][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_bas.info_this_jjjz_etf
[INFO][2021-06-08 20:44:10,285][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:44:10,286][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:44:10,286][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:44:10,287][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:44:10,288][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-08 20:44:10,289][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,290][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:44:10,291][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:44:10,291][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:44:10,292][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,292][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,293][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:44:10,295][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,295][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,296][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:44:10,297][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,6)
[INFO][2021-06-08 20:44:10,298][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,3)
[INFO][2021-06-08 20:44:10,299][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:44:10,300][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:44:10,300][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:44:10,301][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:44:10,301][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:44:10,302][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:44:10,302][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,6)
[INFO][2021-06-08 20:44:10,303][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,6)
[INFO][2021-06-08 20:44:10,303][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 20:44:10,365][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
[INFO][2021-06-08 20:44:10,366][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 2
[INFO][2021-06-08 20:44:10,366][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 1
[INFO][2021-06-08 20:44:10,379][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:19
[INFO][2021-06-08 20:44:10,380][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at JavaParquetOverwrite.java:19) with 1 output partitions
[INFO][2021-06-08 20:44:10,380][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (show at JavaParquetOverwrite.java:19)
[INFO][2021-06-08 20:44:10,380][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:44:10,380][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:44:10,381][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[5] at show at JavaParquetOverwrite.java:19), which has no missing parents
[INFO][2021-06-08 20:44:10,384][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 10.168.88.20:52039 in memory (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,387][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 10.168.88.20:52039 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,389][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 10.168.88.20:52039 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,392][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,438][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,439][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 10.168.88.20:52039 (size: 2.6 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,439][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:44:10,439][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at show at JavaParquetOverwrite.java:19)
[INFO][2021-06-08 20:44:10,439][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
[INFO][2021-06-08 20:44:10,446][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7403 bytes)
[INFO][2021-06-08 20:44:10,447][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 20:44:10,480][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.3762 ms
[INFO][2021-06-08 20:44:10,485][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 1663 bytes result sent to driver
[INFO][2021-06-08 20:44:10,487][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 47 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:44:10,488][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:44:10,488][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (show at JavaParquetOverwrite.java:19) finished in 0.048 s
[INFO][2021-06-08 20:44:10,488][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at JavaParquetOverwrite.java:19, took 0.109675 s
[INFO][2021-06-08 20:44:10,499][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.3159 ms
[INFO][2021-06-08 20:44:10,501][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.parquet_test1
[INFO][2021-06-08 20:44:10,526][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:44:10,526][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:44:10,545][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
[INFO][2021-06-08 20:44:10,545][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
[INFO][2021-06-08 20:44:10,545][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<id: int, name: string>
[INFO][2021-06-08 20:44:10,546][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pushed Filters: 
[INFO][2021-06-08 20:44:10,570][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 145.9 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,578][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 16.5 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,580][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 10.168.88.20:52039 (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,580][org.apache.spark.SparkContext:54] - Created broadcast 4 from show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:44:10,581][org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO][2021-06-08 20:44:10,588][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:44:10,588][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at JavaParquetOverwrite.java:20) with 1 output partitions
[INFO][2021-06-08 20:44:10,589][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:44:10,589][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:44:10,589][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:44:10,589][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20), which has no missing parents
[INFO][2021-06-08 20:44:10,591][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,594][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,595][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 10.168.88.20:52039 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,596][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:44:10,596][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:44:10,596][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 20:44:10,598][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 6496 bytes)
[INFO][2021-06-08 20:44:10,598][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 3)
[INFO][2021-06-08 20:44:10,600][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:44:10,608][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,614][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,616][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 3). 1348 bytes result sent to driver
[INFO][2021-06-08 20:44:10,619][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:44:10,620][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:44:10,620][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at JavaParquetOverwrite.java:20) finished in 0.023 s
[INFO][2021-06-08 20:44:10,620][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at JavaParquetOverwrite.java:20, took 0.032408 s
[INFO][2021-06-08 20:44:10,622][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:44:10,622][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at JavaParquetOverwrite.java:20) with 1 output partitions
[INFO][2021-06-08 20:44:10,623][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:44:10,623][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:44:10,623][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:44:10,623][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20), which has no missing parents
[INFO][2021-06-08 20:44:10,624][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,627][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:44:10,628][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 10.168.88.20:52039 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:44:10,629][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:44:10,629][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:44:10,629][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 20:44:10,630][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 1, ANY, 6503 bytes)
[INFO][2021-06-08 20:44:10,630][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 4)
[INFO][2021-06-08 20:44:10,633][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0_copy_1, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:44:10,639][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,643][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:44:10,645][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 4). 1427 bytes result sent to driver
[INFO][2021-06-08 20:44:10,646][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:44:10,646][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:44:10,646][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at JavaParquetOverwrite.java:20) finished in 0.017 s
[INFO][2021-06-08 20:44:10,647][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at JavaParquetOverwrite.java:20, took 0.024634 s
[INFO][2021-06-08 20:44:10,650][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 20:44:10,653][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@74cadd41{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 20:44:10,654][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4a335fa8{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,655][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@76f7d241{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,655][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2783717b{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,655][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75e01201{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,655][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@c260bdc{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,655][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6bb75258{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,656][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ad10c1a{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,656][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5b04476e{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,656][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4264b240{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,657][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2b43529a{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,657][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@25748410{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,657][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@485a3466{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,658][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a527389{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,658][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1623134f{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5357c287{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@546ccad7{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@78a287ed{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ce33a58{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8fa663{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3a62c01e{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,659][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@50fe837a{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,660][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3c435123{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,660][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@150ab4ed{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,660][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a8c1f44{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,660][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@71b3bc45{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:44:10,661][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://10.168.88.20:4040
[INFO][2021-06-08 20:44:10,669][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 20:44:10,681][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 20:44:10,682][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 20:44:10,683][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 20:44:10,685][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 20:44:10,688][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 20:44:10,688][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 20:44:10,688][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-4d25f59e-e757-4f52-9289-b90428b3c626
[INFO][2021-06-08 20:45:12,058][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 20:45:12,349][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 20:45:12,352][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 20:45:12,352][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 20:45:12,353][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 20:45:12,353][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 20:45:13,517][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 61083.
[INFO][2021-06-08 20:45:13,557][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 20:45:13,590][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 20:45:13,595][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 20:45:13,596][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 20:45:13,618][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-0d4448a1-53fb-44dc-aca5-79b042fe37b7
[INFO][2021-06-08 20:45:13,643][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 20:45:13,726][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 20:45:13,862][org.spark_project.jetty.util.log:186] - Logging initialized @3482ms
[INFO][2021-06-08 20:45:13,978][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 20:45:14,004][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4c37b5b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,005][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@73db4768{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,005][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@71b3bc45{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,006][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a8c1f44{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,006][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@150ab4ed{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,006][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3c435123{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,007][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@50fe837a{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,008][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a62c01e{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,008][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8fa663{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,008][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ce33a58{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,009][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@78a287ed{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,009][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@546ccad7{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,010][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5357c287{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,010][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1623134f{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,011][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a527389{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,011][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@485a3466{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,011][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@25748410{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,012][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b43529a{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,012][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4264b240{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,013][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5b04476e{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,020][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ad10c1a{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,021][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6bb75258{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,021][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@c260bdc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,021][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75e01201{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,022][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2783717b{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,030][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@62fad19{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 20:45:14,031][org.spark_project.jetty.server.Server:379] - Started @3654ms
[INFO][2021-06-08 20:45:14,031][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 20:45:14,034][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://10.168.88.20:4040
[INFO][2021-06-08 20:45:14,095][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 20:45:14,123][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61125.
[INFO][2021-06-08 20:45:14,124][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 10.168.88.20:61125
[INFO][2021-06-08 20:45:14,126][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 20:45:14,128][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 10.168.88.20, 61125, None)
[INFO][2021-06-08 20:45:14,131][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 10.168.88.20:61125 with 3.8 GB RAM, BlockManagerId(driver, 10.168.88.20, 61125, None)
[INFO][2021-06-08 20:45:14,133][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 10.168.88.20, 61125, None)
[INFO][2021-06-08 20:45:14,134][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 10.168.88.20, 61125, None)
[INFO][2021-06-08 20:45:14,271][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@c074c0c{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,301][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 20:45:14,305][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6ca320ab{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,306][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e53135d{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,306][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@323e8306{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,307][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4acf72b6{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,308][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@57a4d5ee{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 20:45:14,350][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 20:45:14,468][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 20:45:14,468][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 20:45:14,469][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 20:45:14,469][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 20:45:14,469][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 20:45:14,470][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 20:45:14,470][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 20:45:14,470][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 20:45:14,666][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 20:45:14,697][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 20:45:15,398][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 20:45:15,476][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/5c6124af-dcc3-4476-ad5a-45991f33fcad_resources
[INFO][2021-06-08 20:45:15,484][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/5c6124af-dcc3-4476-ad5a-45991f33fcad
[INFO][2021-06-08 20:45:15,489][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/5c6124af-dcc3-4476-ad5a-45991f33fcad
[INFO][2021-06-08 20:45:15,492][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/5c6124af-dcc3-4476-ad5a-45991f33fcad/_tmp_space.db
[INFO][2021-06-08 20:45:15,495][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 20:45:15,579][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.parquet_test1
[INFO][2021-06-08 20:45:16,138][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:16,146][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:18,137][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
[INFO][2021-06-08 20:45:18,142][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
[INFO][2021-06-08 20:45:18,144][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<id: int, name: string>
[INFO][2021-06-08 20:45:18,145][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pushed Filters: 
[INFO][2021-06-08 20:45:18,892][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 356.6084 ms
[INFO][2021-06-08 20:45:19,060][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 145.9 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:19,221][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.5 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:19,224][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 10.168.88.20:61125 (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:19,227][org.apache.spark.SparkContext:54] - Created broadcast 0 from show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:45:19,237][org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO][2021-06-08 20:45:19,312][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:45:19,327][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (show at JavaParquetOverwrite.java:18) with 1 output partitions
[INFO][2021-06-08 20:45:19,328][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:45:19,328][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:19,330][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:19,335][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18), which has no missing parents
[INFO][2021-06-08 20:45:19,377][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:19,383][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:19,384][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 10.168.88.20:61125 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:19,384][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:19,387][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:45:19,388][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 20:45:19,426][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6496 bytes)
[INFO][2021-06-08 20:45:19,434][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 20:45:19,475][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:20,608][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:21,581][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:21,645][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1604 bytes result sent to driver
[INFO][2021-06-08 20:45:21,660][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 2255 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:45:21,661][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:21,666][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (show at JavaParquetOverwrite.java:18) finished in 2.270 s
[INFO][2021-06-08 20:45:21,672][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: show at JavaParquetOverwrite.java:18, took 2.359007 s
[INFO][2021-06-08 20:45:21,682][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:18
[INFO][2021-06-08 20:45:21,683][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at JavaParquetOverwrite.java:18) with 1 output partitions
[INFO][2021-06-08 20:45:21,683][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:45:21,683][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:21,684][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:21,684][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18), which has no missing parents
[INFO][2021-06-08 20:45:21,687][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:21,696][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:21,698][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 10.168.88.20:61125 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:21,698][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:21,699][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at show at JavaParquetOverwrite.java:18)
[INFO][2021-06-08 20:45:21,699][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 20:45:21,701][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, ANY, 6503 bytes)
[INFO][2021-06-08 20:45:21,702][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 20:45:21,706][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0_copy_1, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:21,716][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:21,723][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:21,729][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1517 bytes result sent to driver
[INFO][2021-06-08 20:45:21,758][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 59 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:45:21,759][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:21,759][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at JavaParquetOverwrite.java:18) finished in 0.060 s
[INFO][2021-06-08 20:45:21,760][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at JavaParquetOverwrite.java:18, took 0.077958 s
[INFO][2021-06-08 20:45:21,773][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 10.168.88.20:61125 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:21,781][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.5848 ms
[INFO][2021-06-08 20:45:21,796][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_bas.info_this_jjjz_etf
[INFO][2021-06-08 20:45:21,850][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:21,851][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:21,852][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:21,852][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:21,853][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-08 20:45:21,855][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,857][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:45:21,858][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:45:21,859][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:45:21,860][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,860][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,861][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:45:21,862][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,862][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,863][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:45:21,863][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,6)
[INFO][2021-06-08 20:45:21,864][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,3)
[INFO][2021-06-08 20:45:21,865][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:45:21,865][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:45:21,866][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:45:21,866][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 20:45:21,867][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,4)
[INFO][2021-06-08 20:45:21,867][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 20:45:21,868][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(10,6)
[INFO][2021-06-08 20:45:21,868][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,6)
[INFO][2021-06-08 20:45:21,869][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 20:45:21,910][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:19
[INFO][2021-06-08 20:45:21,911][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at JavaParquetOverwrite.java:19) with 1 output partitions
[INFO][2021-06-08 20:45:21,911][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (show at JavaParquetOverwrite.java:19)
[INFO][2021-06-08 20:45:21,911][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:21,911][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:21,912][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[5] at show at JavaParquetOverwrite.java:19), which has no missing parents
[INFO][2021-06-08 20:45:21,922][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:21,967][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:21,968][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 10.168.88.20:61125 (size: 2.6 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:21,969][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:21,969][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at show at JavaParquetOverwrite.java:19)
[INFO][2021-06-08 20:45:21,969][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
[INFO][2021-06-08 20:45:21,980][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7403 bytes)
[INFO][2021-06-08 20:45:21,982][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 20:45:22,038][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.6743 ms
[INFO][2021-06-08 20:45:22,045][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 1742 bytes result sent to driver
[INFO][2021-06-08 20:45:22,049][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 79 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:45:22,049][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:22,050][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (show at JavaParquetOverwrite.java:19) finished in 0.079 s
[INFO][2021-06-08 20:45:22,050][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at JavaParquetOverwrite.java:19, took 0.140138 s
[INFO][2021-06-08 20:45:22,062][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.8125 ms
[INFO][2021-06-08 20:45:22,064][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.parquet_test1
[INFO][2021-06-08 20:45:22,096][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:22,096][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:22,115][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
[INFO][2021-06-08 20:45:22,115][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
[INFO][2021-06-08 20:45:22,116][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<id: int, name: string>
[INFO][2021-06-08 20:45:22,116][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pushed Filters: 
[INFO][2021-06-08 20:45:22,143][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 145.9 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,156][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 16.5 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,158][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 10.168.88.20:61125 (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:22,159][org.apache.spark.SparkContext:54] - Created broadcast 4 from show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:45:22,160][org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO][2021-06-08 20:45:22,170][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:45:22,171][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at JavaParquetOverwrite.java:20) with 1 output partitions
[INFO][2021-06-08 20:45:22,172][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:45:22,172][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:22,172][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:22,172][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20), which has no missing parents
[INFO][2021-06-08 20:45:22,175][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,180][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,182][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 10.168.88.20:61125 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:22,182][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:22,182][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:45:22,182][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 20:45:22,184][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 6496 bytes)
[INFO][2021-06-08 20:45:22,184][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 3)
[INFO][2021-06-08 20:45:22,187][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:22,195][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,200][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,202][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 3). 1348 bytes result sent to driver
[INFO][2021-06-08 20:45:22,206][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 3) in 23 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:45:22,206][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:22,207][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at JavaParquetOverwrite.java:20) finished in 0.024 s
[INFO][2021-06-08 20:45:22,207][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at JavaParquetOverwrite.java:20, took 0.036145 s
[INFO][2021-06-08 20:45:22,211][org.apache.spark.SparkContext:54] - Starting job: show at JavaParquetOverwrite.java:20
[INFO][2021-06-08 20:45:22,211][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at JavaParquetOverwrite.java:20) with 1 output partitions
[INFO][2021-06-08 20:45:22,211][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:45:22,212][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:22,212][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:22,212][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20), which has no missing parents
[INFO][2021-06-08 20:45:22,214][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,219][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,220][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 10.168.88.20:61125 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:22,221][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:22,221][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[8] at show at JavaParquetOverwrite.java:20)
[INFO][2021-06-08 20:45:22,221][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 20:45:22,222][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 1, ANY, 6503 bytes)
[INFO][2021-06-08 20:45:22,223][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 4)
[INFO][2021-06-08 20:45:22,228][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0_copy_1, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:22,240][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,249][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,254][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 4). 1427 bytes result sent to driver
[INFO][2021-06-08 20:45:22,256][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 4) in 35 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 20:45:22,257][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:22,257][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at JavaParquetOverwrite.java:20) finished in 0.036 s
[INFO][2021-06-08 20:45:22,258][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at JavaParquetOverwrite.java:20, took 0.046991 s
[INFO][2021-06-08 20:45:22,261][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite  table myhive.parquet_test2 select id , name from myhive.parquet_test1
[INFO][2021-06-08 20:45:22,331][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:22,332][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:22,355][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 20:45:22,356][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 20:45:22,513][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,527][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
[INFO][2021-06-08 20:45:22,527][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
[INFO][2021-06-08 20:45:22,529][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<id: int, name: string>
[INFO][2021-06-08 20:45:22,529][org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pushed Filters: 
[INFO][2021-06-08 20:45:22,533][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 20:45:22,533][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 20:45:22,534][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 20:45:22,534][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 20:45:22,534][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 20:45:22,535][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,537][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,556][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.9405 ms
[INFO][2021-06-08 20:45:22,572][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 145.9 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,580][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.5 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,581][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 10.168.88.20:61125 (size: 16.5 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:22,582][org.apache.spark.SparkContext:54] - Created broadcast 7 from sql at JavaParquetOverwrite.java:21
[INFO][2021-06-08 20:45:22,582][org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO][2021-06-08 20:45:22,606][org.apache.spark.SparkContext:54] - Starting job: sql at JavaParquetOverwrite.java:21
[INFO][2021-06-08 20:45:22,607][org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (sql at JavaParquetOverwrite.java:21) with 2 output partitions
[INFO][2021-06-08 20:45:22,607][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (sql at JavaParquetOverwrite.java:21)
[INFO][2021-06-08 20:45:22,607][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 20:45:22,607][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 20:45:22,607][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[10] at sql at JavaParquetOverwrite.java:21), which has no missing parents
[INFO][2021-06-08 20:45:22,614][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 60.2 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,616][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.7 KB, free 3.8 GB)
[INFO][2021-06-08 20:45:22,618][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 10.168.88.20:61125 (size: 22.7 KB, free: 3.8 GB)
[INFO][2021-06-08 20:45:22,618][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 20:45:22,619][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at sql at JavaParquetOverwrite.java:21)
[INFO][2021-06-08 20:45:22,619][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 2 tasks
[INFO][2021-06-08 20:45:22,620][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, ANY, 6589 bytes)
[INFO][2021-06-08 20:45:22,621][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, ANY, 6596 bytes)
[INFO][2021-06-08 20:45:22,621][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 5)
[INFO][2021-06-08 20:45:22,622][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 5.0 (TID 6)
[INFO][2021-06-08 20:45:22,632][org.apache.hadoop.conf.Configuration.deprecation:840] - mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
[INFO][2021-06-08 20:45:22,634][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-08 20:45:22,634][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
[INFO][2021-06-08 20:45:22,635][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-08 20:45:22,641][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,646][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,647][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,648][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 20:45:22,649][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 20:45:22,649][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 20:45:22,651][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 20:45:22,651][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-08 20:45:22,653][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-08 20:45:22,654][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-08 20:45:22,655][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-08 20:45:22,661][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "HIVE_TYPE_STRING" : "string"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary name (UTF8);
}

       
[INFO][2021-06-08 20:45:22,661][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "HIVE_TYPE_STRING" : "string"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary name (UTF8);
}

       
[INFO][2021-06-08 20:45:22,683][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-08 20:45:22,683][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-08 20:45:22,722][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:22,722][org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test1/000000_0_copy_1, range: 0-309, partition values: [empty row]
[INFO][2021-06-08 20:45:22,731][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,732][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,737][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,740][org.apache.parquet.CorruptStatistics:151] - Ignoring statistics because this file was created prior to 1.8.0, see PARQUET-251
[INFO][2021-06-08 20:45:22,741][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 21
[INFO][2021-06-08 20:45:22,741][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 21
[INFO][2021-06-08 20:45:22,803][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 45B for [id] INT32: 1 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-08 20:45:22,803][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 45B for [id] INT32: 1 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-08 20:45:22,804][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 52B for [name] BINARY: 1 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-08 20:45:22,804][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 52B for [name] BINARY: 1 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN, RLE, BIT_PACKED]
[INFO][2021-06-08 20:45:22,903][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608204522_0005_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test2/_temporary/0/task_20210608204522_0005_m_000000
[INFO][2021-06-08 20:45:22,903][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608204522_0005_m_000001_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/parquet_test2/_temporary/0/task_20210608204522_0005_m_000001
[INFO][2021-06-08 20:45:22,904][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608204522_0005_m_000000_0: Committed
[INFO][2021-06-08 20:45:22,904][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608204522_0005_m_000001_0: Committed
[INFO][2021-06-08 20:45:22,907][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 5.0 (TID 6). 1684 bytes result sent to driver
[INFO][2021-06-08 20:45:22,907][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 5). 1507 bytes result sent to driver
[INFO][2021-06-08 20:45:22,911][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 5) in 292 ms on localhost (executor driver) (1/2)
[INFO][2021-06-08 20:45:22,911][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 5.0 (TID 6) in 291 ms on localhost (executor driver) (2/2)
[INFO][2021-06-08 20:45:22,912][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 20:45:22,913][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (sql at JavaParquetOverwrite.java:21) finished in 0.293 s
[INFO][2021-06-08 20:45:22,913][org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: sql at JavaParquetOverwrite.java:21, took 0.307298 s
[INFO][2021-06-08 20:45:22,940][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[INFO][2021-06-08 20:45:22,950][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 20:45:22,953][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@62fad19{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2783717b{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75e01201{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@c260bdc{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6bb75258{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ad10c1a{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,955][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5b04476e{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,956][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4264b240{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,956][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2b43529a{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,956][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@25748410{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,956][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@485a3466{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,957][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a527389{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,957][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1623134f{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,957][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5357c287{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,957][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@546ccad7{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,958][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@78a287ed{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,958][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ce33a58{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,958][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8fa663{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,958][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3a62c01e{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,958][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@50fe837a{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3c435123{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@150ab4ed{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a8c1f44{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@71b3bc45{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@73db4768{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,959][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4c37b5b{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 20:45:22,961][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://10.168.88.20:4040
[INFO][2021-06-08 20:45:22,970][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 20:45:22,988][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 20:45:22,988][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 20:45:22,990][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 20:45:22,992][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 20:45:22,994][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 20:45:22,995][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 20:45:22,996][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-1eb516fe-ed72-4c87-9743-6de5eca5b0d1
[INFO][2021-06-08 21:17:32,093][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:17:32,393][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:17:32,396][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:17:32,396][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:17:32,397][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:17:32,398][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:17:33,703][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 64152.
[INFO][2021-06-08 21:17:33,720][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:17:33,734][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:17:33,736][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:17:33,737][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:17:33,745][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-afae8307-8a56-4e1d-8132-75c025daf469
[INFO][2021-06-08 21:17:33,769][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:17:33,844][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:17:33,896][org.spark_project.jetty.util.log:186] - Logging initialized @4316ms
[INFO][2021-06-08 21:17:33,972][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:17:33,984][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4c37b5b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,984][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@73db4768{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@71b3bc45{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a8c1f44{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@150ab4ed{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3c435123{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@50fe837a{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,985][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a62c01e{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,986][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8fa663{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,986][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ce33a58{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,986][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@78a287ed{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,986][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@546ccad7{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,986][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5357c287{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,987][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1623134f{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,987][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a527389{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,987][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@485a3466{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,988][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@25748410{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,988][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b43529a{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,988][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4264b240{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,989][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5b04476e{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,993][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ad10c1a{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,993][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6bb75258{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,994][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@c260bdc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,994][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75e01201{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:33,994][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2783717b{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,000][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@62fad19{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:17:34,000][org.spark_project.jetty.server.Server:379] - Started @4421ms
[INFO][2021-06-08 21:17:34,001][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:17:34,003][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:17:34,056][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:17:34,086][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64193.
[INFO][2021-06-08 21:17:34,086][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:64193
[INFO][2021-06-08 21:17:34,088][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:17:34,089][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 64193, None)
[INFO][2021-06-08 21:17:34,092][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:64193 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 64193, None)
[INFO][2021-06-08 21:17:34,096][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 64193, None)
[INFO][2021-06-08 21:17:34,097][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 64193, None)
[INFO][2021-06-08 21:17:34,239][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@c074c0c{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,269][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:17:34,274][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e53135d{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,274][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a7704c{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,275][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4acf72b6{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,276][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3301500b{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,277][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3a45c42a{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:17:34,326][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:17:34,447][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:17:34,448][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:17:34,448][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:17:34,448][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:17:34,449][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:17:34,449][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:17:34,449][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:17:34,450][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:17:34,654][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:17:34,682][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:17:35,610][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:17:35,699][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/eac4baf3-3844-40d2-9be2-036474f49f66_resources
[INFO][2021-06-08 21:17:35,706][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/eac4baf3-3844-40d2-9be2-036474f49f66
[INFO][2021-06-08 21:17:35,710][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/eac4baf3-3844-40d2-9be2-036474f49f66
[INFO][2021-06-08 21:17:35,714][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/eac4baf3-3844-40d2-9be2-036474f49f66/_tmp_space.db
[INFO][2021-06-08 21:17:35,717][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:17:35,801][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.kwang_test
[INFO][2021-06-08 21:17:36,402][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:17:36,410][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:17:37,605][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparkKwangTest
[INFO][2021-06-08 21:17:37,861][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparkKwangTest
[INFO][2021-06-08 21:17:38,249][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:38,517][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:38,519][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:64193 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:38,525][org.apache.spark.SparkContext:54] - Created broadcast 0 from show at SparkOverwrite.java:16
[INFO][2021-06-08 21:17:38,768][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 2
[INFO][2021-06-08 21:17:38,789][org.apache.spark.SparkContext:54] - Starting job: show at SparkOverwrite.java:16
[INFO][2021-06-08 21:17:38,817][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (show at SparkOverwrite.java:16) with 1 output partitions
[INFO][2021-06-08 21:17:38,818][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:17:38,819][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:17:38,822][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:17:38,835][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16), which has no missing parents
[INFO][2021-06-08 21:17:38,881][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:38,892][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:38,892][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:64193 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:38,894][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:17:38,898][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:17:38,901][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:17:38,963][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 5961 bytes)
[INFO][2021-06-08 21:17:38,978][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:17:39,060][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0:0+8
[INFO][2021-06-08 21:17:39,073][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:17:39,074][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:17:39,074][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:17:39,075][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:17:39,075][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:17:39,496][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 301.151499 ms
[INFO][2021-06-08 21:17:40,503][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1332 bytes result sent to driver
[INFO][2021-06-08 21:17:40,520][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 1594 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:17:40,521][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:17:40,526][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (show at SparkOverwrite.java:16) finished in 1.617 s
[INFO][2021-06-08 21:17:40,532][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: show at SparkOverwrite.java:16, took 1.742881 s
[INFO][2021-06-08 21:17:40,542][org.apache.spark.SparkContext:54] - Starting job: show at SparkOverwrite.java:16
[INFO][2021-06-08 21:17:40,543][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at SparkOverwrite.java:16) with 1 output partitions
[INFO][2021-06-08 21:17:40,543][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:17:40,544][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:17:40,544][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:17:40,545][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16), which has no missing parents
[INFO][2021-06-08 21:17:40,546][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,552][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,596][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:64193 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:40,597][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:17:40,597][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:17:40,597][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:17:40,599][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, ANY, 5968 bytes)
[INFO][2021-06-08 21:17:40,599][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:17:40,606][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0_copy_1:0+8
[INFO][2021-06-08 21:17:40,617][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1163 bytes result sent to driver
[INFO][2021-06-08 21:17:40,621][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:17:40,621][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:17:40,621][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at SparkOverwrite.java:16) finished in 0.023 s
[INFO][2021-06-08 21:17:40,621][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at SparkOverwrite.java:16, took 0.078644 s
[INFO][2021-06-08 21:17:40,646][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.472801 ms
[INFO][2021-06-08 21:17:40,669][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite  table myhive.kwang_test_2 select id , name from sparkKwangTest
[INFO][2021-06-08 21:17:40,718][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:17:40,719][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:17:40,768][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 140.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,782][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,783][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:64193 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:40,784][org.apache.spark.SparkContext:54] - Created broadcast 3 from sql at SparkOverwrite.java:17
[INFO][2021-06-08 21:17:40,802][org.apache.hadoop.hive.common.FileUtils:501] - Creating directory if it doesn't exist: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-17-40_798_3302525573322728275-1
[INFO][2021-06-08 21:17:40,872][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 2
[INFO][2021-06-08 21:17:40,885][org.apache.spark.SparkContext:54] - Starting job: sql at SparkOverwrite.java:17
[INFO][2021-06-08 21:17:40,886][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (sql at SparkOverwrite.java:17) with 2 output partitions
[INFO][2021-06-08 21:17:40,886][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (sql at SparkOverwrite.java:17)
[INFO][2021-06-08 21:17:40,886][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:17:40,886][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:17:40,887][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[9] at sql at SparkOverwrite.java:17), which has no missing parents
[INFO][2021-06-08 21:17:40,897][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 58.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,920][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:17:40,921][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:64193 (size: 22.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:40,923][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:17:40,924][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sql at SparkOverwrite.java:17)
[INFO][2021-06-08 21:17:40,925][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
[INFO][2021-06-08 21:17:40,927][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6028 bytes)
[INFO][2021-06-08 21:17:40,929][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 6035 bytes)
[INFO][2021-06-08 21:17:40,929][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:17:40,930][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:17:40,946][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-08 21:17:40,948][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-08 21:17:40,948][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:64193 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:40,949][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
[INFO][2021-06-08 21:17:40,950][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0:0+8
[INFO][2021-06-08 21:17:40,952][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0_copy_1:0+8
[INFO][2021-06-08 21:17:40,955][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
[INFO][2021-06-08 21:17:40,958][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.52.10:64193 in memory (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:40,960][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:64193 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:17:41,928][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608211740_0002_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-17-40_798_3302525573322728275-1/-ext-10000/_temporary/0/task_20210608211740_0002_m_000000
[INFO][2021-06-08 21:17:41,928][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608211740_0002_m_000001_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-17-40_798_3302525573322728275-1/-ext-10000/_temporary/0/task_20210608211740_0002_m_000001
[INFO][2021-06-08 21:17:41,929][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608211740_0002_m_000001_0: Committed
[INFO][2021-06-08 21:17:41,929][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608211740_0002_m_000000_0: Committed
[INFO][2021-06-08 21:17:41,931][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 1255 bytes result sent to driver
[INFO][2021-06-08 21:17:41,931][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 1255 bytes result sent to driver
[INFO][2021-06-08 21:17:41,934][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 1006 ms on localhost (executor driver) (1/2)
[INFO][2021-06-08 21:17:41,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 1009 ms on localhost (executor driver) (2/2)
[INFO][2021-06-08 21:17:41,935][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:17:41,935][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (sql at SparkOverwrite.java:17) finished in 1.009 s
[INFO][2021-06-08 21:17:41,936][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: sql at SparkOverwrite.java:17, took 1.050861 s
[INFO][2021-06-08 21:17:42,057][hive.ql.metadata.Hive:2641] - Replacing src:hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-17-40_798_3302525573322728275-1/-ext-10000/part-00000, dest: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00000, Status:true
[INFO][2021-06-08 21:17:42,098][hive.ql.metadata.Hive:2641] - Replacing src:hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-17-40_798_3302525573322728275-1/-ext-10000/part-00001, dest: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00001, Status:true
[INFO][2021-06-08 21:17:42,431][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: `myhive`.`kwang_test_2`
[INFO][2021-06-08 21:17:42,541][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:17:42,542][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:17:42,559][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 21:17:42,567][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@62fad19{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:17:42,571][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2783717b{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,572][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75e01201{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,572][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@c260bdc{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,573][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6bb75258{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,573][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ad10c1a{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,573][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5b04476e{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,574][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4264b240{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,575][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2b43529a{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,575][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@25748410{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,576][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@485a3466{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,576][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a527389{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,577][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1623134f{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,577][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5357c287{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,578][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@546ccad7{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,578][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@78a287ed{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,579][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ce33a58{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,579][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8fa663{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,580][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3a62c01e{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,580][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@50fe837a{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,581][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3c435123{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,581][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@150ab4ed{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,581][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a8c1f44{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,582][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@71b3bc45{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,582][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@73db4768{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,583][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4c37b5b{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:17:42,586][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-08 21:17:42,606][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 21:17:42,632][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 21:17:42,633][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 21:17:42,636][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 21:17:42,641][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 21:17:42,647][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 21:17:42,648][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 21:17:42,650][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-31b56ee3-6ac3-4806-afa7-eb196180b3ba
[INFO][2021-06-08 21:21:00,804][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:21:01,171][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:21:01,175][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:21:01,175][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:21:01,176][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:21:01,177][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:21:02,637][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 59264.
[INFO][2021-06-08 21:21:02,660][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:21:02,680][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:21:02,683][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:21:02,683][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:21:02,696][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-f9748928-2913-408b-9cf8-08c71b0423dd
[INFO][2021-06-08 21:21:02,716][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:21:02,753][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:21:02,820][org.spark_project.jetty.util.log:186] - Logging initialized @4780ms
[INFO][2021-06-08 21:21:02,921][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:21:02,936][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@49c8f6e8{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,936][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6b0615ae{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,936][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4e73b552{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,936][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@221dad51{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,937][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2cec704c{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,937][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@771cbb1a{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,937][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2416498e{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,937][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6b2e0f78{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,937][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@240f6c41{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,938][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3659d7b1{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,938][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2015b2cd{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,938][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3bdb2c78{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,938][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@64693226{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,938][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1c758545{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@117bcfdc{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@73a19967{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5e746d37{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6e1b9411{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@21d1b321{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,939][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ec46cdd{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,943][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2324bfe7{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,944][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@112d1c8e{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,944][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3d49fd31{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,944][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4016ccc1{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,944][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@46cb98a3{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:02,951][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@6642dc5a{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:21:02,952][org.spark_project.jetty.server.Server:379] - Started @4912ms
[INFO][2021-06-08 21:21:02,952][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:21:02,956][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:21:03,030][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:21:03,071][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56687.
[INFO][2021-06-08 21:21:03,071][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:56687
[INFO][2021-06-08 21:21:03,073][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:21:03,075][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 56687, None)
[INFO][2021-06-08 21:21:03,078][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:56687 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 56687, None)
[INFO][2021-06-08 21:21:03,083][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 56687, None)
[INFO][2021-06-08 21:21:03,084][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 56687, None)
[INFO][2021-06-08 21:21:03,245][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@68b9834c{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,280][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:21:03,285][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3b920bdc{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,286][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@72fd8a3c{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,287][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1ab5f08a{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,287][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@79a04e5f{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,289][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@574a89e2{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:03,352][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:21:03,478][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:21:03,478][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:21:03,479][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:21:03,479][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:21:03,479][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:21:03,480][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:21:03,480][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:21:03,480][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:21:03,685][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:21:03,726][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:21:04,679][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:21:04,873][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/9bbb4871-30b1-46db-8c5c-d5e6909179cd_resources
[INFO][2021-06-08 21:21:04,891][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/9bbb4871-30b1-46db-8c5c-d5e6909179cd
[INFO][2021-06-08 21:21:04,940][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/9bbb4871-30b1-46db-8c5c-d5e6909179cd
[INFO][2021-06-08 21:21:04,944][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/9bbb4871-30b1-46db-8c5c-d5e6909179cd/_tmp_space.db
[INFO][2021-06-08 21:21:04,951][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:21:05,112][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from myhive.kwang_test
[INFO][2021-06-08 21:21:05,824][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:05,830][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:07,260][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparkKwangTest
[INFO][2021-06-08 21:21:07,582][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparkKwangTest
[INFO][2021-06-08 21:21:07,914][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:08,119][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:08,165][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:56687 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:08,172][org.apache.spark.SparkContext:54] - Created broadcast 0 from show at SparkOverwrite.java:16
[INFO][2021-06-08 21:21:08,404][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 2
[INFO][2021-06-08 21:21:08,426][org.apache.spark.SparkContext:54] - Starting job: show at SparkOverwrite.java:16
[INFO][2021-06-08 21:21:08,446][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (show at SparkOverwrite.java:16) with 1 output partitions
[INFO][2021-06-08 21:21:08,447][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:21:08,447][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:08,448][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:08,458][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16), which has no missing parents
[INFO][2021-06-08 21:21:08,518][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:08,530][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:08,531][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:56687 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:08,532][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:08,536][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:21:08,537][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:21:08,583][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 5961 bytes)
[INFO][2021-06-08 21:21:08,596][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:21:08,634][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0:0+8
[INFO][2021-06-08 21:21:08,647][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:21:08,647][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:21:08,648][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:21:08,648][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:21:08,648][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:21:08,926][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 212.039 ms
[INFO][2021-06-08 21:21:09,700][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1332 bytes result sent to driver
[INFO][2021-06-08 21:21:09,712][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 1150 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:09,713][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:09,715][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (show at SparkOverwrite.java:16) finished in 1.168 s
[INFO][2021-06-08 21:21:09,720][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: show at SparkOverwrite.java:16, took 1.293693 s
[INFO][2021-06-08 21:21:09,727][org.apache.spark.SparkContext:54] - Starting job: show at SparkOverwrite.java:16
[INFO][2021-06-08 21:21:09,728][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at SparkOverwrite.java:16) with 1 output partitions
[INFO][2021-06-08 21:21:09,728][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:21:09,728][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:09,729][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:09,729][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16), which has no missing parents
[INFO][2021-06-08 21:21:09,732][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:09,737][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:09,738][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:56687 (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:09,739][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:09,739][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkOverwrite.java:16)
[INFO][2021-06-08 21:21:09,740][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:21:09,741][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, ANY, 5968 bytes)
[INFO][2021-06-08 21:21:09,742][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:21:09,747][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0_copy_1:0+8
[INFO][2021-06-08 21:21:09,756][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1163 bytes result sent to driver
[INFO][2021-06-08 21:21:09,760][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 20 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:09,761][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:09,761][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at SparkOverwrite.java:16) finished in 0.021 s
[INFO][2021-06-08 21:21:09,761][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at SparkOverwrite.java:16, took 0.033954 s
[INFO][2021-06-08 21:21:09,781][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.4805 ms
[INFO][2021-06-08 21:21:09,797][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite  table myhive.kwang_test_2 select id , name from sparkKwangTest
[INFO][2021-06-08 21:21:09,844][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:09,845][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:09,909][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 140.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:09,985][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:09,986][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:56687 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:09,990][org.apache.spark.SparkContext:54] - Created broadcast 3 from sql at SparkOverwrite.java:17
[INFO][2021-06-08 21:21:10,018][org.apache.hadoop.hive.common.FileUtils:501] - Creating directory if it doesn't exist: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-21-10_012_5970243955739560689-1
[INFO][2021-06-08 21:21:10,021][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:56687 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:10,026][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
[INFO][2021-06-08 21:21:10,027][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:56687 in memory (size: 4.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:10,029][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.52.10:56687 in memory (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:10,096][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 2
[INFO][2021-06-08 21:21:10,111][org.apache.spark.SparkContext:54] - Starting job: sql at SparkOverwrite.java:17
[INFO][2021-06-08 21:21:10,112][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (sql at SparkOverwrite.java:17) with 2 output partitions
[INFO][2021-06-08 21:21:10,112][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (sql at SparkOverwrite.java:17)
[INFO][2021-06-08 21:21:10,112][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:10,112][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:10,113][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[9] at sql at SparkOverwrite.java:17), which has no missing parents
[INFO][2021-06-08 21:21:10,126][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 58.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:10,132][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:10,134][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:56687 (size: 22.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:10,134][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:10,135][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sql at SparkOverwrite.java:17)
[INFO][2021-06-08 21:21:10,135][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
[INFO][2021-06-08 21:21:10,137][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6028 bytes)
[INFO][2021-06-08 21:21:10,139][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 6035 bytes)
[INFO][2021-06-08 21:21:10,139][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:21:10,140][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:21:10,157][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-08 21:21:10,158][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-08 21:21:10,160][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
[INFO][2021-06-08 21:21:10,161][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0:0+8
[INFO][2021-06-08 21:21:10,161][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test/000000_0_copy_1:0+8
[INFO][2021-06-08 21:21:11,094][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608212110_0002_m_000001_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-21-10_012_5970243955739560689-1/-ext-10000/_temporary/0/task_20210608212110_0002_m_000001
[INFO][2021-06-08 21:21:11,094][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608212110_0002_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-21-10_012_5970243955739560689-1/-ext-10000/_temporary/0/task_20210608212110_0002_m_000000
[INFO][2021-06-08 21:21:11,095][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608212110_0002_m_000001_0: Committed
[INFO][2021-06-08 21:21:11,095][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608212110_0002_m_000000_0: Committed
[INFO][2021-06-08 21:21:11,099][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 1255 bytes result sent to driver
[INFO][2021-06-08 21:21:11,100][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 1255 bytes result sent to driver
[INFO][2021-06-08 21:21:11,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 969 ms on localhost (executor driver) (1/2)
[INFO][2021-06-08 21:21:11,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 968 ms on localhost (executor driver) (2/2)
[INFO][2021-06-08 21:21:11,105][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:11,105][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (sql at SparkOverwrite.java:17) finished in 0.970 s
[INFO][2021-06-08 21:21:11,106][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: sql at SparkOverwrite.java:17, took 0.994065 s
[INFO][2021-06-08 21:21:11,176][org.apache.hadoop.hive.common.FileUtils:600] - deleting  hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00000
[INFO][2021-06-08 21:21:11,180][org.apache.hadoop.fs.TrashPolicyDefault:92] - Namenode trash configuration: Deletion interval = 604800000 minutes, Emptier interval = 0 minutes.
[INFO][2021-06-08 21:21:11,187][org.apache.hadoop.hive.common.FileUtils:604] - Moved to trash: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00000
[INFO][2021-06-08 21:21:11,187][org.apache.hadoop.hive.common.FileUtils:600] - deleting  hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00001
[INFO][2021-06-08 21:21:11,189][org.apache.hadoop.fs.TrashPolicyDefault:92] - Namenode trash configuration: Deletion interval = 604800000 minutes, Emptier interval = 0 minutes.
[INFO][2021-06-08 21:21:11,195][org.apache.hadoop.hive.common.FileUtils:604] - Moved to trash: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00001
[INFO][2021-06-08 21:21:11,206][hive.ql.metadata.Hive:2641] - Replacing src:hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-21-10_012_5970243955739560689-1/-ext-10000/part-00000, dest: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00000, Status:true
[INFO][2021-06-08 21:21:11,249][hive.ql.metadata.Hive:2641] - Replacing src:hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/.hive-staging_hive_2021-06-08_21-21-10_012_5970243955739560689-1/-ext-10000/part-00001, dest: hdfs://node01:8020/user/hive/warehouse/myhive.db/kwang_test_2/part-00001, Status:true
[INFO][2021-06-08 21:21:11,433][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: `myhive`.`kwang_test_2`
[INFO][2021-06-08 21:21:11,537][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:11,538][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:11,547][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 21:21:11,551][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@6642dc5a{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:21:11,554][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@46cb98a3{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,554][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4016ccc1{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,555][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3d49fd31{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,555][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@112d1c8e{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,555][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2324bfe7{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,555][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ec46cdd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,556][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@21d1b321{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,556][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6e1b9411{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,556][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5e746d37{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,556][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@73a19967{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,556][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@117bcfdc{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1c758545{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@64693226{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3bdb2c78{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2015b2cd{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3659d7b1{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@240f6c41{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,557][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6b2e0f78{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2416498e{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@771cbb1a{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2cec704c{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@221dad51{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4e73b552{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6b0615ae{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,558][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@49c8f6e8{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:11,560][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-08 21:21:11,570][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 21:21:11,582][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 21:21:11,583][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 21:21:11,585][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 21:21:11,587][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 21:21:11,591][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 21:21:11,591][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 21:21:11,592][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-129c2448-d8dd-4e17-b88b-0d9f483e5196
[INFO][2021-06-08 21:21:44,008][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:21:44,187][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:21:44,188][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:21:44,188][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:21:44,188][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:21:44,189][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:21:45,247][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 65390.
[INFO][2021-06-08 21:21:45,265][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:21:45,278][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:21:45,281][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:21:45,282][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:21:45,293][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-4a603c2e-cae8-4e76-951f-2d6d1e1a8387
[INFO][2021-06-08 21:21:45,306][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:21:45,335][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:21:45,396][org.spark_project.jetty.util.log:186] - Logging initialized @3828ms
[INFO][2021-06-08 21:21:45,476][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:21:45,492][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@46c670a6{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,493][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@59fc684e{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,493][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ae81e1{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,493][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,493][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5ae76500{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,494][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6063d80a{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,495][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1133ec6e{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,495][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,495][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,496][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,496][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@24f360b2{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,497][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,497][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,497][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,498][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@48c40605{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,498][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,499][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,499][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,499][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,500][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,505][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,506][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,506][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@21ec5d87{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,507][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,507][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,514][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@660e9100{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:21:45,515][org.spark_project.jetty.server.Server:379] - Started @3948ms
[INFO][2021-06-08 21:21:45,516][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:21:45,519][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:21:45,576][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:21:45,603][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65431.
[INFO][2021-06-08 21:21:45,604][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:65431
[INFO][2021-06-08 21:21:45,605][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:21:45,607][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 65431, None)
[INFO][2021-06-08 21:21:45,609][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:65431 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 65431, None)
[INFO][2021-06-08 21:21:45,612][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 65431, None)
[INFO][2021-06-08 21:21:45,613][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 65431, None)
[INFO][2021-06-08 21:21:45,762][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@62315f22{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,798][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:21:45,804][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@779dfe55{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,805][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1144a55a{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,806][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@3cc20577{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,807][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,809][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@241a0c3a{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:21:45,876][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:21:46,001][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:21:46,005][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:21:46,006][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:21:46,006][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:21:46,007][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:21:46,007][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:21:46,008][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:21:46,008][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:21:46,229][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:21:46,256][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:21:46,964][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:21:47,031][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/6f73f91d-6f84-4f45-ab98-71ffec0fd0c6_resources
[INFO][2021-06-08 21:21:47,037][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/6f73f91d-6f84-4f45-ab98-71ffec0fd0c6
[INFO][2021-06-08 21:21:47,042][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/6f73f91d-6f84-4f45-ab98-71ffec0fd0c6
[INFO][2021-06-08 21:21:47,045][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/6f73f91d-6f84-4f45-ab98-71ffec0fd0c6/_tmp_space.db
[INFO][2021-06-08 21:21:47,048][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:21:47,136][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-08 21:21:47,798][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,801][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,801][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-08 21:21:47,802][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-08 21:21:47,802][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,803][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,803][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,803][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:47,803][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:49,515][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:49,760][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:49,763][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:65431 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:49,770][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:21:50,322][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 296.345801 ms
[INFO][2021-06-08 21:21:50,447][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.3644 ms
[INFO][2021-06-08 21:21:50,511][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-08 21:21:50,561][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:21:50,583][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-08 21:21:50,584][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:50,584][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:50,586][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:50,594][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:21:50,612][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:50,629][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:50,630][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:65431 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:50,631][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:50,636][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:50,638][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:21:50,703][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-08 21:21:50,714][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:21:50,766][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:21:50,771][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:21:50,772][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:21:50,772][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:21:50,772][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:21:50,772][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:21:50,817][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.380901 ms
[INFO][2021-06-08 21:21:51,664][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155603 bytes result sent to driver
[INFO][2021-06-08 21:21:51,710][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 1036 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:51,711][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:51,716][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 1.060 s
[INFO][2021-06-08 21:21:51,719][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 1.157993 s
[INFO][2021-06-08 21:21:51,835][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:21:51,839][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:51,839][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-08 21:21:51,840][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:51,840][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:21:51,840][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:21:51,841][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:21:51,853][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:51,858][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:51,859][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:65431 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:51,860][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:51,862][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:51,862][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:21:51,864][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-08 21:21:51,865][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:21:51,883][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:21:52,132][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:65431 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:52,397][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1921 bytes result sent to driver
[INFO][2021-06-08 21:21:52,402][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 539 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:52,402][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:52,403][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 0.540 s
[INFO][2021-06-08 21:21:52,404][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-08 21:21:52,404][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-08 21:21:52,405][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-08 21:21:52,405][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-08 21:21:52,408][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:21:52,428][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:52,431][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:52,432][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:65431 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:52,433][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:52,434][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:21:52,434][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-08 21:21:52,437][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,438][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,439][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,440][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,441][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,442][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,442][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,443][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,444][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,446][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,447][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,448][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,448][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,449][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,450][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,450][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,451][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:21:52,451][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:21:52,452][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-08 21:21:52,452][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-08 21:21:52,459][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-08 21:21:52,460][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-08 21:21:52,460][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-08 21:21:52,460][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-08 21:21:52,459][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-08 21:21:52,463][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-08 21:21:52,474][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-08 21:21:52,474][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-08 21:21:52,477][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-08 21:21:52,477][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-08 21:21:52,477][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-08 21:21:52,490][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,493][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,495][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-08 21:21:52,495][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,493][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,495][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:21:52,499][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,500][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:21:52,498][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,502][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:52,503][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,505][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,506][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:21:52,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:21:52,504][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,504][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,507][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,504][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,508][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:52,504][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,510][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:21:52,507][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,536][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.1891 ms
[INFO][2021-06-08 21:21:52,565][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2445 bytes result sent to driver
[INFO][2021-06-08 21:21:52,566][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2277 bytes result sent to driver
[INFO][2021-06-08 21:21:52,567][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:52,567][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2283 bytes result sent to driver
[INFO][2021-06-08 21:21:52,568][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,566][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,568][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:52,569][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2317 bytes result sent to driver
[INFO][2021-06-08 21:21:52,571][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,572][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,573][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2425 bytes result sent to driver
[INFO][2021-06-08 21:21:52,573][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2348 bytes result sent to driver
[INFO][2021-06-08 21:21:52,573][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,575][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:52,575][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-08 21:21:52,576][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2343 bytes result sent to driver
[INFO][2021-06-08 21:21:52,576][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2450 bytes result sent to driver
[INFO][2021-06-08 21:21:52,576][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,578][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2364 bytes result sent to driver
[INFO][2021-06-08 21:21:52,578][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,579][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,578][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-08 21:21:52,579][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,580][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-08 21:21:52,582][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,583][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,584][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,584][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,585][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,586][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,587][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-08 21:21:52,587][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,586][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-08 21:21:52,589][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,589][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-08 21:21:52,590][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,590][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,590][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,592][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,592][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,589][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2343 bytes result sent to driver
[INFO][2021-06-08 21:21:52,594][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-08 21:21:52,590][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,596][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,596][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:52,597][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-08 21:21:52,594][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-08 21:21:52,597][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-08 21:21:52,597][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,596][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2269 bytes result sent to driver
[INFO][2021-06-08 21:21:52,598][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-08 21:21:52,599][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,599][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2365 bytes result sent to driver
[INFO][2021-06-08 21:21:52,599][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-08 21:21:52,600][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,600][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,600][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,603][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,605][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,605][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,605][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,606][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-08 21:21:52,602][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,607][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:21:52,605][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,609][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:21:52,610][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-08 21:21:52,610][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-08 21:21:52,611][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,612][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,613][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,613][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,613][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,614][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,615][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,616][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2374 bytes result sent to driver
[INFO][2021-06-08 21:21:52,617][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-08 21:21:52,617][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-08 21:21:52,618][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:52,619][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-08 21:21:52,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,624][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,609][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,632][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 23 ms
[INFO][2021-06-08 21:21:52,634][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:52,635][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,635][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,631][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,637][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:21:52,639][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,639][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2332 bytes result sent to driver
[INFO][2021-06-08 21:21:52,628][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-08 21:21:52,648][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,648][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 29 ms
[INFO][2021-06-08 21:21:52,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,619][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-08 21:21:52,610][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-08 21:21:52,609][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,657][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 48 ms
[INFO][2021-06-08 21:21:52,658][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,659][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,657][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,661][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:52,662][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,656][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,663][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:52,648][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,639][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 185 ms on localhost (executor driver) (1/200)
[INFO][2021-06-08 21:21:52,665][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 219 ms on localhost (executor driver) (2/200)
[INFO][2021-06-08 21:21:52,664][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2363 bytes result sent to driver
[INFO][2021-06-08 21:21:52,660][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2464 bytes result sent to driver
[INFO][2021-06-08 21:21:52,670][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2369 bytes result sent to driver
[INFO][2021-06-08 21:21:52,669][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2363 bytes result sent to driver
[INFO][2021-06-08 21:21:52,667][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,673][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2419 bytes result sent to driver
[INFO][2021-06-08 21:21:52,675][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,676][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,676][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-08 21:21:52,677][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-08 21:21:52,678][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 242 ms on localhost (executor driver) (3/200)
[INFO][2021-06-08 21:21:52,679][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,679][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,679][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 234 ms on localhost (executor driver) (4/200)
[INFO][2021-06-08 21:21:52,680][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 232 ms on localhost (executor driver) (5/200)
[INFO][2021-06-08 21:21:52,680][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,680][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,679][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:52,681][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 241 ms on localhost (executor driver) (6/200)
[INFO][2021-06-08 21:21:52,681][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 240 ms on localhost (executor driver) (7/200)
[INFO][2021-06-08 21:21:52,682][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 243 ms on localhost (executor driver) (8/200)
[INFO][2021-06-08 21:21:52,682][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 240 ms on localhost (executor driver) (9/200)
[INFO][2021-06-08 21:21:52,683][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,684][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-08 21:21:52,685][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,685][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2263 bytes result sent to driver
[INFO][2021-06-08 21:21:52,685][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-08 21:21:52,686][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 236 ms on localhost (executor driver) (10/200)
[INFO][2021-06-08 21:21:52,686][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 249 ms on localhost (executor driver) (11/200)
[INFO][2021-06-08 21:21:52,687][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 239 ms on localhost (executor driver) (12/200)
[INFO][2021-06-08 21:21:52,687][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 238 ms on localhost (executor driver) (13/200)
[INFO][2021-06-08 21:21:52,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,687][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 109 ms on localhost (executor driver) (14/200)
[INFO][2021-06-08 21:21:52,688][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,689][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 101 ms on localhost (executor driver) (15/200)
[INFO][2021-06-08 21:21:52,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,691][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,692][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-08 21:21:52,692][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,694][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:52,694][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-08 21:21:52,694][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,695][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 109 ms on localhost (executor driver) (16/200)
[INFO][2021-06-08 21:21:52,695][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-08 21:21:52,695][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 122 ms on localhost (executor driver) (17/200)
[INFO][2021-06-08 21:21:52,696][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 253 ms on localhost (executor driver) (18/200)
[INFO][2021-06-08 21:21:52,696][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,699][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,699][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,700][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,698][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2375 bytes result sent to driver
[INFO][2021-06-08 21:21:52,698][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 257 ms on localhost (executor driver) (19/200)
[INFO][2021-06-08 21:21:52,699][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,700][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 250 ms on localhost (executor driver) (20/200)
[INFO][2021-06-08 21:21:52,700][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,701][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 112 ms on localhost (executor driver) (21/200)
[INFO][2021-06-08 21:21:52,702][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 123 ms on localhost (executor driver) (22/200)
[INFO][2021-06-08 21:21:52,703][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,703][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-08 21:21:52,704][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,705][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:52,705][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,705][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-08 21:21:52,706][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,709][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-08 21:21:52,708][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-08 21:21:52,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,710][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,710][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,711][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-08 21:21:52,710][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,712][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,713][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,714][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,714][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,714][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,714][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,715][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-08 21:21:52,715][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-08 21:21:52,714][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,716][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,716][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,716][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,716][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-08 21:21:52,717][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 142 ms on localhost (executor driver) (23/200)
[INFO][2021-06-08 21:21:52,717][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-08 21:21:52,717][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 121 ms on localhost (executor driver) (24/200)
[INFO][2021-06-08 21:21:52,717][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2255 bytes result sent to driver
[INFO][2021-06-08 21:21:52,718][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2375 bytes result sent to driver
[INFO][2021-06-08 21:21:52,718][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 104 ms on localhost (executor driver) (25/200)
[INFO][2021-06-08 21:21:52,718][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 119 ms on localhost (executor driver) (26/200)
[INFO][2021-06-08 21:21:52,719][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 121 ms on localhost (executor driver) (27/200)
[INFO][2021-06-08 21:21:52,719][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 113 ms on localhost (executor driver) (28/200)
[INFO][2021-06-08 21:21:52,720][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 115 ms on localhost (executor driver) (29/200)
[INFO][2021-06-08 21:21:52,721][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 106 ms on localhost (executor driver) (30/200)
[INFO][2021-06-08 21:21:52,722][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 110 ms on localhost (executor driver) (31/200)
[INFO][2021-06-08 21:21:52,722][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 119 ms on localhost (executor driver) (32/200)
[INFO][2021-06-08 21:21:52,723][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,723][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,720][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:52,723][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 119 ms on localhost (executor driver) (33/200)
[INFO][2021-06-08 21:21:52,722][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,722][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,721][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:52,725][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,724][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,725][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,726][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,725][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,727][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,727][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-08 21:21:52,727][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-08 21:21:52,728][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,729][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-08 21:21:52,727][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:52,732][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,733][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,729][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,734][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,734][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,734][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 121 ms on localhost (executor driver) (34/200)
[INFO][2021-06-08 21:21:52,733][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,735][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-08 21:21:52,735][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,737][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-08 21:21:52,737][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,738][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,739][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,739][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-08 21:21:52,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:52,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,741][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-08 21:21:52,739][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2356 bytes result sent to driver
[INFO][2021-06-08 21:21:52,742][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2447 bytes result sent to driver
[INFO][2021-06-08 21:21:52,742][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2265 bytes result sent to driver
[INFO][2021-06-08 21:21:52,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,740][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,743][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,746][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2450 bytes result sent to driver
[INFO][2021-06-08 21:21:52,742][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-08 21:21:52,748][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2375 bytes result sent to driver
[INFO][2021-06-08 21:21:52,744][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-08 21:21:52,751][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,751][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,752][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,753][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2345 bytes result sent to driver
[INFO][2021-06-08 21:21:52,753][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,754][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2263 bytes result sent to driver
[INFO][2021-06-08 21:21:52,755][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-08 21:21:52,753][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,755][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,756][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,757][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,758][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,759][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,759][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-08 21:21:52,760][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,760][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-08 21:21:52,760][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-08 21:21:52,761][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-08 21:21:52,762][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,765][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2259 bytes result sent to driver
[INFO][2021-06-08 21:21:52,765][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,765][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,760][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,766][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,767][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,767][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-08 21:21:52,767][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,767][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,768][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,768][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,769][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-08 21:21:52,769][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2285 bytes result sent to driver
[INFO][2021-06-08 21:21:52,770][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-08 21:21:52,771][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,771][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,771][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2355 bytes result sent to driver
[INFO][2021-06-08 21:21:52,773][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2273 bytes result sent to driver
[INFO][2021-06-08 21:21:52,770][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,773][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,773][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,774][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-08 21:21:52,774][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,774][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,774][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,775][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 188 ms on localhost (executor driver) (35/200)
[INFO][2021-06-08 21:21:52,775][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,774][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:52,775][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 185 ms on localhost (executor driver) (36/200)
[INFO][2021-06-08 21:21:52,775][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-08 21:21:52,776][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 93 ms on localhost (executor driver) (37/200)
[INFO][2021-06-08 21:21:52,777][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 103 ms on localhost (executor driver) (38/200)
[INFO][2021-06-08 21:21:52,777][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 87 ms on localhost (executor driver) (39/200)
[INFO][2021-06-08 21:21:52,778][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,778][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,778][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 85 ms on localhost (executor driver) (40/200)
[INFO][2021-06-08 21:21:52,779][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 112 ms on localhost (executor driver) (41/200)
[INFO][2021-06-08 21:21:52,779][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,780][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2262 bytes result sent to driver
[INFO][2021-06-08 21:21:52,780][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 184 ms on localhost (executor driver) (42/200)
[INFO][2021-06-08 21:21:52,780][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,780][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 78 ms on localhost (executor driver) (43/200)
[INFO][2021-06-08 21:21:52,781][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,781][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,781][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 89 ms on localhost (executor driver) (44/200)
[INFO][2021-06-08 21:21:52,781][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2291 bytes result sent to driver
[INFO][2021-06-08 21:21:52,782][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,783][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-08 21:21:52,783][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,784][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-08 21:21:52,785][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,786][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,786][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-08 21:21:52,787][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,787][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,787][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,785][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2279 bytes result sent to driver
[INFO][2021-06-08 21:21:52,787][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,786][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,788][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-08 21:21:52,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,789][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,790][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-08 21:21:52,790][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,791][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 83 ms on localhost (executor driver) (45/200)
[INFO][2021-06-08 21:21:52,791][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-08 21:21:52,791][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 86 ms on localhost (executor driver) (46/200)
[INFO][2021-06-08 21:21:52,792][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 80 ms on localhost (executor driver) (47/200)
[INFO][2021-06-08 21:21:52,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,792][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:52,793][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 77 ms on localhost (executor driver) (48/200)
[INFO][2021-06-08 21:21:52,793][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2355 bytes result sent to driver
[INFO][2021-06-08 21:21:52,794][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 110 ms on localhost (executor driver) (49/200)
[INFO][2021-06-08 21:21:52,794][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 68 ms on localhost (executor driver) (50/200)
[INFO][2021-06-08 21:21:52,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,795][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,795][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,796][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 92 ms on localhost (executor driver) (51/200)
[INFO][2021-06-08 21:21:52,796][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 93 ms on localhost (executor driver) (52/200)
[INFO][2021-06-08 21:21:52,796][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-08 21:21:52,797][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 84 ms on localhost (executor driver) (53/200)
[INFO][2021-06-08 21:21:52,797][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 60 ms on localhost (executor driver) (54/200)
[INFO][2021-06-08 21:21:52,798][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 71 ms on localhost (executor driver) (55/200)
[INFO][2021-06-08 21:21:52,798][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 84 ms on localhost (executor driver) (56/200)
[INFO][2021-06-08 21:21:52,799][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 75 ms on localhost (executor driver) (57/200)
[INFO][2021-06-08 21:21:52,799][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2282 bytes result sent to driver
[INFO][2021-06-08 21:21:52,799][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 50 ms on localhost (executor driver) (58/200)
[INFO][2021-06-08 21:21:52,800][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,801][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,801][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 67 ms on localhost (executor driver) (59/200)
[INFO][2021-06-08 21:21:52,802][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-08 21:21:52,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 47 ms on localhost (executor driver) (60/200)
[INFO][2021-06-08 21:21:52,802][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:52,803][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 64 ms on localhost (executor driver) (61/200)
[INFO][2021-06-08 21:21:52,803][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 74 ms on localhost (executor driver) (62/200)
[INFO][2021-06-08 21:21:52,803][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 67 ms on localhost (executor driver) (63/200)
[INFO][2021-06-08 21:21:52,804][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 65 ms on localhost (executor driver) (64/200)
[INFO][2021-06-08 21:21:52,804][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,805][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,805][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,805][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-08 21:21:52,805][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 47 ms on localhost (executor driver) (65/200)
[INFO][2021-06-08 21:21:52,805][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,806][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,807][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-08 21:21:52,807][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 48 ms on localhost (executor driver) (66/200)
[INFO][2021-06-08 21:21:52,808][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2372 bytes result sent to driver
[INFO][2021-06-08 21:21:52,808][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,808][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-08 21:21:52,809][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,809][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,809][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,810][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,812][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2253 bytes result sent to driver
[INFO][2021-06-08 21:21:52,812][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-08 21:21:52,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,813][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,813][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-08 21:21:52,817][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,819][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,819][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,820][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,820][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,821][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,820][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,820][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-08 21:21:52,822][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-08 21:21:52,823][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,825][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,826][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,826][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,828][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,828][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,828][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2275 bytes result sent to driver
[INFO][2021-06-08 21:21:52,821][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:21:52,829][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-08 21:21:52,832][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-08 21:21:52,833][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,834][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,834][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2338 bytes result sent to driver
[INFO][2021-06-08 21:21:52,835][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,836][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 75 ms on localhost (executor driver) (67/200)
[INFO][2021-06-08 21:21:52,836][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-08 21:21:52,822][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2285 bytes result sent to driver
[INFO][2021-06-08 21:21:52,837][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,836][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 62 ms on localhost (executor driver) (68/200)
[INFO][2021-06-08 21:21:52,835][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2364 bytes result sent to driver
[INFO][2021-06-08 21:21:52,834][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-08 21:21:52,834][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-08 21:21:52,833][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,837][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,838][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:21:52,838][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,838][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,841][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,840][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,842][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,842][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-08 21:21:52,841][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,842][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,841][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-08 21:21:52,841][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,842][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,847][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,847][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-08 21:21:52,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,848][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-08 21:21:52,848][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:52,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,849][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,849][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-08 21:21:52,850][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,850][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2355 bytes result sent to driver
[INFO][2021-06-08 21:21:52,850][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,851][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,851][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,851][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,852][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,853][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,853][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-08 21:21:52,853][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,854][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,854][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:52,855][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,856][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2260 bytes result sent to driver
[INFO][2021-06-08 21:21:52,856][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,857][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-08 21:21:52,857][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,858][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,859][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-08 21:21:52,859][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-08 21:21:52,860][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:52,860][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,860][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,854][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-08 21:21:52,859][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2462 bytes result sent to driver
[INFO][2021-06-08 21:21:52,859][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,858][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,856][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-08 21:21:52,861][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-08 21:21:52,863][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2381 bytes result sent to driver
[INFO][2021-06-08 21:21:52,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,866][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,866][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,867][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,868][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2256 bytes result sent to driver
[INFO][2021-06-08 21:21:52,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,869][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:52,870][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2265 bytes result sent to driver
[INFO][2021-06-08 21:21:52,865][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,870][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:21:52,871][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,872][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,868][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2364 bytes result sent to driver
[INFO][2021-06-08 21:21:52,865][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,874][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 106 ms on localhost (executor driver) (69/200)
[INFO][2021-06-08 21:21:52,875][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2372 bytes result sent to driver
[INFO][2021-06-08 21:21:52,874][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,875][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 118 ms on localhost (executor driver) (70/200)
[INFO][2021-06-08 21:21:52,871][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2359 bytes result sent to driver
[INFO][2021-06-08 21:21:52,876][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 94 ms on localhost (executor driver) (71/200)
[INFO][2021-06-08 21:21:52,874][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-08 21:21:52,877][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 109 ms on localhost (executor driver) (72/200)
[INFO][2021-06-08 21:21:52,877][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2285 bytes result sent to driver
[INFO][2021-06-08 21:21:52,877][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 89 ms on localhost (executor driver) (73/200)
[INFO][2021-06-08 21:21:52,877][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-08 21:21:52,878][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 94 ms on localhost (executor driver) (74/200)
[INFO][2021-06-08 21:21:52,879][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,880][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,880][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,881][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-08 21:21:52,881][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 112 ms on localhost (executor driver) (75/200)
[INFO][2021-06-08 21:21:52,881][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 91 ms on localhost (executor driver) (76/200)
[INFO][2021-06-08 21:21:52,882][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 95 ms on localhost (executor driver) (77/200)
[INFO][2021-06-08 21:21:52,883][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,884][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-08 21:21:52,884][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,884][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,884][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,885][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:52,885][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-08 21:21:52,885][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 85 ms on localhost (executor driver) (78/200)
[INFO][2021-06-08 21:21:52,885][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 101 ms on localhost (executor driver) (79/200)
[INFO][2021-06-08 21:21:52,886][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 78 ms on localhost (executor driver) (80/200)
[INFO][2021-06-08 21:21:52,886][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 82 ms on localhost (executor driver) (81/200)
[INFO][2021-06-08 21:21:52,887][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 79 ms on localhost (executor driver) (82/200)
[INFO][2021-06-08 21:21:52,886][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,887][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,887][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 92 ms on localhost (executor driver) (83/200)
[INFO][2021-06-08 21:21:52,888][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 78 ms on localhost (executor driver) (84/200)
[INFO][2021-06-08 21:21:52,888][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,888][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 82 ms on localhost (executor driver) (85/200)
[INFO][2021-06-08 21:21:52,889][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,890][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,891][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2263 bytes result sent to driver
[INFO][2021-06-08 21:21:52,891][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-08 21:21:52,891][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,892][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-08 21:21:52,893][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,893][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 77 ms on localhost (executor driver) (86/200)
[INFO][2021-06-08 21:21:52,893][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:52,894][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 72 ms on localhost (executor driver) (87/200)
[INFO][2021-06-08 21:21:52,895][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 76 ms on localhost (executor driver) (88/200)
[INFO][2021-06-08 21:21:52,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,894][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-08 21:21:52,896][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:52,895][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 71 ms on localhost (executor driver) (89/200)
[INFO][2021-06-08 21:21:52,896][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 56 ms on localhost (executor driver) (90/200)
[INFO][2021-06-08 21:21:52,897][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 49 ms on localhost (executor driver) (91/200)
[INFO][2021-06-08 21:21:52,896][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 63 ms on localhost (executor driver) (92/200)
[INFO][2021-06-08 21:21:52,897][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,898][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 42 ms on localhost (executor driver) (93/200)
[INFO][2021-06-08 21:21:52,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,899][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,900][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-08 21:21:52,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 58 ms on localhost (executor driver) (94/200)
[INFO][2021-06-08 21:21:52,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 63 ms on localhost (executor driver) (95/200)
[INFO][2021-06-08 21:21:52,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 74 ms on localhost (executor driver) (96/200)
[INFO][2021-06-08 21:21:52,901][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,902][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2377 bytes result sent to driver
[INFO][2021-06-08 21:21:52,902][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-08 21:21:52,903][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,903][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,903][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,904][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 58 ms on localhost (executor driver) (97/200)
[INFO][2021-06-08 21:21:52,904][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-08 21:21:52,904][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2375 bytes result sent to driver
[INFO][2021-06-08 21:21:52,904][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,905][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,905][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 56 ms on localhost (executor driver) (98/200)
[INFO][2021-06-08 21:21:52,905][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-08 21:21:52,906][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,906][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,907][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,908][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,907][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,908][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-08 21:21:52,908][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,909][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,910][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,910][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-08 21:21:52,910][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,911][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,912][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,910][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,912][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,912][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-08 21:21:52,913][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-08 21:21:52,914][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,914][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,913][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 80 ms on localhost (executor driver) (99/200)
[INFO][2021-06-08 21:21:52,915][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 58 ms on localhost (executor driver) (100/200)
[INFO][2021-06-08 21:21:52,916][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2458 bytes result sent to driver
[INFO][2021-06-08 21:21:52,916][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 62 ms on localhost (executor driver) (101/200)
[INFO][2021-06-08 21:21:52,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,913][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,913][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2253 bytes result sent to driver
[INFO][2021-06-08 21:21:52,917][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,921][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2283 bytes result sent to driver
[INFO][2021-06-08 21:21:52,922][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-08 21:21:52,923][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:52,922][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,924][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2265 bytes result sent to driver
[INFO][2021-06-08 21:21:52,924][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 73 ms on localhost (executor driver) (102/200)
[INFO][2021-06-08 21:21:52,924][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-08 21:21:52,924][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 69 ms on localhost (executor driver) (103/200)
[INFO][2021-06-08 21:21:52,925][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2267 bytes result sent to driver
[INFO][2021-06-08 21:21:52,925][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 46 ms on localhost (executor driver) (104/200)
[INFO][2021-06-08 21:21:52,926][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-08 21:21:52,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 61 ms on localhost (executor driver) (105/200)
[INFO][2021-06-08 21:21:52,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,927][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 69 ms on localhost (executor driver) (106/200)
[INFO][2021-06-08 21:21:52,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,928][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,928][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-08 21:21:52,929][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,929][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,930][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,930][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 46 ms on localhost (executor driver) (107/200)
[INFO][2021-06-08 21:21:52,930][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-08 21:21:52,931][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,932][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-08 21:21:52,932][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,933][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,933][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2459 bytes result sent to driver
[INFO][2021-06-08 21:21:52,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,933][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,933][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-08 21:21:52,933][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 49 ms on localhost (executor driver) (108/200)
[INFO][2021-06-08 21:21:52,934][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 45 ms on localhost (executor driver) (109/200)
[INFO][2021-06-08 21:21:52,934][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:52,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 44 ms on localhost (executor driver) (110/200)
[INFO][2021-06-08 21:21:52,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 43 ms on localhost (executor driver) (111/200)
[INFO][2021-06-08 21:21:52,936][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,936][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,936][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,937][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,937][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-08 21:21:52,938][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2277 bytes result sent to driver
[INFO][2021-06-08 21:21:52,938][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,938][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2277 bytes result sent to driver
[INFO][2021-06-08 21:21:52,939][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-08 21:21:52,939][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,940][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,939][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,941][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-08 21:21:52,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,941][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,944][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,942][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2363 bytes result sent to driver
[INFO][2021-06-08 21:21:52,944][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,943][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,943][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-08 21:21:52,945][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 46 ms on localhost (executor driver) (112/200)
[INFO][2021-06-08 21:21:52,944][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,947][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:52,946][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-08 21:21:52,947][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,947][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-08 21:21:52,948][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:52,948][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,948][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 43 ms on localhost (executor driver) (113/200)
[INFO][2021-06-08 21:21:52,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,949][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 49 ms on localhost (executor driver) (114/200)
[INFO][2021-06-08 21:21:52,950][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 42 ms on localhost (executor driver) (115/200)
[INFO][2021-06-08 21:21:52,950][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,951][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,950][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:52,952][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,951][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,953][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 51 ms on localhost (executor driver) (116/200)
[INFO][2021-06-08 21:21:52,953][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-08 21:21:52,953][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 47 ms on localhost (executor driver) (117/200)
[INFO][2021-06-08 21:21:52,955][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,956][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-08 21:21:52,956][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,956][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2244 bytes result sent to driver
[INFO][2021-06-08 21:21:52,956][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,956][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,957][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,957][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 48 ms on localhost (executor driver) (118/200)
[INFO][2021-06-08 21:21:52,957][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-08 21:21:52,957][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,958][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 46 ms on localhost (executor driver) (119/200)
[INFO][2021-06-08 21:21:52,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,959][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:52,959][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,959][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-08 21:21:52,959][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 42 ms on localhost (executor driver) (120/200)
[INFO][2021-06-08 21:21:52,960][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,960][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,961][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,960][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 38 ms on localhost (executor driver) (121/200)
[INFO][2021-06-08 21:21:52,961][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-08 21:21:52,962][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,962][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-08 21:21:52,962][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2374 bytes result sent to driver
[INFO][2021-06-08 21:21:52,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,974][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,974][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,975][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 50 ms on localhost (executor driver) (122/200)
[INFO][2021-06-08 21:21:52,974][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2440 bytes result sent to driver
[INFO][2021-06-08 21:21:52,975][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-08 21:21:52,975][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 48 ms on localhost (executor driver) (123/200)
[INFO][2021-06-08 21:21:52,975][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,976][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:65431 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:52,976][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 47 ms on localhost (executor driver) (124/200)
[INFO][2021-06-08 21:21:52,976][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,977][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,977][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,977][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,978][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,978][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-08 21:21:52,978][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2354 bytes result sent to driver
[INFO][2021-06-08 21:21:52,978][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,979][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-08 21:21:52,979][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,979][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2330 bytes result sent to driver
[INFO][2021-06-08 21:21:52,980][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-08 21:21:52,980][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,981][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2341 bytes result sent to driver
[INFO][2021-06-08 21:21:52,981][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-08 21:21:52,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,981][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2354 bytes result sent to driver
[INFO][2021-06-08 21:21:52,981][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,982][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-08 21:21:52,983][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 45 ms on localhost (executor driver) (125/200)
[INFO][2021-06-08 21:21:52,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,983][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 47 ms on localhost (executor driver) (126/200)
[INFO][2021-06-08 21:21:52,982][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,984][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,985][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,985][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,985][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,986][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-08 21:21:52,986][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,986][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:52,987][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,987][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-08 21:21:52,988][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-08 21:21:52,988][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2347 bytes result sent to driver
[INFO][2021-06-08 21:21:52,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,988][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,989][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-08 21:21:52,990][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,990][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,989][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2357 bytes result sent to driver
[INFO][2021-06-08 21:21:52,989][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 59 ms on localhost (executor driver) (127/200)
[INFO][2021-06-08 21:21:52,990][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,990][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,991][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,991][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,992][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,992][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,992][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,993][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-08 21:21:52,993][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,991][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:52,993][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 52 ms on localhost (executor driver) (128/200)
[INFO][2021-06-08 21:21:52,994][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 48 ms on localhost (executor driver) (129/200)
[INFO][2021-06-08 21:21:52,992][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-08 21:21:52,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,994][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:52,996][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2285 bytes result sent to driver
[INFO][2021-06-08 21:21:52,994][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-08 21:21:52,996][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:52,995][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 44 ms on localhost (executor driver) (130/200)
[INFO][2021-06-08 21:21:52,997][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,997][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 66 ms on localhost (executor driver) (131/200)
[INFO][2021-06-08 21:21:52,997][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2341 bytes result sent to driver
[INFO][2021-06-08 21:21:52,997][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 58 ms on localhost (executor driver) (132/200)
[INFO][2021-06-08 21:21:52,997][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:52,998][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,998][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 55 ms on localhost (executor driver) (133/200)
[INFO][2021-06-08 21:21:52,998][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-08 21:21:52,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:52,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:52,999][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:52,999][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 45 ms on localhost (executor driver) (134/200)
[INFO][2021-06-08 21:21:53,000][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-08 21:21:53,000][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 44 ms on localhost (executor driver) (135/200)
[INFO][2021-06-08 21:21:53,000][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2278 bytes result sent to driver
[INFO][2021-06-08 21:21:53,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,002][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,002][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,003][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-08 21:21:53,002][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 44 ms on localhost (executor driver) (136/200)
[INFO][2021-06-08 21:21:53,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,003][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 42 ms on localhost (executor driver) (137/200)
[INFO][2021-06-08 21:21:53,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,004][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,004][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:53,005][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,005][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 31 ms on localhost (executor driver) (138/200)
[INFO][2021-06-08 21:21:53,005][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-08 21:21:53,005][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 45 ms on localhost (executor driver) (139/200)
[INFO][2021-06-08 21:21:53,005][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,006][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,006][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-08 21:21:53,007][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,006][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2336 bytes result sent to driver
[INFO][2021-06-08 21:21:53,007][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-08 21:21:53,007][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,008][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,009][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2358 bytes result sent to driver
[INFO][2021-06-08 21:21:53,008][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,010][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,010][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-08 21:21:53,010][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,010][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,010][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,010][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-08 21:21:53,011][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,012][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,012][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2282 bytes result sent to driver
[INFO][2021-06-08 21:21:53,013][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,013][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-08 21:21:53,012][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,013][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-08 21:21:53,013][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,014][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2273 bytes result sent to driver
[INFO][2021-06-08 21:21:53,013][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,014][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-08 21:21:53,014][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,013][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,016][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-08 21:21:53,016][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,017][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,017][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,018][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-08 21:21:53,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,020][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,021][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,022][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,023][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2361 bytes result sent to driver
[INFO][2021-06-08 21:21:53,016][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,024][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:21:53,020][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,024][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-08 21:21:53,025][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,025][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2355 bytes result sent to driver
[INFO][2021-06-08 21:21:53,025][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,026][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,027][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,019][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,027][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-08 21:21:53,029][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,016][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,026][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,025][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-08 21:21:53,032][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:53,032][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,033][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,034][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-08 21:21:53,034][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,035][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,037][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,037][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,037][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,038][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-08 21:21:53,034][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,039][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:21:53,039][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-08 21:21:53,043][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,044][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-08 21:21:53,038][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,044][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-08 21:21:53,044][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-08 21:21:53,045][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,047][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,044][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:53,044][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-08 21:21:53,043][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2350 bytes result sent to driver
[INFO][2021-06-08 21:21:53,042][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-08 21:21:53,047][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,048][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,047][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,048][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,049][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,050][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,047][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,046][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-08 21:21:53,051][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2450 bytes result sent to driver
[INFO][2021-06-08 21:21:53,051][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,046][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-08 21:21:53,052][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,053][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,053][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,049][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,054][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:21:53,054][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-08 21:21:53,053][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2366 bytes result sent to driver
[INFO][2021-06-08 21:21:53,053][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,053][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-08 21:21:53,052][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-08 21:21:53,056][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,056][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,052][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-08 21:21:53,060][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2373 bytes result sent to driver
[INFO][2021-06-08 21:21:53,052][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2359 bytes result sent to driver
[INFO][2021-06-08 21:21:53,052][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2346 bytes result sent to driver
[INFO][2021-06-08 21:21:53,055][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,061][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:21:53,062][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:53,054][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 75 ms on localhost (executor driver) (140/200)
[INFO][2021-06-08 21:21:53,062][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 81 ms on localhost (executor driver) (141/200)
[INFO][2021-06-08 21:21:53,063][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 79 ms on localhost (executor driver) (142/200)
[INFO][2021-06-08 21:21:53,063][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 77 ms on localhost (executor driver) (143/200)
[INFO][2021-06-08 21:21:53,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,061][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:21:53,061][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2268 bytes result sent to driver
[INFO][2021-06-08 21:21:53,064][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 76 ms on localhost (executor driver) (144/200)
[INFO][2021-06-08 21:21:53,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,065][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 80 ms on localhost (executor driver) (145/200)
[INFO][2021-06-08 21:21:53,063][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2372 bytes result sent to driver
[INFO][2021-06-08 21:21:53,066][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 74 ms on localhost (executor driver) (146/200)
[INFO][2021-06-08 21:21:53,065][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,067][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 75 ms on localhost (executor driver) (147/200)
[INFO][2021-06-08 21:21:53,067][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:53,067][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 74 ms on localhost (executor driver) (148/200)
[INFO][2021-06-08 21:21:53,067][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 88 ms on localhost (executor driver) (149/200)
[INFO][2021-06-08 21:21:53,068][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 69 ms on localhost (executor driver) (150/200)
[INFO][2021-06-08 21:21:53,068][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 66 ms on localhost (executor driver) (151/200)
[INFO][2021-06-08 21:21:53,069][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 66 ms on localhost (executor driver) (152/200)
[INFO][2021-06-08 21:21:53,069][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 64 ms on localhost (executor driver) (153/200)
[INFO][2021-06-08 21:21:53,069][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 56 ms on localhost (executor driver) (154/200)
[INFO][2021-06-08 21:21:53,069][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 62 ms on localhost (executor driver) (155/200)
[INFO][2021-06-08 21:21:53,069][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 59 ms on localhost (executor driver) (156/200)
[INFO][2021-06-08 21:21:53,070][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 55 ms on localhost (executor driver) (157/200)
[INFO][2021-06-08 21:21:53,070][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 64 ms on localhost (executor driver) (158/200)
[INFO][2021-06-08 21:21:53,070][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2369 bytes result sent to driver
[INFO][2021-06-08 21:21:53,070][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 53 ms on localhost (executor driver) (159/200)
[INFO][2021-06-08 21:21:53,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 95 ms on localhost (executor driver) (160/200)
[INFO][2021-06-08 21:21:53,072][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2377 bytes result sent to driver
[INFO][2021-06-08 21:21:53,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 96 ms on localhost (executor driver) (161/200)
[INFO][2021-06-08 21:21:53,072][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 60 ms on localhost (executor driver) (162/200)
[INFO][2021-06-08 21:21:53,074][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,074][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 63 ms on localhost (executor driver) (163/200)
[INFO][2021-06-08 21:21:53,075][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-08 21:21:53,074][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2359 bytes result sent to driver
[INFO][2021-06-08 21:21:53,075][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 77 ms on localhost (executor driver) (164/200)
[INFO][2021-06-08 21:21:53,076][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,076][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-08 21:21:53,076][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 52 ms on localhost (executor driver) (165/200)
[INFO][2021-06-08 21:21:53,077][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,077][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,077][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,077][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 63 ms on localhost (executor driver) (166/200)
[INFO][2021-06-08 21:21:53,077][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-08 21:21:53,078][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,078][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,079][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,079][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-08 21:21:53,079][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,080][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,080][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,082][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,082][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-08 21:21:53,083][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,083][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,085][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,086][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-08 21:21:53,087][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:53,086][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,086][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:53,086][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2418 bytes result sent to driver
[INFO][2021-06-08 21:21:53,087][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-08 21:21:53,086][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,088][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,089][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-08 21:21:53,089][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2372 bytes result sent to driver
[INFO][2021-06-08 21:21:53,089][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,090][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,090][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,090][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 59 ms on localhost (executor driver) (167/200)
[INFO][2021-06-08 21:21:53,089][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,091][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:53,091][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 58 ms on localhost (executor driver) (168/200)
[INFO][2021-06-08 21:21:53,091][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 66 ms on localhost (executor driver) (169/200)
[INFO][2021-06-08 21:21:53,091][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,092][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,092][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 55 ms on localhost (executor driver) (170/200)
[INFO][2021-06-08 21:21:53,092][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-08 21:21:53,093][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:53,094][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,094][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-08 21:21:53,095][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,095][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2256 bytes result sent to driver
[INFO][2021-06-08 21:21:53,096][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,095][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,096][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-08 21:21:53,096][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-08 21:21:53,097][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,098][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,096][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2288 bytes result sent to driver
[INFO][2021-06-08 21:21:53,096][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,099][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,102][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,102][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,103][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,103][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,103][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-08 21:21:53,096][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,103][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,106][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,106][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,106][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2354 bytes result sent to driver
[INFO][2021-06-08 21:21:53,106][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-08 21:21:53,107][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,108][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,109][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,110][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,111][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,112][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,113][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2282 bytes result sent to driver
[INFO][2021-06-08 21:21:53,115][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2283 bytes result sent to driver
[INFO][2021-06-08 21:21:53,111][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:53,115][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,117][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2276 bytes result sent to driver
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-08 21:21:53,114][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-08 21:21:53,120][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,120][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:21:53,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 80 ms on localhost (executor driver) (171/200)
[INFO][2021-06-08 21:21:53,122][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,122][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,121][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,122][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:21:53,119][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,123][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:53,119][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,123][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:53,119][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,125][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:21:53,127][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2282 bytes result sent to driver
[INFO][2021-06-08 21:21:53,117][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:21:53,130][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2338 bytes result sent to driver
[INFO][2021-06-08 21:21:53,131][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2284 bytes result sent to driver
[INFO][2021-06-08 21:21:53,127][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:21:53,131][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:21:53,132][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2281 bytes result sent to driver
[INFO][2021-06-08 21:21:53,127][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2280 bytes result sent to driver
[INFO][2021-06-08 21:21:53,122][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 87 ms on localhost (executor driver) (172/200)
[INFO][2021-06-08 21:21:53,133][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 96 ms on localhost (executor driver) (173/200)
[INFO][2021-06-08 21:21:53,134][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 88 ms on localhost (executor driver) (174/200)
[INFO][2021-06-08 21:21:53,134][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 82 ms on localhost (executor driver) (175/200)
[INFO][2021-06-08 21:21:53,135][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 90 ms on localhost (executor driver) (176/200)
[INFO][2021-06-08 21:21:53,137][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2464 bytes result sent to driver
[INFO][2021-06-08 21:21:53,137][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 82 ms on localhost (executor driver) (177/200)
[INFO][2021-06-08 21:21:53,137][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2371 bytes result sent to driver
[INFO][2021-06-08 21:21:53,138][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 112 ms on localhost (executor driver) (178/200)
[INFO][2021-06-08 21:21:53,137][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2278 bytes result sent to driver
[INFO][2021-06-08 21:21:53,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 65 ms on localhost (executor driver) (179/200)
[INFO][2021-06-08 21:21:53,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 63 ms on localhost (executor driver) (180/200)
[INFO][2021-06-08 21:21:53,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 64 ms on localhost (executor driver) (181/200)
[INFO][2021-06-08 21:21:53,140][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 90 ms on localhost (executor driver) (182/200)
[INFO][2021-06-08 21:21:53,141][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 62 ms on localhost (executor driver) (183/200)
[INFO][2021-06-08 21:21:53,141][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 63 ms on localhost (executor driver) (184/200)
[INFO][2021-06-08 21:21:53,141][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 55 ms on localhost (executor driver) (185/200)
[INFO][2021-06-08 21:21:53,142][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 62 ms on localhost (executor driver) (186/200)
[INFO][2021-06-08 21:21:53,142][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 55 ms on localhost (executor driver) (187/200)
[INFO][2021-06-08 21:21:53,142][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 49 ms on localhost (executor driver) (188/200)
[INFO][2021-06-08 21:21:53,143][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 45 ms on localhost (executor driver) (189/200)
[INFO][2021-06-08 21:21:53,143][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 49 ms on localhost (executor driver) (190/200)
[INFO][2021-06-08 21:21:53,143][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 55 ms on localhost (executor driver) (191/200)
[INFO][2021-06-08 21:21:53,144][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 49 ms on localhost (executor driver) (192/200)
[INFO][2021-06-08 21:21:53,144][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 33 ms on localhost (executor driver) (193/200)
[INFO][2021-06-08 21:21:53,145][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 36 ms on localhost (executor driver) (194/200)
[INFO][2021-06-08 21:21:53,145][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 39 ms on localhost (executor driver) (195/200)
[INFO][2021-06-08 21:21:53,145][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 34 ms on localhost (executor driver) (196/200)
[INFO][2021-06-08 21:21:53,146][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 34 ms on localhost (executor driver) (197/200)
[INFO][2021-06-08 21:21:53,146][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 44 ms on localhost (executor driver) (198/200)
[INFO][2021-06-08 21:21:53,147][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 39 ms on localhost (executor driver) (199/200)
[INFO][2021-06-08 21:21:53,147][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 37 ms on localhost (executor driver) (200/200)
[INFO][2021-06-08 21:21:53,147][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:53,147][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.712 s
[INFO][2021-06-08 21:21:53,148][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 1.311849 s
[INFO][2021-06-08 21:21:53,183][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.841301 ms
[INFO][2021-06-08 21:21:53,200][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,204][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,204][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:65431 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,205][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-08 21:21:53,205][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,208][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,209][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:65431 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,209][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-08 21:21:53,209][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-08 21:21:53,211][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-08 21:21:53,237][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-08 21:21:53,242][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-08 21:21:53,243][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:65431 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,243][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:347
[INFO][2021-06-08 21:21:53,251][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-08 21:21:53,259][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-08 21:21:53,260][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:65431 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,261][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:316
[INFO][2021-06-08 21:21:53,442][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:21:53,448][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:21:53,448][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:21:53,575][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.6137 ms
[INFO][2021-06-08 21:21:53,582][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-08 21:21:53,583][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-08 21:21:53,583][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:21:53,583][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:53,583][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:53,583][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-08 21:21:53,592][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,594][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,594][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:65431 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,595][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:53,595][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:21:53,595][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 21:21:53,596][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:21:53,597][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-08 21:21:53,638][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:21:53,640][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2360 bytes result sent to driver
[INFO][2021-06-08 21:21:53,640][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 44 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:53,640][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:53,640][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.044 s
[INFO][2021-06-08 21:21:53,641][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.058681 s
[INFO][2021-06-08 21:21:53,681][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 33.858999 ms
[INFO][2021-06-08 21:21:53,690][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:21:53,730][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:21:53,733][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-08 21:21:53,733][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:21:53,796][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.049999 ms
[INFO][2021-06-08 21:21:53,808][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-08 21:21:53,809][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-08 21:21:53,809][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:21:53,809][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:53,809][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:53,810][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-08 21:21:53,811][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,812][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:53,813][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:65431 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:53,814][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:53,814][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:21:53,814][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 21:21:53,815][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:21:53,815][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-08 21:21:53,850][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:21:53,851][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2287 bytes result sent to driver
[INFO][2021-06-08 21:21:53,852][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 38 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:53,852][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:53,852][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.038 s
[INFO][2021-06-08 21:21:53,853][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.044494 s
[INFO][2021-06-08 21:21:53,856][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-08 21:21:53,890][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:53,891][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,891][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,892][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,892][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:21:53,892][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:21:53,892][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:21:53,892][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,893][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,894][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:21:53,895][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,896][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:21:53,896][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,896][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,897][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,898][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,913][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.558699 ms
[INFO][2021-06-08 21:21:53,916][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-08 21:21:53,926][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk,cast(null as decimal(8,0)) as wssgjkr,cast(null as decimal(8,0)) as wssgtkr,cast(null as decimal(8,0)) as zjxcgpr,cast(null as decimal(8,0)) as fxjgggr from sparktxggl
[INFO][2021-06-08 21:21:53,953][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:21:53,957][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_txggl select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:21:53,978][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:53,979][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,979][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:21:53,980][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,981][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,982][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,982][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,982][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:21:53,982][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,982][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:53,983][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,984][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,984][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:53,984][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:21:54,141][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-08 21:21:54,144][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:21:54,144][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-08 21:21:54,176][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.2417 ms
[INFO][2021-06-08 21:21:54,183][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-08 21:21:54,183][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-08 21:21:54,184][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:21:54,184][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:54,184][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:54,184][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[25] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-08 21:21:54,187][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 10.7 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,190][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,191][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.52.10:65431 (size: 5.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:54,191][org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:54,192][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:21:54,192][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
[INFO][2021-06-08 21:21:54,193][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:21:54,194][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 204)
[INFO][2021-06-08 21:21:54,210][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:21:54,212][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 204). 2295 bytes result sent to driver
[INFO][2021-06-08 21:21:54,212][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 204) in 20 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:54,213][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (show at DemoMoveFinfo.java:130) finished in 0.020 s
[INFO][2021-06-08 21:21:54,213][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:54,213][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at DemoMoveFinfo.java:130, took 0.030461 s
[INFO][2021-06-08 21:21:54,227][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.753301 ms
[INFO][2021-06-08 21:21:54,228][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,tranMarketCode(JYS) as JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-08 21:21:54,233][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-08 21:21:54,235][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-08 21:21:54,236][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-08 21:21:54,266][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.558399 ms
[INFO][2021-06-08 21:21:54,269][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-08 21:21:54,270][org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-08 21:21:54,270][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:21:54,271][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:54,271][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:54,271][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[29] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-08 21:21:54,272][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 15.1 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,275][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.0 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,275][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.52.10:65431 (size: 7.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:54,277][org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:54,277][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[29] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:21:54,277][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
[INFO][2021-06-08 21:21:54,278][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:21:54,278][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 205)
[INFO][2021-06-08 21:21:54,291][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:21:54,293][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 205). 2204 bytes result sent to driver
[INFO][2021-06-08 21:21:54,293][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 205) in 16 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:54,293][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:54,293][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (show at DemoMoveFinfo.java:134) finished in 0.016 s
[INFO][2021-06-08 21:21:54,294][org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at DemoMoveFinfo.java:134, took 0.023898 s
[INFO][2021-06-08 21:21:54,296][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_tzqdmbg
[INFO][2021-06-08 21:21:54,325][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,325][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,325][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,325][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,326][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:54,327][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:21:54,352][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg
[INFO][2021-06-08 21:21:54,357][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as string) as id,cast(jys as string) as jys,cast(zqdm as string) as zqdm,cast(zqmc as string) as zqmc,cast(zqlb as string) as zqlb,cast(bgdm as string) as bgdm,cast(bgmc as string) as bgmc,cast(blzh as decimal(12,9)) as blzh,cast(bgsm as string) as bgsm,cast(bglb as decimal(12,0)) as bglb,cast(whsj as string) as whsj,cast(bgrq as int) as bgrq,cast(zxj as decimal(9,4)) as zxj from sparktzqdmbg
[INFO][2021-06-08 21:21:54,364][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-08 21:21:54,366][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_tzqdmbg select ID,JYS,ZQDM,ZQMC,ZQLB,BGDM,BGMC,BLZH,BGSM,BGLB,BGRQ,WHSJ,ZXJ from sparktzqdmbg
[INFO][2021-06-08 21:21:54,379][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,380][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,9)
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,0)
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:21:54,381][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:21:54,490][org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat:54] - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 21:21:54,537][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 21:21:54,538][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 21:21:54,558][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.936899 ms
[INFO][2021-06-08 21:21:54,582][org.apache.spark.SparkContext:54] - Starting job: sql at DemoMoveFinfo.java:141
[INFO][2021-06-08 21:21:54,582][org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (sql at DemoMoveFinfo.java:141) with 1 output partitions
[INFO][2021-06-08 21:21:54,582][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (sql at DemoMoveFinfo.java:141)
[INFO][2021-06-08 21:21:54,582][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:21:54,583][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:21:54,583][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[33] at sql at DemoMoveFinfo.java:141), which has no missing parents
[INFO][2021-06-08 21:21:54,592][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 69.8 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,596][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 27.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:21:54,597][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.52.10:65431 (size: 27.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:54,597][org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:21:54,598][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at sql at DemoMoveFinfo.java:141)
[INFO][2021-06-08 21:21:54,598][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
[INFO][2021-06-08 21:21:54,599][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5816 bytes)
[INFO][2021-06-08 21:21:54,599][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 206)
[INFO][2021-06-08 21:21:54,606][org.apache.hadoop.conf.Configuration.deprecation:840] - mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
[INFO][2021-06-08 21:21:54,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[INFO][2021-06-08 21:21:54,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
[INFO][2021-06-08 21:21:54,612][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
[INFO][2021-06-08 21:21:54,626][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 21:21:54,627][org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol:54] - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO][2021-06-08 21:21:54,629][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 21:21:54,631][org.apache.parquet.hadoop.codec.CodecConfig:151] - Compression: SNAPPY
[INFO][2021-06-08 21:21:54,634][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet block size to 134217728
[INFO][2021-06-08 21:21:54,634][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet page size to 1048576
[INFO][2021-06-08 21:21:54,634][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Parquet dictionary page size to 1048576
[INFO][2021-06-08 21:21:54,634][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Dictionary is on
[INFO][2021-06-08 21:21:54,634][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Validation is off
[INFO][2021-06-08 21:21:54,635][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Writer version is: PARQUET_1_0
[INFO][2021-06-08 21:21:54,635][org.apache.parquet.hadoop.ParquetOutputFormat:151] - Maximum row group padding size is 0 bytes
[INFO][2021-06-08 21:21:54,648][org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport:54] - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : false,
    "metadata" : {
      "comment" : "ID",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "jys",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "zqlb",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgdm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgmc",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "blzh",
    "type" : "decimal(12,9)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,9)"
    }
  }, {
    "name" : "bgsm",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bglb",
    "type" : "decimal(12,0)",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "decimal(12,0)"
    }
  }, {
    "name" : "whsj",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "string"
    }
  }, {
    "name" : "bgrq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "comment" : "????",
      "HIVE_TYPE_STRING" : "int"
    }
  }, {
    "name" : "zxj",
    "type" : "decimal(9,4)",
    "nullable" : true,
    "metadata" : {
      "comment" : "???",
      "HIVE_TYPE_STRING" : "decimal(9,4)"
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required binary id (UTF8);
  optional binary jys (UTF8);
  optional binary zqdm (UTF8);
  optional binary zqmc (UTF8);
  optional binary zqlb (UTF8);
  optional binary bgdm (UTF8);
  optional binary bgmc (UTF8);
  optional fixed_len_byte_array(6) blzh (DECIMAL(12,9));
  optional binary bgsm (UTF8);
  optional fixed_len_byte_array(6) bglb (DECIMAL(12,0));
  optional binary whsj (UTF8);
  optional int32 bgrq;
  optional fixed_len_byte_array(4) zxj (DECIMAL(9,4));
}

       
[INFO][2021-06-08 21:21:54,677][org.apache.hadoop.io.compress.CodecPool:150] - Got brand-new compressor [.snappy]
[INFO][2021-06-08 21:21:54,799][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:21:54,800][org.apache.parquet.hadoop.InternalParquetRecordWriter:151] - Flushing mem columnStore to file. allocated memory: 7,751
[INFO][2021-06-08 21:21:54,915][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 220B for [id] BINARY: 47 values, 275B raw, 191B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
[INFO][2021-06-08 21:21:54,916][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 55B for [jys] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 5 entries, 25B raw, 5B comp}
[INFO][2021-06-08 21:21:54,917][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 359B for [zqdm] BINARY: 47 values, 466B raw, 320B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:54,918][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 93B for [zqmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 42 entries, 605B raw, 42B comp}
[INFO][2021-06-08 21:21:54,918][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 46B for [zqlb] BINARY: 47 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 2 entries, 12B raw, 2B comp}
[INFO][2021-06-08 21:21:54,919][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 280B for [bgdm] BINARY: 47 values, 467B raw, 241B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:54,919][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 84B for [bgmc] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 41 entries, 539B raw, 41B comp}
[INFO][2021-06-08 21:21:54,919][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 92B for [blzh] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 54B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:54,920][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 105B for [bgsm] BINARY: 47 values, 26B raw, 28B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 7 entries, 172B raw, 7B comp}
[INFO][2021-06-08 21:21:54,920][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 81B for [bglb] FIXED_LEN_BYTE_ARRAY: 47 values, 288B raw, 43B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:54,921][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 87B for [whsj] BINARY: 47 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 41 entries, 492B raw, 41B comp}
[INFO][2021-06-08 21:21:54,921][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 29B for [bgrq] INT32: 47 values, 6B raw, 8B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:54,921][org.apache.parquet.hadoop.ColumnChunkPageWriteStore:151] - written 168B for [zxj] FIXED_LEN_BYTE_ARRAY: 47 values, 194B raw, 133B comp, 1 pages, encodings: [PLAIN, BIT_PACKED, RLE]
[INFO][2021-06-08 21:21:55,037][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.52.10:65431 in memory (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:55,039][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5077
[INFO][2021-06-08 21:21:55,040][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.52.10:65431 in memory (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:55,041][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.52.10:65431 in memory (size: 5.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:55,041][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5076
[INFO][2021-06-08 21:21:55,042][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.52.10:65431 in memory (size: 7.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:21:55,042][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4976
[INFO][2021-06-08 21:21:55,043][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5027
[INFO][2021-06-08 21:21:55,043][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4926
[INFO][2021-06-08 21:21:55,043][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 5026
[INFO][2021-06-08 21:21:55,043][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4977
[INFO][2021-06-08 21:21:55,043][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4927
[INFO][2021-06-08 21:21:55,164][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:439] - Saved output of task 'attempt_20210608212154_0007_m_000000_0' to hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/info_tzqdmbg/_temporary/0/task_20210608212154_0007_m_000000
[INFO][2021-06-08 21:21:55,165][org.apache.spark.mapred.SparkHadoopMapRedUtil:54] - attempt_20210608212154_0007_m_000000_0: Committed
[INFO][2021-06-08 21:21:55,167][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 206). 1500 bytes result sent to driver
[INFO][2021-06-08 21:21:55,168][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 206) in 570 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:21:55,169][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:21:55,169][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (sql at DemoMoveFinfo.java:141) finished in 0.571 s
[INFO][2021-06-08 21:21:55,169][org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: sql at DemoMoveFinfo.java:141, took 0.587143 s
[INFO][2021-06-08 21:21:55,188][org.apache.spark.sql.execution.datasources.FileFormatWriter:54] - Job null committed.
[INFO][2021-06-08 21:21:55,238][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 21:21:55,252][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@660e9100{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:21:55,259][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@552518c3{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,260][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,261][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@21ec5d87{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,261][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1eba372c{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,261][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2f2bf0e2{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,261][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@3bd7f8dc{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,262][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6cea706c{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,263][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@476aac9{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,264][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1b11ef33{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,264][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@54107f42{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,264][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@48c40605{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,264][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@770d0ea6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@302fec27{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@60cf80e7{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@24f360b2{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2a2da905{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@54709809{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@355e34c7{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1133ec6e{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6063d80a{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,265][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ae76500{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,266][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,266][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5ae81e1{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,266][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@59fc684e{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,267][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@46c670a6{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:21:55,268][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-08 21:21:55,279][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 21:21:55,334][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 21:21:55,334][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 21:21:55,337][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 21:21:55,338][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 21:21:55,341][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 21:21:55,341][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 21:21:55,342][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-1e9629a4-2b48-483f-ae48-10638f2a60ed
[INFO][2021-06-08 21:24:50,597][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:24:50,783][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:24:50,784][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:24:50,785][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:24:50,785][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:24:50,786][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:24:51,923][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63208.
[INFO][2021-06-08 21:24:51,951][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:24:51,967][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:24:51,970][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:24:51,970][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:24:51,979][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-284a295f-9275-4f37-ada0-3ad658799c7f
[INFO][2021-06-08 21:24:51,992][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:24:52,029][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:24:52,105][org.spark_project.jetty.util.log:186] - Logging initialized @4205ms
[INFO][2021-06-08 21:24:52,201][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:24:52,219][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,219][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,220][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,220][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,220][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@10afe71a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,221][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,221][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,222][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,222][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,222][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,223][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@23a5818e{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,223][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,223][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,224][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,224][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@108a46d6{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,224][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,224][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17690e14{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,225][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,225][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,226][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,232][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f00f851{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,232][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4207609e{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,233][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,233][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,233][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,242][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:24:52,242][org.spark_project.jetty.server.Server:379] - Started @4344ms
[INFO][2021-06-08 21:24:52,243][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:24:52,247][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:24:52,307][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:24:52,337][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63249.
[INFO][2021-06-08 21:24:52,338][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:63249
[INFO][2021-06-08 21:24:52,340][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:24:52,341][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:24:52,345][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:63249 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:24:52,351][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:24:52,351][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:24:52,539][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6056232d{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,570][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:24:52,576][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@42a0501e{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,576][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6e4599c0{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,577][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b5c4f17{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,578][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@69f0b0f4{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,579][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1d61a348{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:24:52,644][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:24:52,773][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:24:52,774][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:24:52,774][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:24:52,775][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:24:52,775][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:24:52,776][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:24:52,776][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:24:52,776][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:24:52,998][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:24:53,031][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:24:53,821][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:24:53,909][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/d171eb61-b3cf-4a13-a672-84af27cd2fcb_resources
[INFO][2021-06-08 21:24:53,915][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/d171eb61-b3cf-4a13-a672-84af27cd2fcb
[INFO][2021-06-08 21:24:53,919][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/d171eb61-b3cf-4a13-a672-84af27cd2fcb
[INFO][2021-06-08 21:24:53,922][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/d171eb61-b3cf-4a13-a672-84af27cd2fcb/_tmp_space.db
[INFO][2021-06-08 21:24:53,925][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:24:54,031][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-08 21:24:54,791][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,796][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,796][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-08 21:24:54,797][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-08 21:24:54,797][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,798][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,798][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,798][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:54,798][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:24:56,718][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:56,958][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:56,960][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:56,967][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:24:57,494][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 228.777801 ms
[INFO][2021-06-08 21:24:57,624][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 26.657001 ms
[INFO][2021-06-08 21:24:57,751][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-08 21:24:57,835][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:24:57,852][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-08 21:24:57,853][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:57,853][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:24:57,856][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:24:57,864][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:24:57,887][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:57,914][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:57,915][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:63249 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:57,916][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:24:57,929][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:57,931][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:24:57,971][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-08 21:24:57,979][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:24:58,018][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:24:58,026][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:24:58,027][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:24:58,027][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:24:58,027][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:24:58,027][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:24:58,090][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.994299 ms
[INFO][2021-06-08 21:24:59,072][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155513 bytes result sent to driver
[INFO][2021-06-08 21:24:59,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 1149 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:24:59,107][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:24:59,111][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 1.166 s
[INFO][2021-06-08 21:24:59,117][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 1.281433 s
[INFO][2021-06-08 21:24:59,190][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:24:59,193][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:59,193][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-08 21:24:59,193][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:59,193][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:24:59,194][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:24:59,195][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:24:59,208][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:59,212][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:59,213][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:63249 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:59,214][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:24:59,216][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:59,216][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:24:59,218][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-08 21:24:59,219][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:24:59,236][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:24:59,554][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1848 bytes result sent to driver
[INFO][2021-06-08 21:24:59,558][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 342 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:24:59,559][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:24:59,559][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 0.343 s
[INFO][2021-06-08 21:24:59,560][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-08 21:24:59,561][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-08 21:24:59,562][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-08 21:24:59,562][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-08 21:24:59,569][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:24:59,609][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:59,613][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:24:59,614][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:59,615][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:24:59,617][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:24:59,617][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-08 21:24:59,621][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,623][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,624][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,625][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,626][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,627][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,628][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,629][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,631][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,632][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,634][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,635][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,636][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,638][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,639][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,640][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,640][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:24:59,641][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:24:59,642][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-08 21:24:59,642][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-08 21:24:59,650][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-08 21:24:59,651][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-08 21:24:59,652][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-08 21:24:59,657][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-08 21:24:59,657][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-08 21:24:59,667][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-08 21:24:59,667][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-08 21:24:59,668][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-08 21:24:59,668][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-08 21:24:59,668][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-08 21:24:59,671][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-08 21:24:59,672][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-08 21:24:59,686][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,690][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-08 21:24:59,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 13 ms
[INFO][2021-06-08 21:24:59,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,692][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
[INFO][2021-06-08 21:24:59,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,693][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
[INFO][2021-06-08 21:24:59,693][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,694][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:24:59,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 12 ms
[INFO][2021-06-08 21:24:59,690][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:24:59,690][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:24:59,690][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:24:59,690][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,696][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,697][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
[INFO][2021-06-08 21:24:59,697][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
[INFO][2021-06-08 21:24:59,696][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
[INFO][2021-06-08 21:24:59,695][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
[INFO][2021-06-08 21:24:59,731][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.2971 ms
[INFO][2021-06-08 21:24:59,768][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2360 bytes result sent to driver
[INFO][2021-06-08 21:24:59,769][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2433 bytes result sent to driver
[INFO][2021-06-08 21:24:59,770][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2452 bytes result sent to driver
[INFO][2021-06-08 21:24:59,770][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2450 bytes result sent to driver
[INFO][2021-06-08 21:24:59,770][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,776][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-08 21:24:59,776][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2355 bytes result sent to driver
[INFO][2021-06-08 21:24:59,778][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,779][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-08 21:24:59,779][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2404 bytes result sent to driver
[INFO][2021-06-08 21:24:59,780][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2456 bytes result sent to driver
[INFO][2021-06-08 21:24:59,780][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2371 bytes result sent to driver
[INFO][2021-06-08 21:24:59,781][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2269 bytes result sent to driver
[INFO][2021-06-08 21:24:59,780][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2284 bytes result sent to driver
[INFO][2021-06-08 21:24:59,781][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2450 bytes result sent to driver
[INFO][2021-06-08 21:24:59,782][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,783][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,783][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2371 bytes result sent to driver
[INFO][2021-06-08 21:24:59,783][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,782][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2338 bytes result sent to driver
[INFO][2021-06-08 21:24:59,784][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,785][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2356 bytes result sent to driver
[INFO][2021-06-08 21:24:59,784][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2375 bytes result sent to driver
[INFO][2021-06-08 21:24:59,786][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-08 21:24:59,786][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,787][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-08 21:24:59,788][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2287 bytes result sent to driver
[INFO][2021-06-08 21:24:59,788][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,789][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-08 21:24:59,790][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,790][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-08 21:24:59,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,794][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,794][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2376 bytes result sent to driver
[INFO][2021-06-08 21:24:59,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,794][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2284 bytes result sent to driver
[INFO][2021-06-08 21:24:59,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:24:59,797][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,801][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-08 21:24:59,801][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,802][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-08 21:24:59,802][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,803][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2419 bytes result sent to driver
[INFO][2021-06-08 21:24:59,803][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2269 bytes result sent to driver
[INFO][2021-06-08 21:24:59,804][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-08 21:24:59,805][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,806][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,807][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,807][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-08 21:24:59,808][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,809][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,809][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,807][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,811][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,811][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-08 21:24:59,812][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,813][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,814][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-08 21:24:59,815][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 179 ms on localhost (executor driver) (1/200)
[INFO][2021-06-08 21:24:59,815][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,815][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,816][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,816][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,816][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-08 21:24:59,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,818][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,819][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,820][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,807][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-08 21:24:59,820][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2287 bytes result sent to driver
[INFO][2021-06-08 21:24:59,816][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,815][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 182 ms on localhost (executor driver) (2/200)
[INFO][2021-06-08 21:24:59,829][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 193 ms on localhost (executor driver) (3/200)
[INFO][2021-06-08 21:24:59,829][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 208 ms on localhost (executor driver) (4/200)
[INFO][2021-06-08 21:24:59,830][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 191 ms on localhost (executor driver) (5/200)
[INFO][2021-06-08 21:24:59,830][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 211 ms on localhost (executor driver) (6/200)
[INFO][2021-06-08 21:24:59,831][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 200 ms on localhost (executor driver) (7/200)
[INFO][2021-06-08 21:24:59,814][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-08 21:24:59,833][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,834][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,834][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,834][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,836][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2453 bytes result sent to driver
[INFO][2021-06-08 21:24:59,814][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-08 21:24:59,839][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2343 bytes result sent to driver
[INFO][2021-06-08 21:24:59,841][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2282 bytes result sent to driver
[INFO][2021-06-08 21:24:59,838][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2363 bytes result sent to driver
[INFO][2021-06-08 21:24:59,844][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,844][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,844][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2355 bytes result sent to driver
[INFO][2021-06-08 21:24:59,832][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 204 ms on localhost (executor driver) (8/200)
[INFO][2021-06-08 21:24:59,846][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2372 bytes result sent to driver
[INFO][2021-06-08 21:24:59,839][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2377 bytes result sent to driver
[INFO][2021-06-08 21:24:59,846][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 222 ms on localhost (executor driver) (9/200)
[INFO][2021-06-08 21:24:59,847][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,848][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,848][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 214 ms on localhost (executor driver) (10/200)
[INFO][2021-06-08 21:24:59,849][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 222 ms on localhost (executor driver) (11/200)
[INFO][2021-06-08 21:24:59,850][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2355 bytes result sent to driver
[INFO][2021-06-08 21:24:59,849][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-08 21:24:59,851][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 212 ms on localhost (executor driver) (12/200)
[INFO][2021-06-08 21:24:59,852][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 226 ms on localhost (executor driver) (13/200)
[INFO][2021-06-08 21:24:59,852][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 229 ms on localhost (executor driver) (14/200)
[INFO][2021-06-08 21:24:59,853][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 228 ms on localhost (executor driver) (15/200)
[INFO][2021-06-08 21:24:59,855][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,855][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,855][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,856][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-08 21:24:59,857][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,857][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-08 21:24:59,869][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,870][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,870][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,871][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,871][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-08 21:24:59,871][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 100 ms on localhost (executor driver) (16/200)
[INFO][2021-06-08 21:24:59,871][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,872][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:24:59,872][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 96 ms on localhost (executor driver) (17/200)
[INFO][2021-06-08 21:24:59,873][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 84 ms on localhost (executor driver) (18/200)
[INFO][2021-06-08 21:24:59,871][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-08 21:24:59,874][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2357 bytes result sent to driver
[INFO][2021-06-08 21:24:59,877][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,877][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,879][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2349 bytes result sent to driver
[INFO][2021-06-08 21:24:59,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,880][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,881][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-08 21:24:59,882][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2405 bytes result sent to driver
[INFO][2021-06-08 21:24:59,882][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 101 ms on localhost (executor driver) (19/200)
[INFO][2021-06-08 21:24:59,883][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 81 ms on localhost (executor driver) (20/200)
[INFO][2021-06-08 21:24:59,885][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 254 ms on localhost (executor driver) (21/200)
[INFO][2021-06-08 21:24:59,885][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,885][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,886][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,887][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2268 bytes result sent to driver
[INFO][2021-06-08 21:24:59,888][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-08 21:24:59,887][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,893][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-08 21:24:59,894][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2350 bytes result sent to driver
[INFO][2021-06-08 21:24:59,896][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2372 bytes result sent to driver
[INFO][2021-06-08 21:24:59,897][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,897][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,898][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,902][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-08 21:24:59,904][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2287 bytes result sent to driver
[INFO][2021-06-08 21:24:59,898][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,905][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,905][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,906][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2355 bytes result sent to driver
[INFO][2021-06-08 21:24:59,906][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,907][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-08 21:24:59,906][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-08 21:24:59,908][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,909][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-08 21:24:59,909][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,911][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,911][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,911][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-08 21:24:59,911][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,912][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,913][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-08 21:24:59,913][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-08 21:24:59,914][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,914][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,915][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,915][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,916][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,916][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2285 bytes result sent to driver
[INFO][2021-06-08 21:24:59,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,913][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,920][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2285 bytes result sent to driver
[INFO][2021-06-08 21:24:59,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,921][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:24:59,922][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,916][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,923][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,923][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-08 21:24:59,923][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-08 21:24:59,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,928][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,920][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,928][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-08 21:24:59,928][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 142 ms on localhost (executor driver) (22/200)
[INFO][2021-06-08 21:24:59,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,929][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:24:59,929][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2255 bytes result sent to driver
[INFO][2021-06-08 21:24:59,929][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 118 ms on localhost (executor driver) (23/200)
[INFO][2021-06-08 21:24:59,929][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 142 ms on localhost (executor driver) (24/200)
[INFO][2021-06-08 21:24:59,930][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 140 ms on localhost (executor driver) (25/200)
[INFO][2021-06-08 21:24:59,930][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 123 ms on localhost (executor driver) (26/200)
[INFO][2021-06-08 21:24:59,931][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 121 ms on localhost (executor driver) (27/200)
[INFO][2021-06-08 21:24:59,931][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,931][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,931][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 125 ms on localhost (executor driver) (28/200)
[INFO][2021-06-08 21:24:59,927][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2445 bytes result sent to driver
[INFO][2021-06-08 21:24:59,923][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2287 bytes result sent to driver
[INFO][2021-06-08 21:24:59,932][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 129 ms on localhost (executor driver) (29/200)
[INFO][2021-06-08 21:24:59,933][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 86 ms on localhost (executor driver) (30/200)
[INFO][2021-06-08 21:24:59,934][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 80 ms on localhost (executor driver) (31/200)
[INFO][2021-06-08 21:24:59,934][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 78 ms on localhost (executor driver) (32/200)
[INFO][2021-06-08 21:24:59,935][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 121 ms on localhost (executor driver) (33/200)
[INFO][2021-06-08 21:24:59,935][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2371 bytes result sent to driver
[INFO][2021-06-08 21:24:59,936][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 135 ms on localhost (executor driver) (34/200)
[INFO][2021-06-08 21:24:59,936][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2284 bytes result sent to driver
[INFO][2021-06-08 21:24:59,936][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2371 bytes result sent to driver
[INFO][2021-06-08 21:24:59,938][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,938][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 130 ms on localhost (executor driver) (35/200)
[INFO][2021-06-08 21:24:59,939][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-08 21:24:59,940][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2370 bytes result sent to driver
[INFO][2021-06-08 21:24:59,941][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,941][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-08 21:24:59,942][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,942][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 84 ms on localhost (executor driver) (36/200)
[INFO][2021-06-08 21:24:59,943][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 68 ms on localhost (executor driver) (37/200)
[INFO][2021-06-08 21:24:59,943][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-08 21:24:59,942][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,944][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,945][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-08 21:24:59,945][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,946][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-08 21:24:59,946][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,946][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,947][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,946][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,948][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,948][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,949][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-08 21:24:59,949][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 79 ms on localhost (executor driver) (38/200)
[INFO][2021-06-08 21:24:59,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,950][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 64 ms on localhost (executor driver) (39/200)
[INFO][2021-06-08 21:24:59,951][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2363 bytes result sent to driver
[INFO][2021-06-08 21:24:59,951][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 65 ms on localhost (executor driver) (40/200)
[INFO][2021-06-08 21:24:59,953][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,953][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,954][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-08 21:24:59,955][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,956][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,955][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:63249 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:59,957][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2360 bytes result sent to driver
[INFO][2021-06-08 21:24:59,956][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-08 21:24:59,958][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2364 bytes result sent to driver
[INFO][2021-06-08 21:24:59,956][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2265 bytes result sent to driver
[INFO][2021-06-08 21:24:59,956][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,957][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,957][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,957][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-08 21:24:59,959][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-08 21:24:59,960][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,960][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,960][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,961][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,961][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-08 21:24:59,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,962][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-08 21:24:59,959][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:24:59,962][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2432 bytes result sent to driver
[INFO][2021-06-08 21:24:59,962][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,962][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,964][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:24:59,964][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,964][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-08 21:24:59,965][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,965][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,966][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-08 21:24:59,965][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,967][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-08 21:24:59,968][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,967][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,969][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,968][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2350 bytes result sent to driver
[INFO][2021-06-08 21:24:59,968][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,970][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:24:59,968][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,972][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:24:59,972][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,973][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2285 bytes result sent to driver
[INFO][2021-06-08 21:24:59,973][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,974][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,974][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,974][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-08 21:24:59,969][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:63249 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:24:59,969][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-08 21:24:59,978][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2361 bytes result sent to driver
[INFO][2021-06-08 21:24:59,969][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,979][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2371 bytes result sent to driver
[INFO][2021-06-08 21:24:59,975][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,974][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2268 bytes result sent to driver
[INFO][2021-06-08 21:24:59,980][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-08 21:24:59,974][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-08 21:24:59,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,973][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2352 bytes result sent to driver
[INFO][2021-06-08 21:24:59,973][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-08 21:24:59,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,980][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,985][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2259 bytes result sent to driver
[INFO][2021-06-08 21:24:59,985][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-08 21:24:59,980][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2364 bytes result sent to driver
[INFO][2021-06-08 21:24:59,979][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,986][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:24:59,987][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,987][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,985][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,990][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:24:59,992][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2341 bytes result sent to driver
[INFO][2021-06-08 21:24:59,987][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,993][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2370 bytes result sent to driver
[INFO][2021-06-08 21:24:59,993][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 96 ms on localhost (executor driver) (41/200)
[INFO][2021-06-08 21:24:59,992][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-08 21:24:59,990][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2370 bytes result sent to driver
[INFO][2021-06-08 21:24:59,995][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,996][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-08 21:24:59,997][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2281 bytes result sent to driver
[INFO][2021-06-08 21:24:59,997][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-08 21:24:59,998][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 89 ms on localhost (executor driver) (42/200)
[INFO][2021-06-08 21:24:59,998][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 86 ms on localhost (executor driver) (43/200)
[INFO][2021-06-08 21:24:59,998][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2369 bytes result sent to driver
[INFO][2021-06-08 21:24:59,998][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-08 21:24:59,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:24:59,999][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:24:59,998][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 87 ms on localhost (executor driver) (44/200)
[INFO][2021-06-08 21:25:00,000][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 92 ms on localhost (executor driver) (45/200)
[INFO][2021-06-08 21:25:00,000][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 94 ms on localhost (executor driver) (46/200)
[INFO][2021-06-08 21:25:00,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,002][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 89 ms on localhost (executor driver) (47/200)
[INFO][2021-06-08 21:25:00,003][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 66 ms on localhost (executor driver) (48/200)
[INFO][2021-06-08 21:25:00,003][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 59 ms on localhost (executor driver) (49/200)
[INFO][2021-06-08 21:25:00,007][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 86 ms on localhost (executor driver) (50/200)
[INFO][2021-06-08 21:25:00,008][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 68 ms on localhost (executor driver) (51/200)
[INFO][2021-06-08 21:25:00,008][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2361 bytes result sent to driver
[INFO][2021-06-08 21:25:00,008][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 67 ms on localhost (executor driver) (52/200)
[INFO][2021-06-08 21:25:00,009][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2359 bytes result sent to driver
[INFO][2021-06-08 21:25:00,009][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 87 ms on localhost (executor driver) (53/200)
[INFO][2021-06-08 21:25:00,010][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 63 ms on localhost (executor driver) (54/200)
[INFO][2021-06-08 21:25:00,010][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 56 ms on localhost (executor driver) (55/200)
[INFO][2021-06-08 21:25:00,011][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 54 ms on localhost (executor driver) (56/200)
[INFO][2021-06-08 21:25:00,008][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2434 bytes result sent to driver
[INFO][2021-06-08 21:25:00,012][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 60 ms on localhost (executor driver) (57/200)
[INFO][2021-06-08 21:25:00,012][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 67 ms on localhost (executor driver) (58/200)
[INFO][2021-06-08 21:25:00,013][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,014][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-08 21:25:00,016][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,016][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-08 21:25:00,017][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,018][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,018][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,018][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,018][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-08 21:25:00,019][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-08 21:25:00,019][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,020][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 123 ms on localhost (executor driver) (59/200)
[INFO][2021-06-08 21:25:00,020][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 60 ms on localhost (executor driver) (60/200)
[INFO][2021-06-08 21:25:00,021][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,022][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,024][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-08 21:25:00,026][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,026][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,027][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,027][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,029][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,022][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:25:00,032][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,032][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-08 21:25:00,033][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2369 bytes result sent to driver
[INFO][2021-06-08 21:25:00,034][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,034][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2371 bytes result sent to driver
[INFO][2021-06-08 21:25:00,036][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,035][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-08 21:25:00,035][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,036][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,038][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2361 bytes result sent to driver
[INFO][2021-06-08 21:25:00,038][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,039][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-08 21:25:00,040][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,041][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,041][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-08 21:25:00,041][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,043][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-08 21:25:00,040][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:00,044][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2343 bytes result sent to driver
[INFO][2021-06-08 21:25:00,044][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,043][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,041][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,041][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,041][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-08 21:25:00,045][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-08 21:25:00,045][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:25:00,045][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:25:00,046][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,046][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,047][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,048][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,048][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,044][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,049][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,049][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,053][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2338 bytes result sent to driver
[INFO][2021-06-08 21:25:00,044][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-08 21:25:00,048][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-08 21:25:00,057][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,048][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,058][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,059][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,048][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-08 21:25:00,060][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,059][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-08 21:25:00,061][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,062][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,062][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,062][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,063][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,059][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:25:00,064][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-08 21:25:00,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,058][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-08 21:25:00,057][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,065][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2347 bytes result sent to driver
[INFO][2021-06-08 21:25:00,064][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,067][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,067][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,064][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,064][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-08 21:25:00,068][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,069][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,069][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,063][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-08 21:25:00,070][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2355 bytes result sent to driver
[INFO][2021-06-08 21:25:00,070][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-08 21:25:00,062][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,070][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
[INFO][2021-06-08 21:25:00,071][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,061][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-08 21:25:00,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,073][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,074][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2350 bytes result sent to driver
[INFO][2021-06-08 21:25:00,075][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,075][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,081][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-08 21:25:00,082][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,061][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-08 21:25:00,084][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,084][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,060][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2375 bytes result sent to driver
[INFO][2021-06-08 21:25:00,060][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,085][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2370 bytes result sent to driver
[INFO][2021-06-08 21:25:00,081][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2371 bytes result sent to driver
[INFO][2021-06-08 21:25:00,072][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,086][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
[INFO][2021-06-08 21:25:00,070][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,086][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2352 bytes result sent to driver
[INFO][2021-06-08 21:25:00,085][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2276 bytes result sent to driver
[INFO][2021-06-08 21:25:00,086][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-08 21:25:00,085][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,087][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,087][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,087][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-08 21:25:00,088][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,089][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,088][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2275 bytes result sent to driver
[INFO][2021-06-08 21:25:00,089][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-08 21:25:00,089][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,089][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 124 ms on localhost (executor driver) (61/200)
[INFO][2021-06-08 21:25:00,090][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,091][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,090][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 131 ms on localhost (executor driver) (62/200)
[INFO][2021-06-08 21:25:00,092][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,092][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,092][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,093][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2276 bytes result sent to driver
[INFO][2021-06-08 21:25:00,092][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,094][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-08 21:25:00,094][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,095][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,095][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-08 21:25:00,095][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,096][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 140 ms on localhost (executor driver) (63/200)
[INFO][2021-06-08 21:25:00,097][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 129 ms on localhost (executor driver) (64/200)
[INFO][2021-06-08 21:25:00,096][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-08 21:25:00,098][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,098][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,098][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-08 21:25:00,097][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 127 ms on localhost (executor driver) (65/200)
[INFO][2021-06-08 21:25:00,099][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,098][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,100][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,100][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2364 bytes result sent to driver
[INFO][2021-06-08 21:25:00,100][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,100][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 127 ms on localhost (executor driver) (66/200)
[INFO][2021-06-08 21:25:00,100][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 139 ms on localhost (executor driver) (67/200)
[INFO][2021-06-08 21:25:00,100][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-08 21:25:00,101][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 127 ms on localhost (executor driver) (68/200)
[INFO][2021-06-08 21:25:00,101][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,101][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 117 ms on localhost (executor driver) (69/200)
[INFO][2021-06-08 21:25:00,101][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,101][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 121 ms on localhost (executor driver) (70/200)
[INFO][2021-06-08 21:25:00,102][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 138 ms on localhost (executor driver) (71/200)
[INFO][2021-06-08 21:25:00,102][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 84 ms on localhost (executor driver) (72/200)
[INFO][2021-06-08 21:25:00,103][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 84 ms on localhost (executor driver) (73/200)
[INFO][2021-06-08 21:25:00,103][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,104][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,104][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,104][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 109 ms on localhost (executor driver) (74/200)
[INFO][2021-06-08 21:25:00,104][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-08 21:25:00,105][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2372 bytes result sent to driver
[INFO][2021-06-08 21:25:00,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 109 ms on localhost (executor driver) (75/200)
[INFO][2021-06-08 21:25:00,106][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 134 ms on localhost (executor driver) (76/200)
[INFO][2021-06-08 21:25:00,106][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 90 ms on localhost (executor driver) (77/200)
[INFO][2021-06-08 21:25:00,106][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2346 bytes result sent to driver
[INFO][2021-06-08 21:25:00,107][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,107][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,107][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,108][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,108][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 96 ms on localhost (executor driver) (78/200)
[INFO][2021-06-08 21:25:00,108][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-08 21:25:00,109][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2363 bytes result sent to driver
[INFO][2021-06-08 21:25:00,109][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,109][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 88 ms on localhost (executor driver) (79/200)
[INFO][2021-06-08 21:25:00,109][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-08 21:25:00,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 94 ms on localhost (executor driver) (80/200)
[INFO][2021-06-08 21:25:00,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 70 ms on localhost (executor driver) (81/200)
[INFO][2021-06-08 21:25:00,110][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 69 ms on localhost (executor driver) (82/200)
[INFO][2021-06-08 21:25:00,110][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,111][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 66 ms on localhost (executor driver) (83/200)
[INFO][2021-06-08 21:25:00,111][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,111][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 74 ms on localhost (executor driver) (84/200)
[INFO][2021-06-08 21:25:00,111][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 49 ms on localhost (executor driver) (85/200)
[INFO][2021-06-08 21:25:00,112][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 79 ms on localhost (executor driver) (86/200)
[INFO][2021-06-08 21:25:00,112][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,113][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,113][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,113][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-08 21:25:00,114][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2342 bytes result sent to driver
[INFO][2021-06-08 21:25:00,114][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,114][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 46 ms on localhost (executor driver) (87/200)
[INFO][2021-06-08 21:25:00,115][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-08 21:25:00,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 73 ms on localhost (executor driver) (88/200)
[INFO][2021-06-08 21:25:00,115][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 58 ms on localhost (executor driver) (89/200)
[INFO][2021-06-08 21:25:00,116][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 81 ms on localhost (executor driver) (90/200)
[INFO][2021-06-08 21:25:00,116][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,116][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 69 ms on localhost (executor driver) (91/200)
[INFO][2021-06-08 21:25:00,116][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,117][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 58 ms on localhost (executor driver) (92/200)
[INFO][2021-06-08 21:25:00,117][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,117][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,118][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,118][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,118][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 55 ms on localhost (executor driver) (93/200)
[INFO][2021-06-08 21:25:00,118][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-08 21:25:00,119][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 72 ms on localhost (executor driver) (94/200)
[INFO][2021-06-08 21:25:00,119][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,119][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,120][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 81 ms on localhost (executor driver) (95/200)
[INFO][2021-06-08 21:25:00,120][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-08 21:25:00,121][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,121][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,121][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,121][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 63 ms on localhost (executor driver) (96/200)
[INFO][2021-06-08 21:25:00,121][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-08 21:25:00,122][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 61 ms on localhost (executor driver) (97/200)
[INFO][2021-06-08 21:25:00,123][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,123][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,123][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,123][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,124][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,124][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 60 ms on localhost (executor driver) (98/200)
[INFO][2021-06-08 21:25:00,124][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-08 21:25:00,125][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,125][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,125][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,126][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-08 21:25:00,126][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,127][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,127][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,127][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-08 21:25:00,128][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,129][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,129][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,129][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,129][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-08 21:25:00,129][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,131][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,131][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2332 bytes result sent to driver
[INFO][2021-06-08 21:25:00,131][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-08 21:25:00,132][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,131][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,133][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,133][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-08 21:25:00,134][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,134][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,135][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,135][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,135][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-08 21:25:00,136][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,136][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,136][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2361 bytes result sent to driver
[INFO][2021-06-08 21:25:00,135][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,136][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2371 bytes result sent to driver
[INFO][2021-06-08 21:25:00,136][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,138][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 69 ms on localhost (executor driver) (99/200)
[INFO][2021-06-08 21:25:00,139][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-08 21:25:00,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 53 ms on localhost (executor driver) (100/200)
[INFO][2021-06-08 21:25:00,139][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 48 ms on localhost (executor driver) (101/200)
[INFO][2021-06-08 21:25:00,139][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,140][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,140][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,141][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,142][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,142][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-08 21:25:00,143][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2267 bytes result sent to driver
[INFO][2021-06-08 21:25:00,142][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,146][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2282 bytes result sent to driver
[INFO][2021-06-08 21:25:00,145][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,147][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-08 21:25:00,147][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,147][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2283 bytes result sent to driver
[INFO][2021-06-08 21:25:00,147][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2265 bytes result sent to driver
[INFO][2021-06-08 21:25:00,148][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,148][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 54 ms on localhost (executor driver) (102/200)
[INFO][2021-06-08 21:25:00,149][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2347 bytes result sent to driver
[INFO][2021-06-08 21:25:00,148][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-08 21:25:00,149][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 46 ms on localhost (executor driver) (103/200)
[INFO][2021-06-08 21:25:00,150][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 63 ms on localhost (executor driver) (104/200)
[INFO][2021-06-08 21:25:00,150][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 51 ms on localhost (executor driver) (105/200)
[INFO][2021-06-08 21:25:00,150][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,150][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,151][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,151][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 44 ms on localhost (executor driver) (106/200)
[INFO][2021-06-08 21:25:00,152][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 56 ms on localhost (executor driver) (107/200)
[INFO][2021-06-08 21:25:00,152][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-08 21:25:00,152][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,153][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,152][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,154][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-08 21:25:00,154][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 45 ms on localhost (executor driver) (108/200)
[INFO][2021-06-08 21:25:00,154][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2371 bytes result sent to driver
[INFO][2021-06-08 21:25:00,155][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 43 ms on localhost (executor driver) (109/200)
[INFO][2021-06-08 21:25:00,155][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 42 ms on localhost (executor driver) (110/200)
[INFO][2021-06-08 21:25:00,156][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,156][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,157][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,157][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2277 bytes result sent to driver
[INFO][2021-06-08 21:25:00,157][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-08 21:25:00,157][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,158][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,158][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,159][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2277 bytes result sent to driver
[INFO][2021-06-08 21:25:00,159][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-08 21:25:00,160][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,160][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,160][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,160][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-08 21:25:00,161][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,162][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2363 bytes result sent to driver
[INFO][2021-06-08 21:25:00,162][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-08 21:25:00,163][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,163][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,163][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,164][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-08 21:25:00,164][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 45 ms on localhost (executor driver) (111/200)
[INFO][2021-06-08 21:25:00,164][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 44 ms on localhost (executor driver) (112/200)
[INFO][2021-06-08 21:25:00,165][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 39 ms on localhost (executor driver) (113/200)
[INFO][2021-06-08 21:25:00,167][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,167][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,168][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,168][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,169][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-08 21:25:00,169][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,169][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,169][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,169][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,171][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-08 21:25:00,171][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 48 ms on localhost (executor driver) (114/200)
[INFO][2021-06-08 21:25:00,172][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,175][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:25:00,174][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 57 ms on localhost (executor driver) (115/200)
[INFO][2021-06-08 21:25:00,173][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,176][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:25:00,176][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2244 bytes result sent to driver
[INFO][2021-06-08 21:25:00,177][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:00,177][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,179][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2368 bytes result sent to driver
[INFO][2021-06-08 21:25:00,179][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2372 bytes result sent to driver
[INFO][2021-06-08 21:25:00,179][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,180][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-08 21:25:00,180][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,181][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,182][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,182][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-08 21:25:00,182][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2363 bytes result sent to driver
[INFO][2021-06-08 21:25:00,184][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,183][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-08 21:25:00,182][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,185][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:25:00,186][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,189][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-08 21:25:00,190][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,190][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,193][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,193][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,193][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-08 21:25:00,193][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 61 ms on localhost (executor driver) (116/200)
[INFO][2021-06-08 21:25:00,194][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 65 ms on localhost (executor driver) (117/200)
[INFO][2021-06-08 21:25:00,194][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 59 ms on localhost (executor driver) (118/200)
[INFO][2021-06-08 21:25:00,194][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 54 ms on localhost (executor driver) (119/200)
[INFO][2021-06-08 21:25:00,196][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,196][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,197][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,197][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,199][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 74 ms on localhost (executor driver) (120/200)
[INFO][2021-06-08 21:25:00,197][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,199][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,201][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,202][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-08 21:25:00,203][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,204][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,205][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-08 21:25:00,206][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,204][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2257 bytes result sent to driver
[INFO][2021-06-08 21:25:00,204][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,206][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,208][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,208][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,211][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,205][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,213][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2284 bytes result sent to driver
[INFO][2021-06-08 21:25:00,213][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,213][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-08 21:25:00,213][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,215][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,215][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-08 21:25:00,216][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-08 21:25:00,216][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,216][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,216][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,217][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,218][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,218][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,219][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,219][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,219][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,220][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,221][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,221][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-08 21:25:00,222][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,222][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2278 bytes result sent to driver
[INFO][2021-06-08 21:25:00,219][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-08 21:25:00,223][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-08 21:25:00,224][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,225][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,225][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2347 bytes result sent to driver
[INFO][2021-06-08 21:25:00,225][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,226][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,226][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:00,227][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,227][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,229][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-08 21:25:00,229][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-08 21:25:00,230][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,232][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2254 bytes result sent to driver
[INFO][2021-06-08 21:25:00,232][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2284 bytes result sent to driver
[INFO][2021-06-08 21:25:00,232][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-08 21:25:00,223][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,233][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-08 21:25:00,234][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,235][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-08 21:25:00,232][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,236][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:25:00,235][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,235][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,236][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,238][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,238][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,238][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,239][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-08 21:25:00,239][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,233][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,240][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 7 ms
[INFO][2021-06-08 21:25:00,240][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,241][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,242][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,238][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-08 21:25:00,236][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,242][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
[INFO][2021-06-08 21:25:00,244][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2371 bytes result sent to driver
[INFO][2021-06-08 21:25:00,242][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,242][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-08 21:25:00,244][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-08 21:25:00,242][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-08 21:25:00,245][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,245][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,241][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,246][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:25:00,247][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,247][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,248][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,249][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,245][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,250][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2368 bytes result sent to driver
[INFO][2021-06-08 21:25:00,251][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,252][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,252][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-08 21:25:00,244][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-08 21:25:00,253][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,254][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2344 bytes result sent to driver
[INFO][2021-06-08 21:25:00,255][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-08 21:25:00,255][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,256][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,253][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,257][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,258][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-08 21:25:00,252][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-08 21:25:00,258][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,261][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,261][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,262][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,262][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-08 21:25:00,247][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,263][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
[INFO][2021-06-08 21:25:00,262][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,265][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,265][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,270][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-08 21:25:00,271][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2352 bytes result sent to driver
[INFO][2021-06-08 21:25:00,272][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:00,273][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,273][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:00,261][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,258][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,256][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,275][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 19 ms
[INFO][2021-06-08 21:25:00,275][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-08 21:25:00,277][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,274][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 13 ms
[INFO][2021-06-08 21:25:00,271][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2361 bytes result sent to driver
[INFO][2021-06-08 21:25:00,265][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2368 bytes result sent to driver
[INFO][2021-06-08 21:25:00,277][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,279][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,279][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,279][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-08 21:25:00,279][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,280][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,281][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,282][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-08 21:25:00,283][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,283][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2276 bytes result sent to driver
[INFO][2021-06-08 21:25:00,282][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,284][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,285][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2339 bytes result sent to driver
[INFO][2021-06-08 21:25:00,286][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,286][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,286][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-08 21:25:00,284][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,284][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-08 21:25:00,289][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-08 21:25:00,289][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,290][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,283][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-08 21:25:00,290][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,291][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,291][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,291][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,290][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,288][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,285][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2282 bytes result sent to driver
[INFO][2021-06-08 21:25:00,294][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,294][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,292][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,295][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-08 21:25:00,294][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,295][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 149 ms on localhost (executor driver) (121/200)
[INFO][2021-06-08 21:25:00,295][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-08 21:25:00,296][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 146 ms on localhost (executor driver) (122/200)
[INFO][2021-06-08 21:25:00,296][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 136 ms on localhost (executor driver) (123/200)
[INFO][2021-06-08 21:25:00,297][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,297][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,298][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 136 ms on localhost (executor driver) (124/200)
[INFO][2021-06-08 21:25:00,298][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 141 ms on localhost (executor driver) (125/200)
[INFO][2021-06-08 21:25:00,299][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,297][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-08 21:25:00,300][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,300][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,299][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 147 ms on localhost (executor driver) (126/200)
[INFO][2021-06-08 21:25:00,298][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,301][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,301][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 174 ms on localhost (executor driver) (127/200)
[INFO][2021-06-08 21:25:00,302][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 169 ms on localhost (executor driver) (128/200)
[INFO][2021-06-08 21:25:00,302][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-08 21:25:00,302][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 143 ms on localhost (executor driver) (129/200)
[INFO][2021-06-08 21:25:00,302][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2283 bytes result sent to driver
[INFO][2021-06-08 21:25:00,304][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,304][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-08 21:25:00,304][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,304][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 162 ms on localhost (executor driver) (130/200)
[INFO][2021-06-08 21:25:00,305][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,305][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,305][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-08 21:25:00,306][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,306][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,306][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,307][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,306][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,306][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2374 bytes result sent to driver
[INFO][2021-06-08 21:25:00,308][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,309][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,309][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,309][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-08 21:25:00,310][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-08 21:25:00,312][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-08 21:25:00,312][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2267 bytes result sent to driver
[INFO][2021-06-08 21:25:00,309][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,312][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,313][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,313][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-08 21:25:00,313][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2282 bytes result sent to driver
[INFO][2021-06-08 21:25:00,313][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,315][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,313][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,316][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:25:00,317][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,317][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,314][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,319][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:25:00,316][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-08 21:25:00,320][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2359 bytes result sent to driver
[INFO][2021-06-08 21:25:00,316][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,321][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-08 21:25:00,322][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,322][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,324][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2459 bytes result sent to driver
[INFO][2021-06-08 21:25:00,321][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,324][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2464 bytes result sent to driver
[INFO][2021-06-08 21:25:00,324][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,325][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,325][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,325][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-08 21:25:00,326][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-08 21:25:00,327][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-08 21:25:00,326][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2268 bytes result sent to driver
[INFO][2021-06-08 21:25:00,326][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,329][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,329][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-08 21:25:00,329][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,330][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2252 bytes result sent to driver
[INFO][2021-06-08 21:25:00,329][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,330][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,330][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-08 21:25:00,331][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,332][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-08 21:25:00,331][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,332][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,331][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,333][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,334][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,332][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,332][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-08 21:25:00,335][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-08 21:25:00,336][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2368 bytes result sent to driver
[INFO][2021-06-08 21:25:00,335][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,333][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,339][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,339][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,339][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2288 bytes result sent to driver
[INFO][2021-06-08 21:25:00,339][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-08 21:25:00,339][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:25:00,339][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,339][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,339][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,340][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,340][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-08 21:25:00,339][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,341][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,340][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,342][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,343][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-08 21:25:00,344][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,344][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2256 bytes result sent to driver
[INFO][2021-06-08 21:25:00,345][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 188 ms on localhost (executor driver) (131/200)
[INFO][2021-06-08 21:25:00,345][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-08 21:25:00,345][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 156 ms on localhost (executor driver) (132/200)
[INFO][2021-06-08 21:25:00,346][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,346][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 166 ms on localhost (executor driver) (133/200)
[INFO][2021-06-08 21:25:00,346][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 164 ms on localhost (executor driver) (134/200)
[INFO][2021-06-08 21:25:00,346][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,347][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 164 ms on localhost (executor driver) (135/200)
[INFO][2021-06-08 21:25:00,347][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 146 ms on localhost (executor driver) (136/200)
[INFO][2021-06-08 21:25:00,347][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2372 bytes result sent to driver
[INFO][2021-06-08 21:25:00,347][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:25:00,347][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2359 bytes result sent to driver
[INFO][2021-06-08 21:25:00,348][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2355 bytes result sent to driver
[INFO][2021-06-08 21:25:00,349][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,347][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 147 ms on localhost (executor driver) (137/200)
[INFO][2021-06-08 21:25:00,350][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,349][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,351][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 185 ms on localhost (executor driver) (138/200)
[INFO][2021-06-08 21:25:00,353][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 140 ms on localhost (executor driver) (139/200)
[INFO][2021-06-08 21:25:00,353][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2264 bytes result sent to driver
[INFO][2021-06-08 21:25:00,353][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 185 ms on localhost (executor driver) (140/200)
[INFO][2021-06-08 21:25:00,354][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 135 ms on localhost (executor driver) (141/200)
[INFO][2021-06-08 21:25:00,355][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 149 ms on localhost (executor driver) (142/200)
[INFO][2021-06-08 21:25:00,356][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,357][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 142 ms on localhost (executor driver) (143/200)
[INFO][2021-06-08 21:25:00,357][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-08 21:25:00,357][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 137 ms on localhost (executor driver) (144/200)
[INFO][2021-06-08 21:25:00,357][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 124 ms on localhost (executor driver) (145/200)
[INFO][2021-06-08 21:25:00,358][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 135 ms on localhost (executor driver) (146/200)
[INFO][2021-06-08 21:25:00,358][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 179 ms on localhost (executor driver) (147/200)
[INFO][2021-06-08 21:25:00,359][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 124 ms on localhost (executor driver) (148/200)
[INFO][2021-06-08 21:25:00,359][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 141 ms on localhost (executor driver) (149/200)
[INFO][2021-06-08 21:25:00,359][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2283 bytes result sent to driver
[INFO][2021-06-08 21:25:00,360][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 108 ms on localhost (executor driver) (150/200)
[INFO][2021-06-08 21:25:00,360][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,360][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,360][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2276 bytes result sent to driver
[INFO][2021-06-08 21:25:00,361][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,361][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 146 ms on localhost (executor driver) (151/200)
[INFO][2021-06-08 21:25:00,361][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-08 21:25:00,362][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 145 ms on localhost (executor driver) (152/200)
[INFO][2021-06-08 21:25:00,362][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 126 ms on localhost (executor driver) (153/200)
[INFO][2021-06-08 21:25:00,362][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 123 ms on localhost (executor driver) (154/200)
[INFO][2021-06-08 21:25:00,365][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 143 ms on localhost (executor driver) (155/200)
[INFO][2021-06-08 21:25:00,365][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 124 ms on localhost (executor driver) (156/200)
[INFO][2021-06-08 21:25:00,366][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 124 ms on localhost (executor driver) (157/200)
[INFO][2021-06-08 21:25:00,365][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,366][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,366][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 122 ms on localhost (executor driver) (158/200)
[INFO][2021-06-08 21:25:00,367][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 110 ms on localhost (executor driver) (159/200)
[INFO][2021-06-08 21:25:00,368][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,369][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-08 21:25:00,369][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2361 bytes result sent to driver
[INFO][2021-06-08 21:25:00,369][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,370][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 120 ms on localhost (executor driver) (160/200)
[INFO][2021-06-08 21:25:00,370][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-08 21:25:00,370][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 118 ms on localhost (executor driver) (161/200)
[INFO][2021-06-08 21:25:00,370][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 114 ms on localhost (executor driver) (162/200)
[INFO][2021-06-08 21:25:00,370][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 91 ms on localhost (executor driver) (163/200)
[INFO][2021-06-08 21:25:00,371][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 89 ms on localhost (executor driver) (164/200)
[INFO][2021-06-08 21:25:00,371][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 91 ms on localhost (executor driver) (165/200)
[INFO][2021-06-08 21:25:00,371][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 131 ms on localhost (executor driver) (166/200)
[INFO][2021-06-08 21:25:00,372][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 97 ms on localhost (executor driver) (167/200)
[INFO][2021-06-08 21:25:00,372][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 91 ms on localhost (executor driver) (168/200)
[INFO][2021-06-08 21:25:00,373][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 70 ms on localhost (executor driver) (169/200)
[INFO][2021-06-08 21:25:00,373][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,373][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,374][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,373][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2287 bytes result sent to driver
[INFO][2021-06-08 21:25:00,373][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,374][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,374][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 87 ms on localhost (executor driver) (170/200)
[INFO][2021-06-08 21:25:00,374][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-08 21:25:00,375][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 81 ms on localhost (executor driver) (171/200)
[INFO][2021-06-08 21:25:00,376][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,377][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,377][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-08 21:25:00,377][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,378][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,378][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-08 21:25:00,379][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,377][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 77 ms on localhost (executor driver) (172/200)
[INFO][2021-06-08 21:25:00,379][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2363 bytes result sent to driver
[INFO][2021-06-08 21:25:00,380][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 96 ms on localhost (executor driver) (173/200)
[INFO][2021-06-08 21:25:00,380][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 74 ms on localhost (executor driver) (174/200)
[INFO][2021-06-08 21:25:00,380][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,380][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,381][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,381][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,381][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:25:00,382][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-08 21:25:00,382][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-08 21:25:00,382][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-08 21:25:00,382][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2349 bytes result sent to driver
[INFO][2021-06-08 21:25:00,382][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 77 ms on localhost (executor driver) (175/200)
[INFO][2021-06-08 21:25:00,384][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 79 ms on localhost (executor driver) (176/200)
[INFO][2021-06-08 21:25:00,384][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,385][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:25:00,384][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:25:00,386][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:25:00,385][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2278 bytes result sent to driver
[INFO][2021-06-08 21:25:00,386][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2281 bytes result sent to driver
[INFO][2021-06-08 21:25:00,386][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 79 ms on localhost (executor driver) (177/200)
[INFO][2021-06-08 21:25:00,387][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 74 ms on localhost (executor driver) (178/200)
[INFO][2021-06-08 21:25:00,387][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 71 ms on localhost (executor driver) (179/200)
[INFO][2021-06-08 21:25:00,388][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 80 ms on localhost (executor driver) (180/200)
[INFO][2021-06-08 21:25:00,389][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 65 ms on localhost (executor driver) (181/200)
[INFO][2021-06-08 21:25:00,389][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 68 ms on localhost (executor driver) (182/200)
[INFO][2021-06-08 21:25:00,390][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2280 bytes result sent to driver
[INFO][2021-06-08 21:25:00,390][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2282 bytes result sent to driver
[INFO][2021-06-08 21:25:00,390][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 58 ms on localhost (executor driver) (183/200)
[INFO][2021-06-08 21:25:00,390][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 60 ms on localhost (executor driver) (184/200)
[INFO][2021-06-08 21:25:00,391][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 55 ms on localhost (executor driver) (185/200)
[INFO][2021-06-08 21:25:00,391][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 66 ms on localhost (executor driver) (186/200)
[INFO][2021-06-08 21:25:00,391][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 52 ms on localhost (executor driver) (187/200)
[INFO][2021-06-08 21:25:00,392][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 61 ms on localhost (executor driver) (188/200)
[INFO][2021-06-08 21:25:00,392][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 63 ms on localhost (executor driver) (189/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 53 ms on localhost (executor driver) (190/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 50 ms on localhost (executor driver) (191/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 38 ms on localhost (executor driver) (192/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 24 ms on localhost (executor driver) (193/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 26 ms on localhost (executor driver) (194/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 33 ms on localhost (executor driver) (195/200)
[INFO][2021-06-08 21:25:00,393][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 20 ms on localhost (executor driver) (196/200)
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 19 ms on localhost (executor driver) (197/200)
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 18 ms on localhost (executor driver) (198/200)
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 13 ms on localhost (executor driver) (199/200)
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 14 ms on localhost (executor driver) (200/200)
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:25:00,394][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.776 s
[INFO][2021-06-08 21:25:00,395][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 1.205538 s
[INFO][2021-06-08 21:25:00,436][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.135 ms
[INFO][2021-06-08 21:25:00,458][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:00,463][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:00,464][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:25:00,465][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-08 21:25:00,465][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:00,470][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:00,471][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:25:00,472][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-08 21:25:00,473][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-08 21:25:00,476][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-08 21:25:00,510][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-08 21:25:00,514][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-08 21:25:00,515][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:25:00,515][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:347
[INFO][2021-06-08 21:25:00,525][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-08 21:25:00,529][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-08 21:25:00,530][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:25:00,530][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:316
[INFO][2021-06-08 21:25:04,610][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:25:04,616][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:25:04,617][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:25:04,811][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 32.359099 ms
[INFO][2021-06-08 21:25:04,824][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-08 21:25:04,824][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-08 21:25:04,825][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:25:04,825][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:25:04,825][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:25:04,825][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-08 21:25:04,838][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:04,841][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:04,842][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63249 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:25:04,842][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:25:04,843][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:25:04,843][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 21:25:04,844][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:25:04,845][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-08 21:25:04,958][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:25:04,961][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2360 bytes result sent to driver
[INFO][2021-06-08 21:25:04,962][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 119 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:25:04,962][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.119 s
[INFO][2021-06-08 21:25:04,962][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:25:04,963][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.138542 s
[INFO][2021-06-08 21:25:05,017][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 45.1103 ms
[INFO][2021-06-08 21:25:05,035][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:25:05,104][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:25:05,108][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-08 21:25:05,108][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:25:05,234][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.52.10:63249 in memory (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:25:05,245][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 58.6802 ms
[INFO][2021-06-08 21:25:05,246][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4926
[INFO][2021-06-08 21:25:05,246][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4927
[INFO][2021-06-08 21:25:05,263][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-08 21:25:05,263][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-08 21:25:05,263][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:25:05,264][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:25:05,264][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:25:05,264][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-08 21:25:05,265][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:05,268][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:25:05,268][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:25:05,269][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:25:05,269][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:25:05,269][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 21:25:05,271][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:25:05,271][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-08 21:25:05,334][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:25:05,336][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2366 bytes result sent to driver
[INFO][2021-06-08 21:25:05,337][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 67 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:25:05,337][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:25:05,337][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.068 s
[INFO][2021-06-08 21:25:05,338][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.074786 s
[INFO][2021-06-08 21:25:05,343][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-08 21:25:05,399][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:25:05,399][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,400][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,400][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,400][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:25:05,401][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:25:05,402][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:25:05,403][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:25:05,403][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:25:05,404][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,404][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,405][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,405][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,405][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,406][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,406][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,407][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,407][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:25:05,408][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,409][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:25:05,410][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,410][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:25:05,411][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,412][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,412][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:25:05,413][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,413][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:25:05,413][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,413][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,414][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,414][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:25:05,438][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.71 ms
[INFO][2021-06-08 21:25:05,441][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-08 21:25:05,456][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk,cast(null as decimal(8,0)) as wssgjkr,cast(null as decimal(8,0)) as wssgtkr,cast(null as decimal(8,0)) as zjxcgpr,cast(null as decimal(8,0)) as fxjgggr from sparktxggl
[INFO][2021-06-08 21:25:05,493][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:26:20,612][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_txggl select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:26:25,986][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:26:25,987][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:25,989][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:25,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:25,992][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:26:25,994][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:26:25,996][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:26:25,998][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:26:25,999][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:26:26,001][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,003][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,005][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,007][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,009][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,010][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,012][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,014][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,016][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:26:26,017][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,019][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:26:26,022][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,023][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:26:26,025][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,027][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:26,029][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:26:26,030][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:26,032][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:26:26,034][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,035][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,037][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:26:26,039][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[WARN][2021-06-08 21:35:31,749][org.apache.spark.HeartbeatReceiver:66] - Removing executor driver with no recent heartbeats: 537399 ms exceeds timeout 120000 ms
[ERROR][2021-06-08 21:35:31,751][org.apache.spark.scheduler.TaskSchedulerImpl:70] - Lost executor driver on localhost: Executor heartbeat timed out after 537399 ms
[INFO][2021-06-08 21:35:31,755][org.apache.spark.scheduler.DAGScheduler:54] - Executor lost: driver (epoch 1)
[INFO][2021-06-08 21:35:31,755][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,756][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,756][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,756][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Trying to remove executor driver from BlockManagerMaster.
[WARN][2021-06-08 21:35:31,758][org.apache.spark.SparkContext:66] - Killing executors is only supported in coarse-grained mode
[INFO][2021-06-08 21:35:31,758][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Removing block manager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,759][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:63249 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,759][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,759][org.apache.spark.storage.BlockManagerMaster:54] - Removed driver successfully in removeExecutor
[INFO][2021-06-08 21:35:31,760][org.apache.spark.scheduler.DAGScheduler:54] - Shuffle files lost for executor: driver (epoch 1)
[INFO][2021-06-08 21:35:31,760][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,761][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,761][org.apache.spark.scheduler.DAGScheduler:54] - Host added was in lost list earlier: localhost
[INFO][2021-06-08 21:35:31,763][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,764][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,765][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,766][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,767][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,767][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,768][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,768][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,768][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,768][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,768][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,769][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,770][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,770][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,771][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,772][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,772][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,773][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,773][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktzqdmbg
[INFO][2021-06-08 21:35:31,773][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,773][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,773][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,774][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,774][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,774][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,775][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,775][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,776][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,776][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:35:31,776][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktzqdmbg limit 10
[INFO][2021-06-08 21:35:31,776][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,777][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,777][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,778][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,778][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,778][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,778][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,778][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,779][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,779][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,780][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,780][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,781][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,782][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,782][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,783][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,783][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,783][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,783][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,784][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,784][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,785][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,785][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,786][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,786][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,787][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,788][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,788][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,788][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,788][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,788][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,789][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,789][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,789][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,790][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,790][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,791][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,792][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,792][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,793][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,793][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,793][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,794][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,794][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,794][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,795][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,795][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,796][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,797][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,798][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,798][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,799][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,799][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,799][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,800][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,800][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,800][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,801][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,802][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,803][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,804][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.1099 ms
[INFO][2021-06-08 21:35:31,804][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,804][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 21:35:31,805][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,805][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,806][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,806][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,806][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,806][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,807][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,807][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,808][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,809][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,810][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,811][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,811][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,811][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:35:31,812][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,813][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,813][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,813][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,814][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,814][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,815][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,815][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,815][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,815][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,815][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,816][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4207609e{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,816][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2f00f851{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,816][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,816][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,816][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,816][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,817][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17690e14{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,817][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,817][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@108a46d6{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,817][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,817][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@23a5818e{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,818][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@10afe71a{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,819][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:35:31,820][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,820][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,821][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,821][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,821][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,821][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,821][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-08 21:35:31,821][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,822][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,823][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,823][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,824][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,825][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,825][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:35:31,826][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:35:31,826][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None) re-registering with master
[INFO][2021-06-08 21:35:31,826][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[ERROR][2021-06-08 21:35:31,827][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[ERROR][2021-06-08 21:35:31,827][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1623159331827,BlockManagerId(driver, 192.168.52.10, 63249, None),4041757163)
[INFO][2021-06-08 21:35:31,827][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63249, None)
[INFO][2021-06-08 21:35:31,827][org.apache.spark.storage.BlockManager:54] - Reporting 14 blocks to the master.
[INFO][2021-06-08 21:35:31,828][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63249 (size: 8.3 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,828][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_9_piece0,StorageLevel(memory, 1 replicas),8495,0))
[INFO][2021-06-08 21:35:31,828][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63249 (size: 16.2 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,829][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_0_piece0,StorageLevel(memory, 1 replicas),16586,0))
[INFO][2021-06-08 21:35:31,830][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63249 (size: 17.2 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,830][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_4_piece0,StorageLevel(memory, 1 replicas),17581,0))
[INFO][2021-06-08 21:35:31,831][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63249 (size: 8.6 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,831][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_3_piece0,StorageLevel(memory, 1 replicas),8807,0))
[INFO][2021-06-08 21:35:31,831][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63249 (size: 124.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,831][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_7_piece0,StorageLevel(memory, 1 replicas),124,0))
[INFO][2021-06-08 21:35:31,832][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63249 (size: 167.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,832][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_6_piece0,StorageLevel(memory, 1 replicas),167,0))
[INFO][2021-06-08 21:35:31,832][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63249 (size: 12.0 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:35:31,832][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63249, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[INFO][2021-06-08 21:35:31,836][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 21:35:31,882][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 21:35:31,883][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 21:35:31,883][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 21:35:31,885][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 21:35:31,888][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 21:35:31,888][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 21:35:31,889][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-2542e408-8dca-43d1-83f5-5666a0b1a05f
[INFO][2021-06-08 21:45:44,787][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:45:44,951][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:45:44,952][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:45:44,952][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:45:44,953][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:45:44,953][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:45:45,818][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63853.
[INFO][2021-06-08 21:45:45,831][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:45:45,844][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:45:45,846][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:45:45,847][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:45:45,855][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-df453003-8829-4bbb-9b29-df1de47df727
[INFO][2021-06-08 21:45:45,865][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:45:45,889][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:45:45,948][org.spark_project.jetty.util.log:186] - Logging initialized @3021ms
[INFO][2021-06-08 21:45:46,019][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:45:46,034][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,034][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,035][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,035][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,035][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@10afe71a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,035][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,035][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,036][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,036][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,036][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,037][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@23a5818e{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,037][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,037][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,037][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,037][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@108a46d6{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17690e14{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,038][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,043][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f00f851{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,044][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4207609e{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,044][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,044][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,045][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,051][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:45:46,051][org.spark_project.jetty.server.Server:379] - Started @3125ms
[INFO][2021-06-08 21:45:46,052][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:45:46,055][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:45:46,107][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:45:46,132][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63894.
[INFO][2021-06-08 21:45:46,132][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:63894
[INFO][2021-06-08 21:45:46,134][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:45:46,136][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:45:46,138][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:63894 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:45:46,142][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:45:46,142][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:45:46,262][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6056232d{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,288][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:45:46,292][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@42a0501e{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,293][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6e4599c0{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,293][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b5c4f17{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,294][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@69f0b0f4{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,295][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1d61a348{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:45:46,345][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:45:46,454][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:45:46,454][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:45:46,455][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:45:46,455][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:45:46,455][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:45:46,456][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:45:46,456][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:45:46,456][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:45:46,648][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:45:46,674][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:45:47,318][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:45:47,386][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/097bf285-a6a6-48e0-89a7-344060368194_resources
[INFO][2021-06-08 21:45:47,393][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/097bf285-a6a6-48e0-89a7-344060368194
[INFO][2021-06-08 21:45:47,397][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/097bf285-a6a6-48e0-89a7-344060368194
[INFO][2021-06-08 21:45:47,400][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/097bf285-a6a6-48e0-89a7-344060368194/_tmp_space.db
[INFO][2021-06-08 21:45:47,403][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:45:47,483][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-08 21:45:48,098][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,102][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,102][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-08 21:45:48,103][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-08 21:45:48,103][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,103][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,104][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,104][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:48,104][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:45:49,473][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:49,606][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:49,610][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:49,615][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:45:50,039][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 200.8104 ms
[INFO][2021-06-08 21:45:50,126][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.311 ms
[INFO][2021-06-08 21:45:50,193][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-08 21:45:50,243][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:45:50,257][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-08 21:45:50,258][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:50,258][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:45:50,259][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:45:50,266][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:45:50,276][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:50,285][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:50,286][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:63894 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:50,286][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:45:50,289][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:50,291][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:45:50,329][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-08 21:45:50,335][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:45:50,366][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:45:50,373][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:45:50,374][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:45:50,374][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:45:50,374][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:45:50,374][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:45:50,408][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.6541 ms
[INFO][2021-06-08 21:45:51,076][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155676 bytes result sent to driver
[INFO][2021-06-08 21:45:51,105][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 793 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:45:51,107][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:45:51,109][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 0.807 s
[INFO][2021-06-08 21:45:51,112][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 0.868277 s
[INFO][2021-06-08 21:45:51,178][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:45:51,181][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:51,182][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-08 21:45:51,182][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:51,182][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:45:51,182][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:45:51,184][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:45:51,194][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:51,198][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:51,199][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:63894 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:51,200][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:45:51,201][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:51,202][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:45:51,204][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-08 21:45:51,205][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:45:51,218][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:45:51,471][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1758 bytes result sent to driver
[INFO][2021-06-08 21:45:51,475][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 273 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:45:51,475][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:45:51,476][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 0.274 s
[INFO][2021-06-08 21:45:51,476][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-08 21:45:51,477][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-08 21:45:51,477][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-08 21:45:51,477][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-08 21:45:51,480][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:45:51,501][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:51,503][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:51,504][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:51,504][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:45:51,505][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:45:51,505][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-08 21:45:51,507][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,508][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,509][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,509][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,510][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,510][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,510][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,511][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,512][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,512][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,513][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,513][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,514][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,515][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,515][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,516][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,516][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:45:51,517][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-08 21:45:51,517][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-08 21:45:51,517][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-08 21:45:51,516][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:45:51,518][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-08 21:45:51,518][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-08 21:45:51,519][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-08 21:45:51,519][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-08 21:45:51,521][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-08 21:45:51,522][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:45:51,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:45:51,580][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.5086 ms
[INFO][2021-06-08 21:45:51,612][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2446 bytes result sent to driver
[INFO][2021-06-08 21:45:51,614][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2537 bytes result sent to driver
[INFO][2021-06-08 21:45:51,614][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,615][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2355 bytes result sent to driver
[INFO][2021-06-08 21:45:51,615][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2464 bytes result sent to driver
[INFO][2021-06-08 21:45:51,615][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2451 bytes result sent to driver
[INFO][2021-06-08 21:45:51,615][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,616][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2363 bytes result sent to driver
[INFO][2021-06-08 21:45:51,617][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2259 bytes result sent to driver
[INFO][2021-06-08 21:45:51,617][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,617][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,617][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2433 bytes result sent to driver
[INFO][2021-06-08 21:45:51,618][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,618][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2362 bytes result sent to driver
[INFO][2021-06-08 21:45:51,617][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-08 21:45:51,618][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2438 bytes result sent to driver
[INFO][2021-06-08 21:45:51,619][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2407 bytes result sent to driver
[INFO][2021-06-08 21:45:51,619][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,620][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2447 bytes result sent to driver
[INFO][2021-06-08 21:45:51,620][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-08 21:45:51,621][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,622][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 111 ms on localhost (executor driver) (1/200)
[INFO][2021-06-08 21:45:51,622][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-08 21:45:51,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,622][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,623][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,623][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 114 ms on localhost (executor driver) (2/200)
[INFO][2021-06-08 21:45:51,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,623][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-08 21:45:51,623][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 108 ms on localhost (executor driver) (3/200)
[INFO][2021-06-08 21:45:51,625][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,625][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,625][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 115 ms on localhost (executor driver) (4/200)
[INFO][2021-06-08 21:45:51,625][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-08 21:45:51,625][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 114 ms on localhost (executor driver) (5/200)
[INFO][2021-06-08 21:45:51,625][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,628][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,628][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,629][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,629][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-08 21:45:51,629][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,629][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,629][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,631][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-08 21:45:51,631][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,631][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,631][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2363 bytes result sent to driver
[INFO][2021-06-08 21:45:51,631][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 119 ms on localhost (executor driver) (6/200)
[INFO][2021-06-08 21:45:51,631][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-08 21:45:51,632][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 117 ms on localhost (executor driver) (7/200)
[INFO][2021-06-08 21:45:51,632][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 120 ms on localhost (executor driver) (8/200)
[INFO][2021-06-08 21:45:51,633][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,633][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2286 bytes result sent to driver
[INFO][2021-06-08 21:45:51,634][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,635][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,635][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,636][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-08 21:45:51,636][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2359 bytes result sent to driver
[INFO][2021-06-08 21:45:51,636][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,635][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,637][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2332 bytes result sent to driver
[INFO][2021-06-08 21:45:51,637][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-08 21:45:51,637][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,637][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,638][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,638][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,638][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,639][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-08 21:45:51,639][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,640][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,640][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,640][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,641][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 132 ms on localhost (executor driver) (9/200)
[INFO][2021-06-08 21:45:51,641][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-08 21:45:51,641][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,642][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,642][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,643][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,643][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,644][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,644][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-08 21:45:51,644][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:51,644][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-08 21:45:51,644][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:51,645][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,646][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,647][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-08 21:45:51,647][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,647][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,647][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2363 bytes result sent to driver
[INFO][2021-06-08 21:45:51,647][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-08 21:45:51,648][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 134 ms on localhost (executor driver) (10/200)
[INFO][2021-06-08 21:45:51,647][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,648][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,649][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,649][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-08 21:45:51,649][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 138 ms on localhost (executor driver) (11/200)
[INFO][2021-06-08 21:45:51,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,650][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,650][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,651][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 145 ms on localhost (executor driver) (12/200)
[INFO][2021-06-08 21:45:51,651][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2372 bytes result sent to driver
[INFO][2021-06-08 21:45:51,652][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,653][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 139 ms on localhost (executor driver) (13/200)
[INFO][2021-06-08 21:45:51,653][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,654][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,654][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:51,654][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-08 21:45:51,654][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 147 ms on localhost (executor driver) (14/200)
[INFO][2021-06-08 21:45:51,656][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 42 ms on localhost (executor driver) (15/200)
[INFO][2021-06-08 21:45:51,656][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 143 ms on localhost (executor driver) (16/200)
[INFO][2021-06-08 21:45:51,657][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,657][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 33 ms on localhost (executor driver) (17/200)
[INFO][2021-06-08 21:45:51,658][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 39 ms on localhost (executor driver) (18/200)
[INFO][2021-06-08 21:45:51,658][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,658][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,659][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2253 bytes result sent to driver
[INFO][2021-06-08 21:45:51,659][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,659][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,659][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 150 ms on localhost (executor driver) (19/200)
[INFO][2021-06-08 21:45:51,659][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-08 21:45:51,660][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:51,660][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,661][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 41 ms on localhost (executor driver) (20/200)
[INFO][2021-06-08 21:45:51,661][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-08 21:45:51,662][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,662][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,663][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 41 ms on localhost (executor driver) (21/200)
[INFO][2021-06-08 21:45:51,663][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-08 21:45:51,663][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,665][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,665][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,666][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,666][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-08 21:45:51,666][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,667][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,667][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-08 21:45:51,668][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,669][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-08 21:45:51,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,670][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,669][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,670][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,671][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-08 21:45:51,671][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2253 bytes result sent to driver
[INFO][2021-06-08 21:45:51,672][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,672][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,673][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,673][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,673][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,674][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,675][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,675][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 49 ms on localhost (executor driver) (22/200)
[INFO][2021-06-08 21:45:51,676][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,675][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-08 21:45:51,676][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 39 ms on localhost (executor driver) (23/200)
[INFO][2021-06-08 21:45:51,679][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,679][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2347 bytes result sent to driver
[INFO][2021-06-08 21:45:51,680][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-08 21:45:51,681][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2361 bytes result sent to driver
[INFO][2021-06-08 21:45:51,681][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,681][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,682][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2342 bytes result sent to driver
[INFO][2021-06-08 21:45:51,681][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,682][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,683][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2375 bytes result sent to driver
[INFO][2021-06-08 21:45:51,684][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-08 21:45:51,684][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,685][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,685][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,685][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-08 21:45:51,686][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,686][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-08 21:45:51,687][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,688][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,688][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-08 21:45:51,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,689][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-08 21:45:51,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,689][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,691][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:51,691][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-08 21:45:51,691][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,692][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,693][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,693][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-08 21:45:51,693][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,694][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,694][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2345 bytes result sent to driver
[INFO][2021-06-08 21:45:51,694][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,695][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,695][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,697][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-08 21:45:51,697][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 67 ms on localhost (executor driver) (24/200)
[INFO][2021-06-08 21:45:51,695][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2451 bytes result sent to driver
[INFO][2021-06-08 21:45:51,698][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,697][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,699][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 63 ms on localhost (executor driver) (25/200)
[INFO][2021-06-08 21:45:51,700][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,700][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,701][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,701][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,700][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 67 ms on localhost (executor driver) (26/200)
[INFO][2021-06-08 21:45:51,701][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,701][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,702][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,702][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-08 21:45:51,703][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,704][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,704][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-08 21:45:51,704][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-08 21:45:51,704][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 75 ms on localhost (executor driver) (27/200)
[INFO][2021-06-08 21:45:51,705][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,706][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,706][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,707][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-08 21:45:51,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,708][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2371 bytes result sent to driver
[INFO][2021-06-08 21:45:51,708][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,708][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,709][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 65 ms on localhost (executor driver) (28/200)
[INFO][2021-06-08 21:45:51,710][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 71 ms on localhost (executor driver) (29/200)
[INFO][2021-06-08 21:45:51,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,709][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-08 21:45:51,711][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,709][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2352 bytes result sent to driver
[INFO][2021-06-08 21:45:51,712][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-08 21:45:51,712][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2355 bytes result sent to driver
[INFO][2021-06-08 21:45:51,714][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,715][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,715][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-08 21:45:51,716][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,716][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-08 21:45:51,716][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,717][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,717][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2277 bytes result sent to driver
[INFO][2021-06-08 21:45:51,718][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-08 21:45:51,717][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-08 21:45:51,718][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,717][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,718][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,718][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,718][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,718][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,720][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-08 21:45:51,720][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,718][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,721][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,721][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,720][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,722][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,722][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,723][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,723][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-08 21:45:51,724][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,725][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2429 bytes result sent to driver
[INFO][2021-06-08 21:45:51,727][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,727][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,728][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-08 21:45:51,728][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,725][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,725][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,729][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:45:51,730][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,730][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-08 21:45:51,727][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2345 bytes result sent to driver
[INFO][2021-06-08 21:45:51,730][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-08 21:45:51,731][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,732][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2364 bytes result sent to driver
[INFO][2021-06-08 21:45:51,732][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,732][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2371 bytes result sent to driver
[INFO][2021-06-08 21:45:51,732][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,733][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,733][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,733][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-08 21:45:51,733][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 85 ms on localhost (executor driver) (30/200)
[INFO][2021-06-08 21:45:51,732][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2372 bytes result sent to driver
[INFO][2021-06-08 21:45:51,734][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-08 21:45:51,734][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,735][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,734][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 93 ms on localhost (executor driver) (31/200)
[INFO][2021-06-08 21:45:51,736][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 78 ms on localhost (executor driver) (32/200)
[INFO][2021-06-08 21:45:51,737][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 76 ms on localhost (executor driver) (33/200)
[INFO][2021-06-08 21:45:51,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,733][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,732][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-08 21:45:51,737][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 71 ms on localhost (executor driver) (34/200)
[INFO][2021-06-08 21:45:51,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,740][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:45:51,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,740][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2273 bytes result sent to driver
[INFO][2021-06-08 21:45:51,742][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,739][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2364 bytes result sent to driver
[INFO][2021-06-08 21:45:51,739][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 78 ms on localhost (executor driver) (35/200)
[INFO][2021-06-08 21:45:51,742][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2259 bytes result sent to driver
[INFO][2021-06-08 21:45:51,743][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 89 ms on localhost (executor driver) (36/200)
[INFO][2021-06-08 21:45:51,744][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,744][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-08 21:45:51,744][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 98 ms on localhost (executor driver) (37/200)
[INFO][2021-06-08 21:45:51,758][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 103 ms on localhost (executor driver) (38/200)
[INFO][2021-06-08 21:45:51,758][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2354 bytes result sent to driver
[INFO][2021-06-08 21:45:51,758][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2425 bytes result sent to driver
[INFO][2021-06-08 21:45:51,759][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 89 ms on localhost (executor driver) (39/200)
[INFO][2021-06-08 21:45:51,760][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,760][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2444 bytes result sent to driver
[INFO][2021-06-08 21:45:51,760][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-08 21:45:51,761][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,761][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,761][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2353 bytes result sent to driver
[INFO][2021-06-08 21:45:51,761][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,761][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-08 21:45:51,762][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,762][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 84 ms on localhost (executor driver) (40/200)
[INFO][2021-06-08 21:45:51,762][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-08 21:45:51,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,763][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 78 ms on localhost (executor driver) (41/200)
[INFO][2021-06-08 21:45:51,765][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 82 ms on localhost (executor driver) (42/200)
[INFO][2021-06-08 21:45:51,764][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,765][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,765][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 96 ms on localhost (executor driver) (43/200)
[INFO][2021-06-08 21:45:51,766][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,766][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,766][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 80 ms on localhost (executor driver) (44/200)
[INFO][2021-06-08 21:45:51,768][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 89 ms on localhost (executor driver) (45/200)
[INFO][2021-06-08 21:45:51,769][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2364 bytes result sent to driver
[INFO][2021-06-08 21:45:51,769][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 106 ms on localhost (executor driver) (46/200)
[INFO][2021-06-08 21:45:51,769][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 102 ms on localhost (executor driver) (47/200)
[INFO][2021-06-08 21:45:51,770][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 75 ms on localhost (executor driver) (48/200)
[INFO][2021-06-08 21:45:51,770][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2358 bytes result sent to driver
[INFO][2021-06-08 21:45:51,770][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 69 ms on localhost (executor driver) (49/200)
[INFO][2021-06-08 21:45:51,771][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2448 bytes result sent to driver
[INFO][2021-06-08 21:45:51,771][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 65 ms on localhost (executor driver) (50/200)
[INFO][2021-06-08 21:45:51,772][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 82 ms on localhost (executor driver) (51/200)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 71 ms on localhost (executor driver) (52/200)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 86 ms on localhost (executor driver) (53/200)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 84 ms on localhost (executor driver) (54/200)
[INFO][2021-06-08 21:45:51,773][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2347 bytes result sent to driver
[INFO][2021-06-08 21:45:51,775][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,775][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-08 21:45:51,776][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,776][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,776][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,776][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-08 21:45:51,777][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,777][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 65 ms on localhost (executor driver) (55/200)
[INFO][2021-06-08 21:45:51,778][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-08 21:45:51,778][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 64 ms on localhost (executor driver) (56/200)
[INFO][2021-06-08 21:45:51,778][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,778][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 71 ms on localhost (executor driver) (57/200)
[INFO][2021-06-08 21:45:51,778][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,779][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,780][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-08 21:45:51,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,780][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,781][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,781][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,782][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-08 21:45:51,782][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-08 21:45:51,782][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,783][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,783][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2367 bytes result sent to driver
[INFO][2021-06-08 21:45:51,784][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,784][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,785][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,785][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,785][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-08 21:45:51,786][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,785][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,789][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-08 21:45:51,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,790][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,790][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 87 ms on localhost (executor driver) (58/200)
[INFO][2021-06-08 21:45:51,791][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 73 ms on localhost (executor driver) (59/200)
[INFO][2021-06-08 21:45:51,791][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 62 ms on localhost (executor driver) (60/200)
[INFO][2021-06-08 21:45:51,792][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,793][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2372 bytes result sent to driver
[INFO][2021-06-08 21:45:51,791][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,794][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,794][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2343 bytes result sent to driver
[INFO][2021-06-08 21:45:51,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,795][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-08 21:45:51,794][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,795][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,796][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-08 21:45:51,796][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,797][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 87 ms on localhost (executor driver) (61/200)
[INFO][2021-06-08 21:45:51,798][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 78 ms on localhost (executor driver) (62/200)
[INFO][2021-06-08 21:45:51,798][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-08 21:45:51,798][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,799][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,799][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,799][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 74 ms on localhost (executor driver) (63/200)
[INFO][2021-06-08 21:45:51,799][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-08 21:45:51,800][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 67 ms on localhost (executor driver) (64/200)
[INFO][2021-06-08 21:45:51,800][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 83 ms on localhost (executor driver) (65/200)
[INFO][2021-06-08 21:45:51,800][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 68 ms on localhost (executor driver) (66/200)
[INFO][2021-06-08 21:45:51,800][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 57 ms on localhost (executor driver) (67/200)
[INFO][2021-06-08 21:45:51,801][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 42 ms on localhost (executor driver) (68/200)
[INFO][2021-06-08 21:45:51,801][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 78 ms on localhost (executor driver) (69/200)
[INFO][2021-06-08 21:45:51,801][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,801][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,802][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,802][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,803][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,802][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,803][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,805][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,805][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-08 21:45:51,806][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,806][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-08 21:45:51,807][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,807][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-08 21:45:51,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,809][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-08 21:45:51,808][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,810][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-08 21:45:51,811][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,811][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,808][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2365 bytes result sent to driver
[INFO][2021-06-08 21:45:51,811][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,808][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2347 bytes result sent to driver
[INFO][2021-06-08 21:45:51,811][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-08 21:45:51,811][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,811][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,809][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2259 bytes result sent to driver
[INFO][2021-06-08 21:45:51,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,813][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,812][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,813][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,813][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 98 ms on localhost (executor driver) (70/200)
[INFO][2021-06-08 21:45:51,814][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-08 21:45:51,814][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,814][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,815][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,813][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,814][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 42 ms on localhost (executor driver) (71/200)
[INFO][2021-06-08 21:45:51,816][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2355 bytes result sent to driver
[INFO][2021-06-08 21:45:51,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,816][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 41 ms on localhost (executor driver) (72/200)
[INFO][2021-06-08 21:45:51,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,818][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,819][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-08 21:45:51,819][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,820][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-08 21:45:51,821][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:51,822][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,822][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,822][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,822][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-08 21:45:51,822][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 92 ms on localhost (executor driver) (73/200)
[INFO][2021-06-08 21:45:51,823][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,823][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,824][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2359 bytes result sent to driver
[INFO][2021-06-08 21:45:51,822][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2291 bytes result sent to driver
[INFO][2021-06-08 21:45:51,822][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,824][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 45 ms on localhost (executor driver) (74/200)
[INFO][2021-06-08 21:45:51,825][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,825][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,826][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,826][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 66 ms on localhost (executor driver) (75/200)
[INFO][2021-06-08 21:45:51,826][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-08 21:45:51,827][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 66 ms on localhost (executor driver) (76/200)
[INFO][2021-06-08 21:45:51,827][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 53 ms on localhost (executor driver) (77/200)
[INFO][2021-06-08 21:45:51,827][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,827][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 51 ms on localhost (executor driver) (78/200)
[INFO][2021-06-08 21:45:51,829][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,830][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-08 21:45:51,830][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,831][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2260 bytes result sent to driver
[INFO][2021-06-08 21:45:51,831][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2265 bytes result sent to driver
[INFO][2021-06-08 21:45:51,832][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,832][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-08 21:45:51,832][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 52 ms on localhost (executor driver) (79/200)
[INFO][2021-06-08 21:45:51,832][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2445 bytes result sent to driver
[INFO][2021-06-08 21:45:51,833][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,833][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,832][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,833][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 51 ms on localhost (executor driver) (80/200)
[INFO][2021-06-08 21:45:51,834][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 53 ms on localhost (executor driver) (81/200)
[INFO][2021-06-08 21:45:51,835][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,835][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,835][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 50 ms on localhost (executor driver) (82/200)
[INFO][2021-06-08 21:45:51,835][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,835][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-08 21:45:51,836][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,837][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-08 21:45:51,837][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,837][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-08 21:45:51,838][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 42 ms on localhost (executor driver) (83/200)
[INFO][2021-06-08 21:45:51,838][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,839][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,839][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,839][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,839][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,840][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-08 21:45:51,840][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,840][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,840][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,841][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,840][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,841][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,841][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 48 ms on localhost (executor driver) (84/200)
[INFO][2021-06-08 21:45:51,841][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-08 21:45:51,841][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 45 ms on localhost (executor driver) (85/200)
[INFO][2021-06-08 21:45:51,843][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:63894 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:51,843][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,844][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,844][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,844][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-08 21:45:51,844][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 46 ms on localhost (executor driver) (86/200)
[INFO][2021-06-08 21:45:51,845][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,845][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 43 ms on localhost (executor driver) (87/200)
[INFO][2021-06-08 21:45:51,846][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,846][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2256 bytes result sent to driver
[INFO][2021-06-08 21:45:51,847][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,847][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-08 21:45:51,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,848][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,848][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,849][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-08 21:45:51,849][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,850][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,850][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,850][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2361 bytes result sent to driver
[INFO][2021-06-08 21:45:51,850][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,851][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-08 21:45:51,851][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,851][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,851][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,851][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-08 21:45:51,852][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,852][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 46 ms on localhost (executor driver) (88/200)
[INFO][2021-06-08 21:45:51,853][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-08 21:45:51,853][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 46 ms on localhost (executor driver) (89/200)
[INFO][2021-06-08 21:45:51,853][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 35 ms on localhost (executor driver) (90/200)
[INFO][2021-06-08 21:45:51,853][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:63894 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:51,854][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,855][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,854][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 35 ms on localhost (executor driver) (91/200)
[INFO][2021-06-08 21:45:51,853][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,855][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,855][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2263 bytes result sent to driver
[INFO][2021-06-08 21:45:51,855][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 51 ms on localhost (executor driver) (92/200)
[INFO][2021-06-08 21:45:51,856][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,856][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 44 ms on localhost (executor driver) (93/200)
[INFO][2021-06-08 21:45:51,856][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 48 ms on localhost (executor driver) (94/200)
[INFO][2021-06-08 21:45:51,856][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,857][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,857][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,857][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-08 21:45:51,857][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 36 ms on localhost (executor driver) (95/200)
[INFO][2021-06-08 21:45:51,857][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,858][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,859][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-08 21:45:51,860][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,860][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,861][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,861][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,862][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,862][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,863][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,863][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-08 21:45:51,864][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2364 bytes result sent to driver
[INFO][2021-06-08 21:45:51,863][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,865][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-08 21:45:51,865][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,866][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,866][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-08 21:45:51,866][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,867][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 39 ms on localhost (executor driver) (96/200)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 37 ms on localhost (executor driver) (97/200)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,867][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 57 ms on localhost (executor driver) (98/200)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 33 ms on localhost (executor driver) (99/200)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,867][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 42 ms on localhost (executor driver) (100/200)
[INFO][2021-06-08 21:45:51,867][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,868][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,869][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2445 bytes result sent to driver
[INFO][2021-06-08 21:45:51,869][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,869][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,870][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,870][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-08 21:45:51,871][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,871][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 34 ms on localhost (executor driver) (101/200)
[INFO][2021-06-08 21:45:51,871][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-08 21:45:51,872][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,873][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2253 bytes result sent to driver
[INFO][2021-06-08 21:45:51,873][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,872][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 36 ms on localhost (executor driver) (102/200)
[INFO][2021-06-08 21:45:51,874][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,875][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,875][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,875][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,875][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 37 ms on localhost (executor driver) (103/200)
[INFO][2021-06-08 21:45:51,876][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-08 21:45:51,877][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,878][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,878][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-08 21:45:51,879][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,880][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-08 21:45:51,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,880][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,880][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,882][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-08 21:45:51,882][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,882][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,880][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,883][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,882][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2344 bytes result sent to driver
[INFO][2021-06-08 21:45:51,883][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,882][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2362 bytes result sent to driver
[INFO][2021-06-08 21:45:51,883][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,883][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-08 21:45:51,884][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,885][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-08 21:45:51,885][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,886][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,886][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,887][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,887][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,888][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2369 bytes result sent to driver
[INFO][2021-06-08 21:45:51,888][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,889][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,889][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-08 21:45:51,889][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2267 bytes result sent to driver
[INFO][2021-06-08 21:45:51,890][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,891][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 43 ms on localhost (executor driver) (104/200)
[INFO][2021-06-08 21:45:51,891][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,891][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 42 ms on localhost (executor driver) (105/200)
[INFO][2021-06-08 21:45:51,891][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-08 21:45:51,892][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 42 ms on localhost (executor driver) (106/200)
[INFO][2021-06-08 21:45:51,893][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 49 ms on localhost (executor driver) (107/200)
[INFO][2021-06-08 21:45:51,894][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,894][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,894][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,894][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-08 21:45:51,895][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,895][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,895][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,895][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 49 ms on localhost (executor driver) (108/200)
[INFO][2021-06-08 21:45:51,895][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-08 21:45:51,896][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2277 bytes result sent to driver
[INFO][2021-06-08 21:45:51,896][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2356 bytes result sent to driver
[INFO][2021-06-08 21:45:51,896][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 56 ms on localhost (executor driver) (109/200)
[INFO][2021-06-08 21:45:51,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 39 ms on localhost (executor driver) (110/200)
[INFO][2021-06-08 21:45:51,897][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 46 ms on localhost (executor driver) (111/200)
[INFO][2021-06-08 21:45:51,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,899][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,899][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,900][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-08 21:45:51,900][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 44 ms on localhost (executor driver) (112/200)
[INFO][2021-06-08 21:45:51,900][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,900][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,901][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2374 bytes result sent to driver
[INFO][2021-06-08 21:45:51,901][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,902][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-08 21:45:51,902][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,903][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,903][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-08 21:45:51,903][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 44 ms on localhost (executor driver) (113/200)
[INFO][2021-06-08 21:45:51,905][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,905][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,906][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,906][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,906][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 41 ms on localhost (executor driver) (114/200)
[INFO][2021-06-08 21:45:51,906][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-08 21:45:51,906][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,906][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 36 ms on localhost (executor driver) (115/200)
[INFO][2021-06-08 21:45:51,906][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,907][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,907][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 41 ms on localhost (executor driver) (116/200)
[INFO][2021-06-08 21:45:51,908][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,908][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,909][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 46 ms on localhost (executor driver) (117/200)
[INFO][2021-06-08 21:45:51,909][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-08 21:45:51,910][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,910][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,910][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,910][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,911][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-08 21:45:51,911][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,912][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2447 bytes result sent to driver
[INFO][2021-06-08 21:45:51,911][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,912][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,912][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,912][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-08 21:45:51,913][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2244 bytes result sent to driver
[INFO][2021-06-08 21:45:51,913][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,914][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-08 21:45:51,915][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,916][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,915][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,917][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,917][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-08 21:45:51,917][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2377 bytes result sent to driver
[INFO][2021-06-08 21:45:51,916][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-08 21:45:51,916][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,918][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,918][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,918][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,917][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 49 ms on localhost (executor driver) (118/200)
[INFO][2021-06-08 21:45:51,919][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,920][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,920][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:51,920][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 46 ms on localhost (executor driver) (119/200)
[INFO][2021-06-08 21:45:51,920][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,920][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,920][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 42 ms on localhost (executor driver) (120/200)
[INFO][2021-06-08 21:45:51,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 44 ms on localhost (executor driver) (121/200)
[INFO][2021-06-08 21:45:51,921][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 38 ms on localhost (executor driver) (122/200)
[INFO][2021-06-08 21:45:51,922][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,922][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,922][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,923][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-08 21:45:51,923][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2257 bytes result sent to driver
[INFO][2021-06-08 21:45:51,923][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,923][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 44 ms on localhost (executor driver) (123/200)
[INFO][2021-06-08 21:45:51,924][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-08 21:45:51,924][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,925][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-08 21:45:51,925][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,925][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,926][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,925][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,926][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,926][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,926][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-08 21:45:51,926][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 38 ms on localhost (executor driver) (124/200)
[INFO][2021-06-08 21:45:51,927][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,927][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 45 ms on localhost (executor driver) (125/200)
[INFO][2021-06-08 21:45:51,928][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,928][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,928][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,928][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 43 ms on localhost (executor driver) (126/200)
[INFO][2021-06-08 21:45:51,928][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-08 21:45:51,930][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,930][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,930][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,931][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,932][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,932][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,932][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-08 21:45:51,933][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:51,933][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,934][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-08 21:45:51,932][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-08 21:45:51,934][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2365 bytes result sent to driver
[INFO][2021-06-08 21:45:51,936][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,936][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,936][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,937][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-08 21:45:51,937][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,937][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,938][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,938][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-08 21:45:51,938][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,938][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,938][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,938][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,938][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,939][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-08 21:45:51,939][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,939][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,940][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,940][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,941][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,941][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-08 21:45:51,941][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,942][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,942][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-08 21:45:51,942][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,943][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,943][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,944][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,945][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2333 bytes result sent to driver
[INFO][2021-06-08 21:45:51,945][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,946][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-08 21:45:51,947][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,947][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2374 bytes result sent to driver
[INFO][2021-06-08 21:45:51,948][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-08 21:45:51,948][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:51,946][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,948][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-08 21:45:51,949][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-08 21:45:51,949][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-08 21:45:51,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,948][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,948][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,950][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-08 21:45:51,946][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2375 bytes result sent to driver
[INFO][2021-06-08 21:45:51,950][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,949][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2278 bytes result sent to driver
[INFO][2021-06-08 21:45:51,949][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:45:51,950][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,951][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,952][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 58 ms on localhost (executor driver) (127/200)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,952][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 59 ms on localhost (executor driver) (128/200)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,953][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 55 ms on localhost (executor driver) (129/200)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,952][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-08 21:45:51,952][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,954][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,953][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 51 ms on localhost (executor driver) (130/200)
[INFO][2021-06-08 21:45:51,953][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,955][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 45 ms on localhost (executor driver) (131/200)
[INFO][2021-06-08 21:45:51,955][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,955][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,956][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 45 ms on localhost (executor driver) (132/200)
[INFO][2021-06-08 21:45:51,956][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,958][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:45:51,959][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2447 bytes result sent to driver
[INFO][2021-06-08 21:45:51,958][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 46 ms on localhost (executor driver) (133/200)
[INFO][2021-06-08 21:45:51,959][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2366 bytes result sent to driver
[INFO][2021-06-08 21:45:51,960][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 43 ms on localhost (executor driver) (134/200)
[INFO][2021-06-08 21:45:51,960][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2347 bytes result sent to driver
[INFO][2021-06-08 21:45:51,961][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,961][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2361 bytes result sent to driver
[INFO][2021-06-08 21:45:51,960][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2336 bytes result sent to driver
[INFO][2021-06-08 21:45:51,960][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2273 bytes result sent to driver
[INFO][2021-06-08 21:45:51,962][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-08 21:45:51,962][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,962][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 61 ms on localhost (executor driver) (135/200)
[INFO][2021-06-08 21:45:51,963][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 56 ms on localhost (executor driver) (136/200)
[INFO][2021-06-08 21:45:51,962][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-08 21:45:51,963][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 58 ms on localhost (executor driver) (137/200)
[INFO][2021-06-08 21:45:51,963][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 49 ms on localhost (executor driver) (138/200)
[INFO][2021-06-08 21:45:51,964][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,964][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2371 bytes result sent to driver
[INFO][2021-06-08 21:45:51,964][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,964][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 41 ms on localhost (executor driver) (139/200)
[INFO][2021-06-08 21:45:51,964][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-08 21:45:51,965][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 41 ms on localhost (executor driver) (140/200)
[INFO][2021-06-08 21:45:51,964][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,965][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 40 ms on localhost (executor driver) (141/200)
[INFO][2021-06-08 21:45:51,965][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 43 ms on localhost (executor driver) (142/200)
[INFO][2021-06-08 21:45:51,965][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,965][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 38 ms on localhost (executor driver) (143/200)
[INFO][2021-06-08 21:45:51,965][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,966][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 33 ms on localhost (executor driver) (144/200)
[INFO][2021-06-08 21:45:51,966][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 36 ms on localhost (executor driver) (145/200)
[INFO][2021-06-08 21:45:51,966][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,967][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 30 ms on localhost (executor driver) (146/200)
[INFO][2021-06-08 21:45:51,967][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,967][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-08 21:45:51,967][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,967][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 36 ms on localhost (executor driver) (147/200)
[INFO][2021-06-08 21:45:51,968][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,968][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-08 21:45:51,968][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 30 ms on localhost (executor driver) (148/200)
[INFO][2021-06-08 21:45:51,969][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,969][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,969][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-08 21:45:51,970][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,970][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,970][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 36 ms on localhost (executor driver) (149/200)
[INFO][2021-06-08 21:45:51,970][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-08 21:45:51,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,971][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,971][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,971][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-08 21:45:51,972][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,973][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,973][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-08 21:45:51,973][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2361 bytes result sent to driver
[INFO][2021-06-08 21:45:51,973][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,974][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-08 21:45:51,974][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,974][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,974][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 35 ms on localhost (executor driver) (150/200)
[INFO][2021-06-08 21:45:51,976][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2426 bytes result sent to driver
[INFO][2021-06-08 21:45:51,976][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,976][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,976][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,976][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-08 21:45:51,977][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,977][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,977][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-08 21:45:51,977][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,978][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,977][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2371 bytes result sent to driver
[INFO][2021-06-08 21:45:51,978][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-08 21:45:51,978][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,979][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,978][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,979][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:51,979][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-08 21:45:51,979][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,979][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,980][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,980][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-08 21:45:51,980][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,980][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,981][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,980][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 36 ms on localhost (executor driver) (151/200)
[INFO][2021-06-08 21:45:51,981][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,980][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,982][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,983][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,982][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 39 ms on localhost (executor driver) (152/200)
[INFO][2021-06-08 21:45:51,983][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-08 21:45:51,984][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2283 bytes result sent to driver
[INFO][2021-06-08 21:45:51,984][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,985][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-08 21:45:51,986][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,986][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,986][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-08 21:45:51,986][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 46 ms on localhost (executor driver) (153/200)
[INFO][2021-06-08 21:45:51,986][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:51,987][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 39 ms on localhost (executor driver) (154/200)
[INFO][2021-06-08 21:45:51,987][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 37 ms on localhost (executor driver) (155/200)
[INFO][2021-06-08 21:45:51,987][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:51,987][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 42 ms on localhost (executor driver) (156/200)
[INFO][2021-06-08 21:45:51,987][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2267 bytes result sent to driver
[INFO][2021-06-08 21:45:51,987][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 41 ms on localhost (executor driver) (157/200)
[INFO][2021-06-08 21:45:51,987][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 45 ms on localhost (executor driver) (158/200)
[INFO][2021-06-08 21:45:51,987][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,988][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 37 ms on localhost (executor driver) (159/200)
[INFO][2021-06-08 21:45:51,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,988][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,988][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,989][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,989][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-08 21:45:51,989][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 27 ms on localhost (executor driver) (160/200)
[INFO][2021-06-08 21:45:51,990][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,990][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-08 21:45:51,990][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 30 ms on localhost (executor driver) (161/200)
[INFO][2021-06-08 21:45:51,991][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,991][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,991][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,992][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-08 21:45:51,992][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 29 ms on localhost (executor driver) (162/200)
[INFO][2021-06-08 21:45:51,992][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,993][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,993][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,993][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-08 21:45:51,994][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2268 bytes result sent to driver
[INFO][2021-06-08 21:45:51,994][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2371 bytes result sent to driver
[INFO][2021-06-08 21:45:51,994][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,994][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 28 ms on localhost (executor driver) (163/200)
[INFO][2021-06-08 21:45:51,994][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-08 21:45:51,994][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,995][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 27 ms on localhost (executor driver) (164/200)
[INFO][2021-06-08 21:45:51,995][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,995][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,996][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:51,996][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 26 ms on localhost (executor driver) (165/200)
[INFO][2021-06-08 21:45:51,996][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:51,996][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-08 21:45:51,997][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:51,997][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:51,997][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,997][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:51,998][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-08 21:45:51,998][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 29 ms on localhost (executor driver) (166/200)
[INFO][2021-06-08 21:45:51,999][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:51,999][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-08 21:45:52,000][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,000][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2287 bytes result sent to driver
[INFO][2021-06-08 21:45:52,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,001][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-08 21:45:52,000][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,001][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:52,001][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,001][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,002][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-08 21:45:52,002][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 31 ms on localhost (executor driver) (167/200)
[INFO][2021-06-08 21:45:52,002][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,002][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,003][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,002][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2252 bytes result sent to driver
[INFO][2021-06-08 21:45:52,003][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-08 21:45:52,003][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,004][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,005][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-08 21:45:52,005][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,005][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,006][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,004][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,006][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2372 bytes result sent to driver
[INFO][2021-06-08 21:45:52,006][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-08 21:45:52,007][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,007][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,007][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,008][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,007][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:52,008][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2360 bytes result sent to driver
[INFO][2021-06-08 21:45:52,007][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-08 21:45:52,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,008][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-08 21:45:52,009][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,009][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,010][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2288 bytes result sent to driver
[INFO][2021-06-08 21:45:52,009][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2367 bytes result sent to driver
[INFO][2021-06-08 21:45:52,010][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,010][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 32 ms on localhost (executor driver) (168/200)
[INFO][2021-06-08 21:45:52,011][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 35 ms on localhost (executor driver) (169/200)
[INFO][2021-06-08 21:45:52,010][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-08 21:45:52,010][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,012][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2343 bytes result sent to driver
[INFO][2021-06-08 21:45:52,011][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,011][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 32 ms on localhost (executor driver) (170/200)
[INFO][2021-06-08 21:45:52,013][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2368 bytes result sent to driver
[INFO][2021-06-08 21:45:52,013][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 41 ms on localhost (executor driver) (171/200)
[INFO][2021-06-08 21:45:52,013][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 38 ms on localhost (executor driver) (172/200)
[INFO][2021-06-08 21:45:52,014][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2276 bytes result sent to driver
[INFO][2021-06-08 21:45:52,014][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:45:52,014][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 37 ms on localhost (executor driver) (173/200)
[INFO][2021-06-08 21:45:52,015][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,015][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,015][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,015][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-08 21:45:52,016][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,016][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-08 21:45:52,017][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2264 bytes result sent to driver
[INFO][2021-06-08 21:45:52,017][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,017][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,017][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-08 21:45:52,018][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,018][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,018][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 33 ms on localhost (executor driver) (174/200)
[INFO][2021-06-08 21:45:52,018][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-08 21:45:52,019][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 28 ms on localhost (executor driver) (175/200)
[INFO][2021-06-08 21:45:52,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,019][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,020][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 27 ms on localhost (executor driver) (176/200)
[INFO][2021-06-08 21:45:52,019][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2283 bytes result sent to driver
[INFO][2021-06-08 21:45:52,020][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2355 bytes result sent to driver
[INFO][2021-06-08 21:45:52,020][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,021][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,021][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,022][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,022][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,022][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-08 21:45:52,025][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2372 bytes result sent to driver
[INFO][2021-06-08 21:45:52,025][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,025][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,025][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,026][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,026][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2377 bytes result sent to driver
[INFO][2021-06-08 21:45:52,026][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2284 bytes result sent to driver
[INFO][2021-06-08 21:45:52,027][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-08 21:45:52,026][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-08 21:45:52,027][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,027][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:52,028][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-08 21:45:52,028][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-08 21:45:52,029][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-08 21:45:52,029][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 45 ms on localhost (executor driver) (177/200)
[INFO][2021-06-08 21:45:52,029][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 41 ms on localhost (executor driver) (178/200)
[INFO][2021-06-08 21:45:52,029][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,030][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 41 ms on localhost (executor driver) (179/200)
[INFO][2021-06-08 21:45:52,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,030][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2259 bytes result sent to driver
[INFO][2021-06-08 21:45:52,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:45:52,030][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,031][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 38 ms on localhost (executor driver) (180/200)
[INFO][2021-06-08 21:45:52,031][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:45:52,032][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 32 ms on localhost (executor driver) (181/200)
[INFO][2021-06-08 21:45:52,032][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:45:52,033][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 38 ms on localhost (executor driver) (182/200)
[INFO][2021-06-08 21:45:52,033][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 31 ms on localhost (executor driver) (183/200)
[INFO][2021-06-08 21:45:52,034][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 31 ms on localhost (executor driver) (184/200)
[INFO][2021-06-08 21:45:52,034][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 30 ms on localhost (executor driver) (185/200)
[INFO][2021-06-08 21:45:52,035][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 37 ms on localhost (executor driver) (186/200)
[INFO][2021-06-08 21:45:52,035][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2282 bytes result sent to driver
[INFO][2021-06-08 21:45:52,035][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2357 bytes result sent to driver
[INFO][2021-06-08 21:45:52,035][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 38 ms on localhost (executor driver) (187/200)
[INFO][2021-06-08 21:45:52,035][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2281 bytes result sent to driver
[INFO][2021-06-08 21:45:52,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 37 ms on localhost (executor driver) (188/200)
[INFO][2021-06-08 21:45:52,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 30 ms on localhost (executor driver) (189/200)
[INFO][2021-06-08 21:45:52,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 29 ms on localhost (executor driver) (190/200)
[INFO][2021-06-08 21:45:52,036][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 28 ms on localhost (executor driver) (191/200)
[INFO][2021-06-08 21:45:52,037][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 23 ms on localhost (executor driver) (192/200)
[INFO][2021-06-08 21:45:52,037][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 22 ms on localhost (executor driver) (193/200)
[INFO][2021-06-08 21:45:52,037][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 21 ms on localhost (executor driver) (194/200)
[INFO][2021-06-08 21:45:52,037][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 20 ms on localhost (executor driver) (195/200)
[INFO][2021-06-08 21:45:52,038][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 18 ms on localhost (executor driver) (196/200)
[INFO][2021-06-08 21:45:52,038][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2280 bytes result sent to driver
[INFO][2021-06-08 21:45:52,038][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 11 ms on localhost (executor driver) (197/200)
[INFO][2021-06-08 21:45:52,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 16 ms on localhost (executor driver) (198/200)
[INFO][2021-06-08 21:45:52,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 13 ms on localhost (executor driver) (199/200)
[INFO][2021-06-08 21:45:52,039][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 11 ms on localhost (executor driver) (200/200)
[INFO][2021-06-08 21:45:52,039][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:45:52,039][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.533 s
[INFO][2021-06-08 21:45:52,040][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 0.861687 s
[INFO][2021-06-08 21:45:52,072][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.1812 ms
[INFO][2021-06-08 21:45:52,090][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:52,094][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:52,095][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:52,096][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-08 21:45:52,097][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:52,100][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-08 21:45:52,101][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:45:52,101][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-08 21:45:52,102][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-08 21:45:52,104][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-08 21:45:52,136][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-08 21:45:52,140][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-08 21:45:52,141][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:45:52,141][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:347
[INFO][2021-06-08 21:45:52,150][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-08 21:45:52,155][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-08 21:45:52,156][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:45:52,156][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:316
[INFO][2021-06-08 21:45:52,344][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:46:27,889][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:46:27,889][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:46:27,998][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.0369 ms
[INFO][2021-06-08 21:46:28,008][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-08 21:46:28,009][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-08 21:46:28,009][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:46:28,009][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:46:28,009][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:46:28,009][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-08 21:46:28,018][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:46:28,021][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:46:28,022][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:46:28,023][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:46:28,023][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:46:28,023][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 21:46:28,024][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:46:28,025][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-08 21:46:28,082][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:46:28,085][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2281 bytes result sent to driver
[INFO][2021-06-08 21:46:28,085][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 61 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:46:28,085][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:46:28,085][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.062 s
[INFO][2021-06-08 21:46:28,086][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.077040 s
[INFO][2021-06-08 21:46:28,126][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 32.1251 ms
[INFO][2021-06-08 21:46:28,136][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:46:28,184][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:46:28,187][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-08 21:46:28,187][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:46:28,255][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.281 ms
[INFO][2021-06-08 21:46:28,270][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-08 21:46:28,271][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-08 21:46:28,271][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:46:28,271][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:46:28,271][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:46:28,271][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-08 21:46:28,273][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:46:28,276][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:46:28,277][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:46:28,277][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:46:28,278][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:46:28,278][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 21:46:28,279][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:46:28,279][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-08 21:46:28,325][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:46:28,326][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2366 bytes result sent to driver
[INFO][2021-06-08 21:46:28,327][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 49 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:46:28,327][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:46:28,327][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.049 s
[INFO][2021-06-08 21:46:28,327][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.056627 s
[INFO][2021-06-08 21:46:28,330][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-08 21:46:28,360][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:46:28,360][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,360][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,361][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,361][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:46:28,361][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:46:28,362][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:46:28,362][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:46:28,362][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:46:28,362][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,362][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,363][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,363][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,363][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,363][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,364][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,364][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,364][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:46:28,364][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,364][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:46:28,365][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,365][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:46:28,366][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,366][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,366][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:46:28,367][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,367][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:46:28,367][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,367][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,367][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,368][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:46:28,384][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.7862 ms
[INFO][2021-06-08 21:46:28,386][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-08 21:46:28,395][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk,cast(null as decimal(8,0)) as wssgjkr,cast(null as decimal(8,0)) as wssgtkr,cast(null as decimal(8,0)) as zjxcgpr,cast(null as decimal(8,0)) as fxjgggr from sparktxggl
[INFO][2021-06-08 21:46:28,414][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:56:06,954][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: insert overwrite table adp_cfg.info_txggl select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,JYS,SSBK from sparktxggl
[WARN][2021-06-08 21:56:06,956][org.apache.spark.rpc.netty.NettyRpcEnv:66] - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply in 10 seconds
[WARN][2021-06-08 21:56:06,956][org.apache.spark.HeartbeatReceiver:66] - Removing executor driver with no recent heartbeats: 458690 ms exceeds timeout 120000 ms
[ERROR][2021-06-08 21:56:06,959][org.apache.spark.scheduler.TaskSchedulerImpl:70] - Lost executor driver on localhost: Executor heartbeat timed out after 458690 ms
[INFO][2021-06-08 21:56:06,962][org.apache.spark.scheduler.DAGScheduler:54] - Executor lost: driver (epoch 1)
[INFO][2021-06-08 21:56:06,963][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,963][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Trying to remove executor driver from BlockManagerMaster.
[INFO][2021-06-08 21:56:06,963][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,964][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,964][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Removing block manager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,966][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:63894 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 63894, None)
[WARN][2021-06-08 21:56:06,966][org.apache.spark.SparkContext:66] - Killing executors is only supported in coarse-grained mode
[INFO][2021-06-08 21:56:06,966][org.apache.spark.storage.BlockManagerMaster:54] - Removed driver successfully in removeExecutor
[INFO][2021-06-08 21:56:06,966][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,967][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,967][org.apache.spark.scheduler.DAGScheduler:54] - Shuffle files lost for executor: driver (epoch 1)
[INFO][2021-06-08 21:56:06,969][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,969][org.apache.spark.scheduler.DAGScheduler:54] - Host added was in lost list earlier: localhost
[INFO][2021-06-08 21:56:06,970][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,971][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,972][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,973][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,974][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,975][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,976][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,977][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,977][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,977][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,977][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,977][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,978][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,978][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,979][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,979][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,980][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,981][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,981][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,982][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,982][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,982][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,982][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,983][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,983][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,983][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,983][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,984][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,984][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,985][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,985][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,986][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,986][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,987][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,987][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,987][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,987][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:06,987][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,988][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,988][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,988][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,988][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,988][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,988][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,989][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,990][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,991][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,992][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:56:06,992][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,992][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,992][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,992][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,992][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,993][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:06,993][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,993][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,993][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,993][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:06,993][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,993][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,994][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,995][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,996][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,996][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,997][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,997][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:06,997][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:06,997][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,997][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:06,998][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:06,998][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,998][org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
[INFO][2021-06-08 21:56:06,999][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:06,999][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,000][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,001][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,001][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,002][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,003][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,003][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:07,003][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:07,003][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,004][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,004][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:07,004][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,005][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,005][org.spark_project.jetty.server.ServerConnector:306] - Stopped Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:56:07,005][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,006][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,007][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,008][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,008][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,008][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,008][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,008][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,009][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4207609e{/,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,009][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,009][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2f00f851{/static,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,010][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,010][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:07,010][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,010][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:07,010][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,010][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,011][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17690e14{/executors,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,011][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,011][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:07,011][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,012][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@108a46d6{/environment,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,012][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,012][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,012][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,012][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,012][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,012][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@23a5818e{/storage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@10afe71a{/stages,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,013][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,014][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,014][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,014][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,014][org.spark_project.jetty.server.handler.ContextHandler:865] - Stopped o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,UNAVAILABLE,@Spark}
[INFO][2021-06-08 21:56:07,014][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,015][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,015][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,016][org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.52.10:4040
[INFO][2021-06-08 21:56:07,016][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,016][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:07,016][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:07,016][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,017][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,017][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:07,017][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,018][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,018][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,019][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:07,019][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,020][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_3_piece0,StorageLevel(memory, 1 replicas),8793,0))
[INFO][2021-06-08 21:56:07,021][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,021][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_7_piece0,StorageLevel(memory, 1 replicas),124,0))
[INFO][2021-06-08 21:56:07,021][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,022][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_6_piece0,StorageLevel(memory, 1 replicas),167,0))
[INFO][2021-06-08 21:56:07,022][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,023][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[INFO][2021-06-08 21:56:07,023][org.apache.spark.executor.Executor:54] - Told to re-register on heartbeat
[INFO][2021-06-08 21:56:07,023][org.apache.spark.storage.BlockManager:54] - BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None) re-registering with master
[INFO][2021-06-08 21:56:07,023][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[ERROR][2021-06-08 21:56:07,024][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1623160567024,BlockManagerId(driver, 192.168.52.10, 63894, None),4041757163)
[INFO][2021-06-08 21:56:07,024][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 63894, None)
[INFO][2021-06-08 21:56:07,024][org.apache.spark.storage.BlockManager:54] - Reporting 16 blocks to the master.
[INFO][2021-06-08 21:56:07,025][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:63894 (size: 8.3 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,025][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_9_piece0,StorageLevel(memory, 1 replicas),8495,0))
[INFO][2021-06-08 21:56:07,025][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:63894 (size: 16.2 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,025][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_0_piece0,StorageLevel(memory, 1 replicas),16581,0))
[INFO][2021-06-08 21:56:07,036][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:63894 (size: 17.2 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,037][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_4_piece0,StorageLevel(memory, 1 replicas),17581,0))
[INFO][2021-06-08 21:56:07,037][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:63894 (size: 6.4 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,037][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_8_piece0,StorageLevel(memory, 1 replicas),6592,0))
[INFO][2021-06-08 21:56:07,038][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:63894 (size: 8.6 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,038][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_3_piece0,StorageLevel(memory, 1 replicas),8793,0))
[INFO][2021-06-08 21:56:07,039][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:63894 (size: 124.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,039][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_7_piece0,StorageLevel(memory, 1 replicas),124,0))
[INFO][2021-06-08 21:56:07,039][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:63894 (size: 167.0 B, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,039][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_6_piece0,StorageLevel(memory, 1 replicas),167,0))
[INFO][2021-06-08 21:56:07,040][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:63894 (size: 12.0 KB, free: 3.8 GB)
[ERROR][2021-06-08 21:56:07,040][org.apache.spark.scheduler.LiveListenerBus:70] - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 192.168.52.10, 63894, None),broadcast_5_piece0,StorageLevel(memory, 1 replicas),12335,0))
[INFO][2021-06-08 21:56:07,045][org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
[INFO][2021-06-08 21:56:07,089][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
[INFO][2021-06-08 21:56:07,089][org.apache.spark.storage.BlockManager:54] - BlockManager stopped
[INFO][2021-06-08 21:56:07,090][org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
[INFO][2021-06-08 21:56:07,092][org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
[INFO][2021-06-08 21:56:07,095][org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
[INFO][2021-06-08 21:56:07,096][org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
[INFO][2021-06-08 21:56:07,097][org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\14226\AppData\Local\Temp\spark-103d7a3c-18ee-4b17-81eb-cb1a950b268a
[INFO][2021-06-08 21:56:11,868][org.apache.spark.SparkContext:54] - Running Spark version 2.1.1
[INFO][2021-06-08 21:56:12,032][org.apache.spark.SecurityManager:54] - Changing view acls to: hello
[INFO][2021-06-08 21:56:12,034][org.apache.spark.SecurityManager:54] - Changing modify acls to: hello
[INFO][2021-06-08 21:56:12,034][org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
[INFO][2021-06-08 21:56:12,035][org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
[INFO][2021-06-08 21:56:12,035][org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hello); groups with view permissions: Set(); users  with modify permissions: Set(hello); groups with modify permissions: Set()
[INFO][2021-06-08 21:56:12,906][org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 65251.
[INFO][2021-06-08 21:56:12,921][org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
[INFO][2021-06-08 21:56:12,933][org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
[INFO][2021-06-08 21:56:12,936][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO][2021-06-08 21:56:12,936][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
[INFO][2021-06-08 21:56:12,945][org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\14226\AppData\Local\Temp\blockmgr-d672715e-e23e-4afe-9882-b57ed1e31006
[INFO][2021-06-08 21:56:12,955][org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 3.8 GB
[INFO][2021-06-08 21:56:12,979][org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
[INFO][2021-06-08 21:56:13,036][org.spark_project.jetty.util.log:186] - Logging initialized @3090ms
[INFO][2021-06-08 21:56:13,112][org.spark_project.jetty.server.Server:327] - jetty-9.2.z-SNAPSHOT
[INFO][2021-06-08 21:56:13,127][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,127][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@66f0548d{/jobs/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,128][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2e6f610d{/jobs/job,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,128][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,128][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@10afe71a{/stages,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,128][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,128][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/pool,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6daf7d37{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@23a5818e{/storage,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4715ae33{/storage/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,129][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@9fc9f91{/storage/rdd,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,130][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1fac1d5c{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,130][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@108a46d6{/environment,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,130][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@7a8406c2{/environment/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,130][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@17690e14{/executors,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,130][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6850b758{/executors/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,131][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2a2ef072{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,131][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@704641e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,136][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2f00f851{/static,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,136][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@4207609e{/,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,137][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@1f77b5cc{/api,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,137][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@5d7ca698{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,137][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@75961f16{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,145][org.spark_project.jetty.server.ServerConnector:266] - Started Spark@4e08acf9{HTTP/1.1}{0.0.0.0:4040}
[INFO][2021-06-08 21:56:13,145][org.spark_project.jetty.server.Server:379] - Started @3200ms
[INFO][2021-06-08 21:56:13,146][org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
[INFO][2021-06-08 21:56:13,148][org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.52.10:4040
[INFO][2021-06-08 21:56:13,199][org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
[INFO][2021-06-08 21:56:13,224][org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65292.
[INFO][2021-06-08 21:56:13,225][org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.52.10:65292
[INFO][2021-06-08 21:56:13,227][org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO][2021-06-08 21:56:13,228][org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.52.10, 65292, None)
[INFO][2021-06-08 21:56:13,232][org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.52.10:65292 with 3.8 GB RAM, BlockManagerId(driver, 192.168.52.10, 65292, None)
[INFO][2021-06-08 21:56:13,237][org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.52.10, 65292, None)
[INFO][2021-06-08 21:56:13,237][org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.52.10, 65292, None)
[INFO][2021-06-08 21:56:13,389][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6056232d{/metrics/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,418][org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'hdfs://192.168.52.100:8020/user/hive/warehouse'.
[INFO][2021-06-08 21:56:13,422][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2629d5dc{/SQL,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,423][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@42a0501e{/SQL/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,424][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@6abdec0e{/SQL/execution,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,424][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@2b5c4f17{/SQL/execution/json,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,426][org.spark_project.jetty.server.handler.ContextHandler:744] - Started o.s.j.s.ServletContextHandler@177c41d7{/static/sql,null,AVAILABLE,@Spark}
[INFO][2021-06-08 21:56:13,477][org.apache.spark.sql.hive.HiveUtils:54] - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
[INFO][2021-06-08 21:56:13,583][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
[INFO][2021-06-08 21:56:13,584][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
[INFO][2021-06-08 21:56:13,584][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
[INFO][2021-06-08 21:56:13,584][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
[INFO][2021-06-08 21:56:13,584][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
[INFO][2021-06-08 21:56:13,584][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
[INFO][2021-06-08 21:56:13,585][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
[INFO][2021-06-08 21:56:13,585][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
[INFO][2021-06-08 21:56:13,780][hive.metastore:376] - Trying to connect to metastore with URI thrift://192.168.52.100:9083
[INFO][2021-06-08 21:56:13,810][hive.metastore:472] - Connected to metastore.
[WARN][2021-06-08 21:56:14,455][org.apache.hadoop.hdfs.BlockReaderLocal:69] - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
[INFO][2021-06-08 21:56:14,524][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/f86a7ace-f481-452e-82f9-04097995bd08_resources
[INFO][2021-06-08 21:56:14,531][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/f86a7ace-f481-452e-82f9-04097995bd08
[INFO][2021-06-08 21:56:14,534][org.apache.hadoop.hive.ql.session.SessionState:641] - Created local directory: C:/Users/14226/AppData/Local/Temp/hello/f86a7ace-f481-452e-82f9-04097995bd08
[INFO][2021-06-08 21:56:14,537][org.apache.hadoop.hive.ql.session.SessionState:641] - Created HDFS directory: /tmp/hive/hello/f86a7ace-f481-452e-82f9-04097995bd08/_tmp_space.db
[INFO][2021-06-08 21:56:14,540][org.apache.spark.sql.hive.client.HiveClientImpl:54] - Warehouse location for Hive client (version 1.2.1) is hdfs://192.168.52.100:8020/user/hive/warehouse
[INFO][2021-06-08 21:56:14,617][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(zrr as int) zrr, cast(jyr as int) jyr from adp_cfg.t_xtjyr order by zrr
[INFO][2021-06-08 21:56:15,256][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,262][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,263][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: smallint
[INFO][2021-06-08 21:56:15,263][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: tinyint
[INFO][2021-06-08 21:56:15,264][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,264][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,264][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,264][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:15,265][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:16,670][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 140.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:16,805][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:16,807][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.52.10:65292 (size: 16.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:16,812][org.apache.spark.SparkContext:54] - Created broadcast 0 from collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:56:17,245][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 200.5236 ms
[INFO][2021-06-08 21:56:17,333][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.1065 ms
[INFO][2021-06-08 21:56:17,405][org.apache.hadoop.mapred.FileInputFormat:253] - Total input paths to process : 1
[INFO][2021-06-08 21:56:17,458][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:56:17,473][org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (collectAsList at TradingDays.java:42) with 1 output partitions
[INFO][2021-06-08 21:56:17,474][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:17,474][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:56:17,475][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:56:17,481][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:56:17,492][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:17,500][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:17,501][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.52.10:65292 (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:17,502][org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:17,504][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:17,506][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
[INFO][2021-06-08 21:56:17,544][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 6048 bytes)
[INFO][2021-06-08 21:56:17,551][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
[INFO][2021-06-08 21:56:17,604][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:56:17,610][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO][2021-06-08 21:56:17,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO][2021-06-08 21:56:17,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO][2021-06-08 21:56:17,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO][2021-06-08 21:56:17,611][org.apache.hadoop.conf.Configuration.deprecation:840] - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO][2021-06-08 21:56:17,646][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.3471 ms
[INFO][2021-06-08 21:56:18,305][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 155676 bytes result sent to driver
[INFO][2021-06-08 21:56:18,335][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 808 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:56:18,336][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:18,338][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (collectAsList at TradingDays.java:42) finished in 0.822 s
[INFO][2021-06-08 21:56:18,342][org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: collectAsList at TradingDays.java:42, took 0.883343 s
[INFO][2021-06-08 21:56:18,408][org.apache.spark.SparkContext:54] - Starting job: collectAsList at TradingDays.java:42
[INFO][2021-06-08 21:56:18,411][org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:18,411][org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collectAsList at TradingDays.java:42) with 200 output partitions
[INFO][2021-06-08 21:56:18,412][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:18,412][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:56:18,412][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
[INFO][2021-06-08 21:56:18,413][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:56:18,423][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 17.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:18,427][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:18,428][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.52.10:65292 (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:18,429][org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:18,431][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:18,431][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
[INFO][2021-06-08 21:56:18,433][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 6037 bytes)
[INFO][2021-06-08 21:56:18,434][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
[INFO][2021-06-08 21:56:18,447][org.apache.spark.rdd.HadoopRDD:54] - Input split: hdfs://node01:8020/user/hive/warehouse/adp_cfg.db/t_xtjyr/part-m-00000:0+201969
[INFO][2021-06-08 21:56:19,275][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1848 bytes result sent to driver
[INFO][2021-06-08 21:56:19,279][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 848 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:56:19,279][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:19,280][org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (collectAsList at TradingDays.java:42) finished in 0.849 s
[INFO][2021-06-08 21:56:19,281][org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
[INFO][2021-06-08 21:56:19,281][org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
[INFO][2021-06-08 21:56:19,282][org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
[INFO][2021-06-08 21:56:19,282][org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
[INFO][2021-06-08 21:56:19,285][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42), which has no missing parents
[INFO][2021-06-08 21:56:19,305][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 16.1 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,307][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,308][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.52.10:65292 (size: 8.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,308][org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:19,309][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collectAsList at TradingDays.java:42)
[INFO][2021-06-08 21:56:19,309][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 200 tasks
[INFO][2021-06-08 21:56:19,311][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,312][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,313][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,313][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,314][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,314][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,315][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,315][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,316][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,317][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,317][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,318][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,318][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,319][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,320][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,320][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,320][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
[INFO][2021-06-08 21:56:19,321][org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
[INFO][2021-06-08 21:56:19,321][org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 2.0 (TID 4)
[INFO][2021-06-08 21:56:19,321][org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 2.0 (TID 7)
[INFO][2021-06-08 21:56:19,322][org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 2.0 (TID 8)
[INFO][2021-06-08 21:56:19,322][org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 2.0 (TID 6)
[INFO][2021-06-08 21:56:19,322][org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 2.0 (TID 5)
[INFO][2021-06-08 21:56:19,323][org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 2.0 (TID 11)
[INFO][2021-06-08 21:56:19,323][org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 2.0 (TID 10)
[INFO][2021-06-08 21:56:19,324][org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 2.0 (TID 9)
[INFO][2021-06-08 21:56:19,325][org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 2.0 (TID 15)
[INFO][2021-06-08 21:56:19,325][org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 2.0 (TID 14)
[INFO][2021-06-08 21:56:19,325][org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 2.0 (TID 13)
[INFO][2021-06-08 21:56:19,327][org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 2.0 (TID 16)
[INFO][2021-06-08 21:56:19,325][org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 2.0 (TID 12)
[INFO][2021-06-08 21:56:19,328][org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 2.0 (TID 17)
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,352][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,351][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
[INFO][2021-06-08 21:56:19,355][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 10 ms
[INFO][2021-06-08 21:56:19,392][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.7239 ms
[INFO][2021-06-08 21:56:19,426][org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 2.0 (TID 16). 2364 bytes result sent to driver
[INFO][2021-06-08 21:56:19,426][org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 2.0 (TID 11). 2450 bytes result sent to driver
[INFO][2021-06-08 21:56:19,426][org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 2.0 (TID 6). 2364 bytes result sent to driver
[INFO][2021-06-08 21:56:19,426][org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 2.0 (TID 4). 2428 bytes result sent to driver
[INFO][2021-06-08 21:56:19,426][org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 2.0 (TID 10). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,427][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,428][org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 2.0 (TID 18)
[INFO][2021-06-08 21:56:19,428][org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 2.0 (TID 7). 2355 bytes result sent to driver
[INFO][2021-06-08 21:56:19,428][org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 2.0 (TID 8). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,428][org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 2.0 (TID 17). 2450 bytes result sent to driver
[INFO][2021-06-08 21:56:19,429][org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 2366 bytes result sent to driver
[INFO][2021-06-08 21:56:19,429][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,430][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2449 bytes result sent to driver
[INFO][2021-06-08 21:56:19,431][org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 2.0 (TID 19)
[INFO][2021-06-08 21:56:19,431][org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 2.0 (TID 15). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,432][org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 2.0 (TID 5). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,432][org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 2.0 (TID 13). 2269 bytes result sent to driver
[INFO][2021-06-08 21:56:19,432][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,433][org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 2.0 (TID 12). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,433][org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 2.0 (TID 20)
[INFO][2021-06-08 21:56:19,434][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,434][org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 2.0 (TID 14). 2328 bytes result sent to driver
[INFO][2021-06-08 21:56:19,434][org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 2.0 (TID 21)
[INFO][2021-06-08 21:56:19,435][org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 2.0 (TID 9). 2343 bytes result sent to driver
[INFO][2021-06-08 21:56:19,435][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,435][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,436][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,436][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,436][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 2.0 (TID 11) in 120 ms on localhost (executor driver) (1/200)
[INFO][2021-06-08 21:56:19,436][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,437][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,437][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 2.0 (TID 16) in 117 ms on localhost (executor driver) (2/200)
[INFO][2021-06-08 21:56:19,436][org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 2.0 (TID 22)
[INFO][2021-06-08 21:56:19,437][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 2.0 (TID 4) in 124 ms on localhost (executor driver) (3/200)
[INFO][2021-06-08 21:56:19,437][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,437][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 2.0 (TID 6) in 123 ms on localhost (executor driver) (4/200)
[INFO][2021-06-08 21:56:19,439][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,439][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,439][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,440][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,440][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,440][org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 2.0 (TID 23)
[INFO][2021-06-08 21:56:19,441][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,443][org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 2.0 (TID 24)
[INFO][2021-06-08 21:56:19,443][org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 2.0 (TID 19). 2363 bytes result sent to driver
[INFO][2021-06-08 21:56:19,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,443][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,444][org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 2.0 (TID 20). 2419 bytes result sent to driver
[INFO][2021-06-08 21:56:19,444][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,445][org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 2.0 (TID 21). 2458 bytes result sent to driver
[INFO][2021-06-08 21:56:19,445][org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 2.0 (TID 25)
[INFO][2021-06-08 21:56:19,445][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,445][org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 2.0 (TID 18). 2365 bytes result sent to driver
[INFO][2021-06-08 21:56:19,446][org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 2.0 (TID 26)
[INFO][2021-06-08 21:56:19,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,446][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,446][org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 2.0 (TID 22). 2359 bytes result sent to driver
[INFO][2021-06-08 21:56:19,447][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 2.0 (TID 7) in 133 ms on localhost (executor driver) (5/200)
[INFO][2021-06-08 21:56:19,446][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,447][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 2.0 (TID 10) in 131 ms on localhost (executor driver) (6/200)
[INFO][2021-06-08 21:56:19,447][org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 2.0 (TID 27)
[INFO][2021-06-08 21:56:19,449][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 137 ms on localhost (executor driver) (7/200)
[INFO][2021-06-08 21:56:19,449][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,449][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,450][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,450][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,450][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 2.0 (TID 17) in 129 ms on localhost (executor driver) (8/200)
[INFO][2021-06-08 21:56:19,450][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 2.0 (TID 8) in 136 ms on localhost (executor driver) (9/200)
[INFO][2021-06-08 21:56:19,450][org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 2.0 (TID 23). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,452][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,452][org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 2.0 (TID 28)
[INFO][2021-06-08 21:56:19,452][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,453][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,453][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,454][org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 2.0 (TID 29)
[INFO][2021-06-08 21:56:19,454][org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 2.0 (TID 24). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,455][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,455][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,457][org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 2.0 (TID 26). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,458][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,458][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,458][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,459][org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 2.0 (TID 30)
[INFO][2021-06-08 21:56:19,460][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,461][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 2.0 (TID 13) in 144 ms on localhost (executor driver) (10/200)
[INFO][2021-06-08 21:56:19,461][org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 2.0 (TID 31)
[INFO][2021-06-08 21:56:19,462][org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 2.0 (TID 27). 2363 bytes result sent to driver
[INFO][2021-06-08 21:56:19,462][org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 2.0 (TID 28). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,462][org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 2.0 (TID 25). 2355 bytes result sent to driver
[INFO][2021-06-08 21:56:19,462][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,462][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 152 ms on localhost (executor driver) (11/200)
[INFO][2021-06-08 21:56:19,463][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,464][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 2.0 (TID 15) in 146 ms on localhost (executor driver) (12/200)
[INFO][2021-06-08 21:56:19,464][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 2.0 (TID 5) in 151 ms on localhost (executor driver) (13/200)
[INFO][2021-06-08 21:56:19,464][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 2.0 (TID 12) in 147 ms on localhost (executor driver) (14/200)
[INFO][2021-06-08 21:56:19,465][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,465][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,465][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,466][org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 2.0 (TID 29). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,466][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 2.0 (TID 14) in 148 ms on localhost (executor driver) (15/200)
[INFO][2021-06-08 21:56:19,466][org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 2.0 (TID 32)
[INFO][2021-06-08 21:56:19,468][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,469][org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 2.0 (TID 33)
[INFO][2021-06-08 21:56:19,469][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,470][org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 2.0 (TID 34)
[INFO][2021-06-08 21:56:19,471][org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 2.0 (TID 30). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,471][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,472][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 2.0 (TID 9) in 156 ms on localhost (executor driver) (16/200)
[INFO][2021-06-08 21:56:19,472][org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 2.0 (TID 35)
[INFO][2021-06-08 21:56:19,472][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,472][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,473][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,473][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,473][org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 2.0 (TID 31). 2332 bytes result sent to driver
[INFO][2021-06-08 21:56:19,474][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,474][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,474][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,475][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,475][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 2.0 (TID 19) in 47 ms on localhost (executor driver) (17/200)
[INFO][2021-06-08 21:56:19,476][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 2.0 (TID 20) in 43 ms on localhost (executor driver) (18/200)
[INFO][2021-06-08 21:56:19,476][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 2.0 (TID 21) in 43 ms on localhost (executor driver) (19/200)
[INFO][2021-06-08 21:56:19,476][org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 2.0 (TID 36)
[INFO][2021-06-08 21:56:19,476][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,477][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 2.0 (TID 18) in 50 ms on localhost (executor driver) (20/200)
[INFO][2021-06-08 21:56:19,479][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,480][org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 2.0 (TID 37)
[INFO][2021-06-08 21:56:19,481][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,481][org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 2.0 (TID 32). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,482][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,482][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,482][org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 2.0 (TID 38)
[INFO][2021-06-08 21:56:19,483][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,483][org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 2.0 (TID 33). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,485][org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 2.0 (TID 34). 2284 bytes result sent to driver
[INFO][2021-06-08 21:56:19,485][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,485][org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 2.0 (TID 35). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,485][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,485][org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 2.0 (TID 39)
[INFO][2021-06-08 21:56:19,486][org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 2.0 (TID 40)
[INFO][2021-06-08 21:56:19,485][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,486][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,487][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,487][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,488][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,489][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,489][org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 2.0 (TID 43)
[INFO][2021-06-08 21:56:19,490][org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 2.0 (TID 42)
[INFO][2021-06-08 21:56:19,490][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,490][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,491][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,491][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,491][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,492][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,492][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,490][org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 2.0 (TID 41)
[INFO][2021-06-08 21:56:19,493][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,492][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,492][org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 2.0 (TID 37). 2355 bytes result sent to driver
[INFO][2021-06-08 21:56:19,494][org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 2.0 (TID 38). 2372 bytes result sent to driver
[INFO][2021-06-08 21:56:19,494][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,492][org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 2.0 (TID 36). 2332 bytes result sent to driver
[INFO][2021-06-08 21:56:19,491][org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 2.0 (TID 45)
[INFO][2021-06-08 21:56:19,491][org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 2.0 (TID 44)
[INFO][2021-06-08 21:56:19,494][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,494][org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 2.0 (TID 46)
[INFO][2021-06-08 21:56:19,495][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,496][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,494][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,498][org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 2.0 (TID 40). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,498][org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 2.0 (TID 43). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,498][org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 2.0 (TID 47)
[INFO][2021-06-08 21:56:19,498][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,498][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,499][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,499][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,500][org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 2.0 (TID 39). 2263 bytes result sent to driver
[INFO][2021-06-08 21:56:19,501][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,501][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,499][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,503][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:56:19,501][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,504][org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 2.0 (TID 42). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,505][org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 2.0 (TID 48)
[INFO][2021-06-08 21:56:19,505][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,505][org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 2.0 (TID 41). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,506][org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 2.0 (TID 49)
[INFO][2021-06-08 21:56:19,506][org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 2.0 (TID 46). 2364 bytes result sent to driver
[INFO][2021-06-08 21:56:19,506][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,506][org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 2.0 (TID 44). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,507][org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 2.0 (TID 50)
[INFO][2021-06-08 21:56:19,507][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,508][org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 2.0 (TID 51)
[INFO][2021-06-08 21:56:19,509][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,509][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,509][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,509][org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 2.0 (TID 47). 2345 bytes result sent to driver
[INFO][2021-06-08 21:56:19,509][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,509][org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 2.0 (TID 52)
[INFO][2021-06-08 21:56:19,509][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,510][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,510][org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 2.0 (TID 45). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,511][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,511][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,511][org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 2.0 (TID 53)
[INFO][2021-06-08 21:56:19,513][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,513][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,514][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,515][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,515][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,515][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,517][org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 2.0 (TID 48). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,517][org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 2.0 (TID 54)
[INFO][2021-06-08 21:56:19,514][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,517][org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 2.0 (TID 55)
[INFO][2021-06-08 21:56:19,517][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,518][org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 2.0 (TID 51). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,517][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:56:19,519][org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 2.0 (TID 52). 2273 bytes result sent to driver
[INFO][2021-06-08 21:56:19,519][org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 2.0 (TID 56)
[INFO][2021-06-08 21:56:19,519][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,521][org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 2.0 (TID 57)
[INFO][2021-06-08 21:56:19,521][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,522][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,522][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,521][org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 2.0 (TID 49). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,521][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,537][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,537][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,537][org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 2.0 (TID 58)
[INFO][2021-06-08 21:56:19,522][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,522][org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 2.0 (TID 53). 2344 bytes result sent to driver
[INFO][2021-06-08 21:56:19,538][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,539][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,539][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,540][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,541][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,541][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,539][org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 2.0 (TID 59)
[INFO][2021-06-08 21:56:19,541][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,542][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,543][org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 2.0 (TID 54). 2354 bytes result sent to driver
[INFO][2021-06-08 21:56:19,543][org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 2.0 (TID 60)
[INFO][2021-06-08 21:56:19,543][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,544][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,544][org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 2.0 (TID 61)
[INFO][2021-06-08 21:56:19,543][org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 2.0 (TID 55). 2354 bytes result sent to driver
[INFO][2021-06-08 21:56:19,544][org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 2.0 (TID 62)
[INFO][2021-06-08 21:56:19,545][org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 2.0 (TID 63)
[INFO][2021-06-08 21:56:19,544][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,546][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,546][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,547][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,543][org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 2.0 (TID 50). 2357 bytes result sent to driver
[INFO][2021-06-08 21:56:19,548][org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 2.0 (TID 65)
[INFO][2021-06-08 21:56:19,548][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,547][org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 2.0 (TID 64)
[INFO][2021-06-08 21:56:19,550][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,550][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,547][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,552][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:56:19,547][org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 2.0 (TID 56). 2437 bytes result sent to driver
[INFO][2021-06-08 21:56:19,545][org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 2.0 (TID 57). 2339 bytes result sent to driver
[INFO][2021-06-08 21:56:19,553][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,553][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,549][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,549][org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 2.0 (TID 58). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,554][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,555][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,549][org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 2.0 (TID 59). 2263 bytes result sent to driver
[INFO][2021-06-08 21:56:19,548][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,556][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,556][org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 2.0 (TID 66)
[INFO][2021-06-08 21:56:19,556][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 2.0 (TID 23) in 118 ms on localhost (executor driver) (21/200)
[INFO][2021-06-08 21:56:19,556][org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 2.0 (TID 67)
[INFO][2021-06-08 21:56:19,557][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 2.0 (TID 27) in 111 ms on localhost (executor driver) (22/200)
[INFO][2021-06-08 21:56:19,557][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 2.0 (TID 28) in 106 ms on localhost (executor driver) (23/200)
[INFO][2021-06-08 21:56:19,558][org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 2.0 (TID 60). 2347 bytes result sent to driver
[INFO][2021-06-08 21:56:19,558][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 2.0 (TID 25) in 116 ms on localhost (executor driver) (24/200)
[INFO][2021-06-08 21:56:19,558][org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 2.0 (TID 64). 2346 bytes result sent to driver
[INFO][2021-06-08 21:56:19,559][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 2.0 (TID 29) in 107 ms on localhost (executor driver) (25/200)
[INFO][2021-06-08 21:56:19,559][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,560][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,561][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 2.0 (TID 30) in 103 ms on localhost (executor driver) (26/200)
[INFO][2021-06-08 21:56:19,558][org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 2.0 (TID 62). 2369 bytes result sent to driver
[INFO][2021-06-08 21:56:19,560][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,562][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 2.0 (TID 26) in 117 ms on localhost (executor driver) (27/200)
[INFO][2021-06-08 21:56:19,562][org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 2.0 (TID 61). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,562][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,562][org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 2.0 (TID 63). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,563][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 2.0 (TID 24) in 123 ms on localhost (executor driver) (28/200)
[INFO][2021-06-08 21:56:19,564][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,564][org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 2.0 (TID 65). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,565][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 2.0 (TID 22) in 130 ms on localhost (executor driver) (29/200)
[INFO][2021-06-08 21:56:19,565][org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 2.0 (TID 68)
[INFO][2021-06-08 21:56:19,565][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,566][org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 2.0 (TID 69)
[INFO][2021-06-08 21:56:19,567][org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 2.0 (TID 66). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,567][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,567][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 2.0 (TID 31) in 108 ms on localhost (executor driver) (30/200)
[INFO][2021-06-08 21:56:19,568][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 2.0 (TID 35) in 96 ms on localhost (executor driver) (31/200)
[INFO][2021-06-08 21:56:19,568][org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 2.0 (TID 70)
[INFO][2021-06-08 21:56:19,568][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 2.0 (TID 33) in 101 ms on localhost (executor driver) (32/200)
[INFO][2021-06-08 21:56:19,568][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,568][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,569][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 2.0 (TID 32) in 104 ms on localhost (executor driver) (33/200)
[INFO][2021-06-08 21:56:19,569][org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 2.0 (TID 67). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,569][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 2.0 (TID 36) in 95 ms on localhost (executor driver) (34/200)
[INFO][2021-06-08 21:56:19,569][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,570][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,570][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,570][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 2.0 (TID 38) in 90 ms on localhost (executor driver) (35/200)
[INFO][2021-06-08 21:56:19,571][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,571][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,571][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 2.0 (TID 34) in 103 ms on localhost (executor driver) (36/200)
[INFO][2021-06-08 21:56:19,572][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 2.0 (TID 43) in 84 ms on localhost (executor driver) (37/200)
[INFO][2021-06-08 21:56:19,570][org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 2.0 (TID 71)
[INFO][2021-06-08 21:56:19,573][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 2.0 (TID 42) in 86 ms on localhost (executor driver) (38/200)
[INFO][2021-06-08 21:56:19,574][org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 2.0 (TID 68). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,576][org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 2.0 (TID 69). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,576][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,577][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,577][org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 2.0 (TID 72)
[INFO][2021-06-08 21:56:19,577][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 2.0 (TID 40) in 92 ms on localhost (executor driver) (39/200)
[INFO][2021-06-08 21:56:19,577][org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 2.0 (TID 70). 2262 bytes result sent to driver
[INFO][2021-06-08 21:56:19,577][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 2.0 (TID 37) in 98 ms on localhost (executor driver) (40/200)
[INFO][2021-06-08 21:56:19,577][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,578][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 2.0 (TID 46) in 86 ms on localhost (executor driver) (41/200)
[INFO][2021-06-08 21:56:19,578][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 2.0 (TID 41) in 92 ms on localhost (executor driver) (42/200)
[INFO][2021-06-08 21:56:19,579][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,579][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 2.0 (TID 45) in 89 ms on localhost (executor driver) (43/200)
[INFO][2021-06-08 21:56:19,579][org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 2.0 (TID 73)
[INFO][2021-06-08 21:56:19,579][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 2.0 (TID 39) in 98 ms on localhost (executor driver) (44/200)
[INFO][2021-06-08 21:56:19,579][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,580][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 2.0 (TID 51) in 73 ms on localhost (executor driver) (45/200)
[INFO][2021-06-08 21:56:19,580][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,580][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 2.0 (TID 44) in 91 ms on localhost (executor driver) (46/200)
[INFO][2021-06-08 21:56:19,581][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 2.0 (TID 49) in 77 ms on localhost (executor driver) (47/200)
[INFO][2021-06-08 21:56:19,581][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 2.0 (TID 52) in 73 ms on localhost (executor driver) (48/200)
[INFO][2021-06-08 21:56:19,582][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,582][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 2.0 (TID 54) in 71 ms on localhost (executor driver) (49/200)
[INFO][2021-06-08 21:56:19,582][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,583][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 2.0 (TID 48) in 85 ms on localhost (executor driver) (50/200)
[INFO][2021-06-08 21:56:19,584][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 2.0 (TID 50) in 79 ms on localhost (executor driver) (51/200)
[INFO][2021-06-08 21:56:19,584][org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 2.0 (TID 71). 2457 bytes result sent to driver
[INFO][2021-06-08 21:56:19,585][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,585][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 2.0 (TID 47) in 92 ms on localhost (executor driver) (52/200)
[INFO][2021-06-08 21:56:19,585][org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 2.0 (TID 74)
[INFO][2021-06-08 21:56:19,586][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 2.0 (TID 57) in 68 ms on localhost (executor driver) (53/200)
[INFO][2021-06-08 21:56:19,588][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,588][org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 2.0 (TID 73). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,588][org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 2.0 (TID 75)
[INFO][2021-06-08 21:56:19,589][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 2.0 (TID 55) in 74 ms on localhost (executor driver) (54/200)
[INFO][2021-06-08 21:56:19,589][org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 2.0 (TID 72). 2369 bytes result sent to driver
[INFO][2021-06-08 21:56:19,590][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,590][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,590][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 2.0 (TID 59) in 53 ms on localhost (executor driver) (55/200)
[INFO][2021-06-08 21:56:19,590][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 2.0 (TID 56) in 74 ms on localhost (executor driver) (56/200)
[INFO][2021-06-08 21:56:19,591][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,592][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,592][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,592][org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 2.0 (TID 76)
[INFO][2021-06-08 21:56:19,593][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,594][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 2.0 (TID 53) in 85 ms on localhost (executor driver) (57/200)
[INFO][2021-06-08 21:56:19,594][org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 2.0 (TID 77)
[INFO][2021-06-08 21:56:19,595][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,595][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,594][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 2.0 (TID 64) in 50 ms on localhost (executor driver) (58/200)
[INFO][2021-06-08 21:56:19,595][org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 2.0 (TID 74). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,595][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 2.0 (TID 60) in 56 ms on localhost (executor driver) (59/200)
[INFO][2021-06-08 21:56:19,596][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 2.0 (TID 58) in 76 ms on localhost (executor driver) (60/200)
[INFO][2021-06-08 21:56:19,597][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,597][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 2.0 (TID 62) in 55 ms on localhost (executor driver) (61/200)
[INFO][2021-06-08 21:56:19,597][org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 2.0 (TID 78)
[INFO][2021-06-08 21:56:19,598][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,598][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,598][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,598][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.52.10:65292 in memory (size: 4.6 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,600][org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 2.0 (TID 75). 2359 bytes result sent to driver
[INFO][2021-06-08 21:56:19,599][org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 2.0 (TID 79)
[INFO][2021-06-08 21:56:19,600][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,600][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,601][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,601][org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 2.0 (TID 80)
[INFO][2021-06-08 21:56:19,602][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,601][org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 2.0 (TID 76). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,603][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,603][org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 2.0 (TID 81)
[INFO][2021-06-08 21:56:19,604][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,604][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,602][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,604][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,604][org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 2.0 (TID 82)
[INFO][2021-06-08 21:56:19,604][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,606][org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 2.0 (TID 77). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,606][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,607][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,607][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,608][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,608][org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 2.0 (TID 83)
[INFO][2021-06-08 21:56:19,608][org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 2.0 (TID 78). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,608][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,609][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.52.10:65292 in memory (size: 7.9 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,609][org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 2.0 (TID 80). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,610][org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 2.0 (TID 84)
[INFO][2021-06-08 21:56:19,611][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,611][org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 2.0 (TID 79). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,612][org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 2.0 (TID 85)
[INFO][2021-06-08 21:56:19,611][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,612][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,612][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,612][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,612][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,612][org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 2.0 (TID 81). 2253 bytes result sent to driver
[INFO][2021-06-08 21:56:19,614][org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 2.0 (TID 86)
[INFO][2021-06-08 21:56:19,614][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,614][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,615][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,615][org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 2.0 (TID 87)
[INFO][2021-06-08 21:56:19,615][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,615][org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 2.0 (TID 88)
[INFO][2021-06-08 21:56:19,616][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,616][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,616][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,617][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,617][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,618][org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 2.0 (TID 89)
[INFO][2021-06-08 21:56:19,618][org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 2.0 (TID 84). 2358 bytes result sent to driver
[INFO][2021-06-08 21:56:19,616][org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 2.0 (TID 82). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,620][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,618][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,617][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,620][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,620][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,621][org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 2.0 (TID 90)
[INFO][2021-06-08 21:56:19,621][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 2.0 (TID 66) in 73 ms on localhost (executor driver) (62/200)
[INFO][2021-06-08 21:56:19,620][org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 2.0 (TID 85). 2275 bytes result sent to driver
[INFO][2021-06-08 21:56:19,621][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 2.0 (TID 65) in 75 ms on localhost (executor driver) (63/200)
[INFO][2021-06-08 21:56:19,620][org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 2.0 (TID 83). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,622][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 2.0 (TID 61) in 81 ms on localhost (executor driver) (64/200)
[INFO][2021-06-08 21:56:19,622][org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 2.0 (TID 87). 2259 bytes result sent to driver
[INFO][2021-06-08 21:56:19,621][org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 2.0 (TID 86). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,623][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 2.0 (TID 63) in 80 ms on localhost (executor driver) (65/200)
[INFO][2021-06-08 21:56:19,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,623][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,623][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,624][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 2.0 (TID 68) in 61 ms on localhost (executor driver) (66/200)
[INFO][2021-06-08 21:56:19,624][org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 2.0 (TID 91)
[INFO][2021-06-08 21:56:19,624][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 2.0 (TID 71) in 55 ms on localhost (executor driver) (67/200)
[INFO][2021-06-08 21:56:19,625][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 2.0 (TID 67) in 68 ms on localhost (executor driver) (68/200)
[INFO][2021-06-08 21:56:19,625][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 2.0 (TID 72) in 50 ms on localhost (executor driver) (69/200)
[INFO][2021-06-08 21:56:19,626][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 2.0 (TID 73) in 48 ms on localhost (executor driver) (70/200)
[INFO][2021-06-08 21:56:19,626][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 2.0 (TID 69) in 61 ms on localhost (executor driver) (71/200)
[INFO][2021-06-08 21:56:19,627][org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 2.0 (TID 88). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,627][org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 2.0 (TID 89). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,628][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,628][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,628][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,628][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 2.0 (TID 70) in 62 ms on localhost (executor driver) (72/200)
[INFO][2021-06-08 21:56:19,628][org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 2.0 (TID 92)
[INFO][2021-06-08 21:56:19,629][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 2.0 (TID 75) in 42 ms on localhost (executor driver) (73/200)
[INFO][2021-06-08 21:56:19,629][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 2.0 (TID 74) in 44 ms on localhost (executor driver) (74/200)
[INFO][2021-06-08 21:56:19,629][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 2.0 (TID 76) in 38 ms on localhost (executor driver) (75/200)
[INFO][2021-06-08 21:56:19,630][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,630][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 2.0 (TID 77) in 38 ms on localhost (executor driver) (76/200)
[INFO][2021-06-08 21:56:19,630][org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 2.0 (TID 93)
[INFO][2021-06-08 21:56:19,631][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,632][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,632][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,632][org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 2.0 (TID 94)
[INFO][2021-06-08 21:56:19,633][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,633][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,633][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,634][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,633][org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 2.0 (TID 95)
[INFO][2021-06-08 21:56:19,636][org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 2.0 (TID 90). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,636][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,636][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,637][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,636][org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 2.0 (TID 96)
[INFO][2021-06-08 21:56:19,637][org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 2.0 (TID 97)
[INFO][2021-06-08 21:56:19,638][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,638][org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 2.0 (TID 92). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,637][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,638][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,638][org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 2.0 (TID 93). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,638][org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 2.0 (TID 98)
[INFO][2021-06-08 21:56:19,639][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,639][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,640][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,640][org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 2.0 (TID 99)
[INFO][2021-06-08 21:56:19,640][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 2.0 (TID 78) in 44 ms on localhost (executor driver) (77/200)
[INFO][2021-06-08 21:56:19,641][org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 2.0 (TID 94). 2291 bytes result sent to driver
[INFO][2021-06-08 21:56:19,642][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 2.0 (TID 84) in 34 ms on localhost (executor driver) (78/200)
[INFO][2021-06-08 21:56:19,642][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 2.0 (TID 82) in 40 ms on localhost (executor driver) (79/200)
[INFO][2021-06-08 21:56:19,642][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 2.0 (TID 85) in 33 ms on localhost (executor driver) (80/200)
[INFO][2021-06-08 21:56:19,640][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,643][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
[INFO][2021-06-08 21:56:19,641][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,643][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,643][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,643][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,645][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,645][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,645][org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 2.0 (TID 100)
[INFO][2021-06-08 21:56:19,645][org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 2.0 (TID 91). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,647][org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 2.0 (TID 96). 2339 bytes result sent to driver
[INFO][2021-06-08 21:56:19,647][org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 2.0 (TID 95). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,647][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,647][org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 2.0 (TID 101)
[INFO][2021-06-08 21:56:19,648][org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 2.0 (TID 102)
[INFO][2021-06-08 21:56:19,648][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,648][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,650][org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 2.0 (TID 97). 2265 bytes result sent to driver
[INFO][2021-06-08 21:56:19,649][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,650][org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 2.0 (TID 103)
[INFO][2021-06-08 21:56:19,650][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,650][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,650][org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 2.0 (TID 98). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,651][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,651][org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 2.0 (TID 99). 2375 bytes result sent to driver
[INFO][2021-06-08 21:56:19,651][org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 2.0 (TID 104)
[INFO][2021-06-08 21:56:19,652][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,652][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 2.0 (TID 80) in 53 ms on localhost (executor driver) (81/200)
[INFO][2021-06-08 21:56:19,653][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,653][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 2.0 (TID 79) in 55 ms on localhost (executor driver) (82/200)
[INFO][2021-06-08 21:56:19,653][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 2.0 (TID 86) in 42 ms on localhost (executor driver) (83/200)
[INFO][2021-06-08 21:56:19,654][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 2.0 (TID 88) in 38 ms on localhost (executor driver) (84/200)
[INFO][2021-06-08 21:56:19,654][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 2.0 (TID 89) in 38 ms on localhost (executor driver) (85/200)
[INFO][2021-06-08 21:56:19,653][org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 2.0 (TID 105)
[INFO][2021-06-08 21:56:19,654][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 2.0 (TID 83) in 50 ms on localhost (executor driver) (86/200)
[INFO][2021-06-08 21:56:19,653][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,655][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 2.0 (TID 81) in 54 ms on localhost (executor driver) (87/200)
[INFO][2021-06-08 21:56:19,654][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,655][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,655][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 2.0 (TID 87) in 41 ms on localhost (executor driver) (88/200)
[INFO][2021-06-08 21:56:19,656][org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 2.0 (TID 102). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,656][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,657][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 2.0 (TID 90) in 40 ms on localhost (executor driver) (89/200)
[INFO][2021-06-08 21:56:19,657][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,657][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,657][org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 2.0 (TID 106)
[INFO][2021-06-08 21:56:19,657][org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 2.0 (TID 101). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,658][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,657][org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 2.0 (TID 100). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,659][org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 2.0 (TID 107)
[INFO][2021-06-08 21:56:19,658][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,660][org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 2.0 (TID 108)
[INFO][2021-06-08 21:56:19,660][org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 2.0 (TID 103). 2256 bytes result sent to driver
[INFO][2021-06-08 21:56:19,660][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,660][org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 2.0 (TID 104). 2361 bytes result sent to driver
[INFO][2021-06-08 21:56:19,661][org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 2.0 (TID 109)
[INFO][2021-06-08 21:56:19,661][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,661][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,662][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,661][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,662][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,662][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,662][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,663][org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 2.0 (TID 110)
[INFO][2021-06-08 21:56:19,663][org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 2.0 (TID 105). 2371 bytes result sent to driver
[INFO][2021-06-08 21:56:19,663][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,663][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,664][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,664][org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 2.0 (TID 111)
[INFO][2021-06-08 21:56:19,664][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,665][org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 2.0 (TID 112)
[INFO][2021-06-08 21:56:19,666][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,666][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,667][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,668][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,668][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,668][org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 2.0 (TID 114)
[INFO][2021-06-08 21:56:19,667][org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 2.0 (TID 113)
[INFO][2021-06-08 21:56:19,669][org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 2.0 (TID 108). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,668][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,668][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,667][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,670][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 2.0 (TID 94) in 39 ms on localhost (executor driver) (90/200)
[INFO][2021-06-08 21:56:19,670][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,670][org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 2.0 (TID 115)
[INFO][2021-06-08 21:56:19,670][org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 2.0 (TID 107). 2263 bytes result sent to driver
[INFO][2021-06-08 21:56:19,670][org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 2.0 (TID 109). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,670][org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 2.0 (TID 106). 2276 bytes result sent to driver
[INFO][2021-06-08 21:56:19,671][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,670][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 2.0 (TID 92) in 43 ms on localhost (executor driver) (91/200)
[INFO][2021-06-08 21:56:19,670][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,672][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,670][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
[INFO][2021-06-08 21:56:19,673][org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 2.0 (TID 112). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,673][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 2.0 (TID 96) in 40 ms on localhost (executor driver) (92/200)
[INFO][2021-06-08 21:56:19,673][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,674][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,674][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 2.0 (TID 97) in 38 ms on localhost (executor driver) (93/200)
[INFO][2021-06-08 21:56:19,675][org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 2.0 (TID 110). 2366 bytes result sent to driver
[INFO][2021-06-08 21:56:19,676][org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 2.0 (TID 113). 2347 bytes result sent to driver
[INFO][2021-06-08 21:56:19,676][org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 2.0 (TID 114). 2332 bytes result sent to driver
[INFO][2021-06-08 21:56:19,676][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,677][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 2.0 (TID 91) in 54 ms on localhost (executor driver) (94/200)
[INFO][2021-06-08 21:56:19,677][org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 2.0 (TID 116)
[INFO][2021-06-08 21:56:19,677][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 2.0 (TID 93) in 48 ms on localhost (executor driver) (95/200)
[INFO][2021-06-08 21:56:19,678][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 2.0 (TID 102) in 32 ms on localhost (executor driver) (96/200)
[INFO][2021-06-08 21:56:19,678][org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 2.0 (TID 111). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,678][org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 2.0 (TID 115). 2459 bytes result sent to driver
[INFO][2021-06-08 21:56:19,678][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 2.0 (TID 99) in 40 ms on localhost (executor driver) (97/200)
[INFO][2021-06-08 21:56:19,679][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,680][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 2.0 (TID 95) in 47 ms on localhost (executor driver) (98/200)
[INFO][2021-06-08 21:56:19,680][org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 2.0 (TID 117)
[INFO][2021-06-08 21:56:19,680][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,680][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,680][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,681][org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 2.0 (TID 118)
[INFO][2021-06-08 21:56:19,682][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,682][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,682][org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 2.0 (TID 119)
[INFO][2021-06-08 21:56:19,683][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,682][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,683][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,684][org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 2.0 (TID 121)
[INFO][2021-06-08 21:56:19,684][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,685][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,684][org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 2.0 (TID 120)
[INFO][2021-06-08 21:56:19,684][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,686][org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 2.0 (TID 116). 2368 bytes result sent to driver
[INFO][2021-06-08 21:56:19,686][org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 2.0 (TID 122)
[INFO][2021-06-08 21:56:19,686][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,688][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,688][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,689][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,689][org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 2.0 (TID 123)
[INFO][2021-06-08 21:56:19,687][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,689][org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 2.0 (TID 118). 2283 bytes result sent to driver
[INFO][2021-06-08 21:56:19,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,689][org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 2.0 (TID 124)
[INFO][2021-06-08 21:56:19,689][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,690][org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 2.0 (TID 125)
[INFO][2021-06-08 21:56:19,691][org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 2.0 (TID 117). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,691][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,692][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,692][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,692][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,692][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,693][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,694][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,694][org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 2.0 (TID 121). 2361 bytes result sent to driver
[INFO][2021-06-08 21:56:19,694][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 2.0 (TID 98) in 57 ms on localhost (executor driver) (99/200)
[INFO][2021-06-08 21:56:19,695][org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 2.0 (TID 126)
[INFO][2021-06-08 21:56:19,695][org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 2.0 (TID 122). 2347 bytes result sent to driver
[INFO][2021-06-08 21:56:19,695][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 2.0 (TID 104) in 46 ms on localhost (executor driver) (100/200)
[INFO][2021-06-08 21:56:19,694][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
[INFO][2021-06-08 21:56:19,695][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 2.0 (TID 105) in 44 ms on localhost (executor driver) (101/200)
[INFO][2021-06-08 21:56:19,696][org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 2.0 (TID 124). 2277 bytes result sent to driver
[INFO][2021-06-08 21:56:19,695][org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 2.0 (TID 119). 2265 bytes result sent to driver
[INFO][2021-06-08 21:56:19,696][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 2.0 (TID 108) in 38 ms on localhost (executor driver) (102/200)
[INFO][2021-06-08 21:56:19,697][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 2.0 (TID 107) in 39 ms on localhost (executor driver) (103/200)
[INFO][2021-06-08 21:56:19,697][org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 2.0 (TID 125). 2364 bytes result sent to driver
[INFO][2021-06-08 21:56:19,697][org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 2.0 (TID 123). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,698][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,698][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,698][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,699][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 2.0 (TID 101) in 55 ms on localhost (executor driver) (104/200)
[INFO][2021-06-08 21:56:19,699][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 2.0 (TID 103) in 51 ms on localhost (executor driver) (105/200)
[INFO][2021-06-08 21:56:19,699][org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 2.0 (TID 127)
[INFO][2021-06-08 21:56:19,699][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 2.0 (TID 106) in 43 ms on localhost (executor driver) (106/200)
[INFO][2021-06-08 21:56:19,700][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 2.0 (TID 109) in 41 ms on localhost (executor driver) (107/200)
[INFO][2021-06-08 21:56:19,700][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 2.0 (TID 112) in 36 ms on localhost (executor driver) (108/200)
[INFO][2021-06-08 21:56:19,701][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 2.0 (TID 100) in 58 ms on localhost (executor driver) (109/200)
[INFO][2021-06-08 21:56:19,702][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,702][org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 2.0 (TID 128)
[INFO][2021-06-08 21:56:19,703][org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 2.0 (TID 120). 2357 bytes result sent to driver
[INFO][2021-06-08 21:56:19,704][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,704][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,704][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 2.0 (TID 110) in 43 ms on localhost (executor driver) (110/200)
[INFO][2021-06-08 21:56:19,704][org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 2.0 (TID 126). 2284 bytes result sent to driver
[INFO][2021-06-08 21:56:19,704][org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 2.0 (TID 129)
[INFO][2021-06-08 21:56:19,704][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,705][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,705][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,706][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,707][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,707][org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 2.0 (TID 130)
[INFO][2021-06-08 21:56:19,707][org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 2.0 (TID 131)
[INFO][2021-06-08 21:56:19,707][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 2.0 (TID 114) in 40 ms on localhost (executor driver) (111/200)
[INFO][2021-06-08 21:56:19,707][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,708][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,708][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,709][org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 2.0 (TID 132)
[INFO][2021-06-08 21:56:19,709][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 2.0 (TID 111) in 46 ms on localhost (executor driver) (112/200)
[INFO][2021-06-08 21:56:19,710][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 2.0 (TID 113) in 45 ms on localhost (executor driver) (113/200)
[INFO][2021-06-08 21:56:19,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,710][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 2.0 (TID 116) in 35 ms on localhost (executor driver) (114/200)
[INFO][2021-06-08 21:56:19,710][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,711][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,712][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,712][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,713][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,713][org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 2.0 (TID 128). 2372 bytes result sent to driver
[INFO][2021-06-08 21:56:19,713][org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 2.0 (TID 127). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,714][org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 2.0 (TID 133)
[INFO][2021-06-08 21:56:19,715][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,717][org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 2.0 (TID 134)
[INFO][2021-06-08 21:56:19,717][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,718][org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 2.0 (TID 135)
[INFO][2021-06-08 21:56:19,718][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,719][org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 2.0 (TID 129). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,719][org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 2.0 (TID 130). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,719][org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 2.0 (TID 131). 2244 bytes result sent to driver
[INFO][2021-06-08 21:56:19,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,719][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,719][org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 2.0 (TID 136)
[INFO][2021-06-08 21:56:19,720][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,720][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,721][org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 2.0 (TID 132). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,721][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,722][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,722][org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 2.0 (TID 137)
[INFO][2021-06-08 21:56:19,722][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,723][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,724][org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 2.0 (TID 138)
[INFO][2021-06-08 21:56:19,724][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,724][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,725][org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 2.0 (TID 139)
[INFO][2021-06-08 21:56:19,726][org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 2.0 (TID 134). 2363 bytes result sent to driver
[INFO][2021-06-08 21:56:19,725][org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 2.0 (TID 133). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,725][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,726][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,727][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,727][org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 2.0 (TID 140)
[INFO][2021-06-08 21:56:19,727][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,728][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,728][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,729][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,729][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 2.0 (TID 115) in 61 ms on localhost (executor driver) (115/200)
[INFO][2021-06-08 21:56:19,728][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,728][org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 2.0 (TID 135). 2359 bytes result sent to driver
[INFO][2021-06-08 21:56:19,731][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,731][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,731][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 2.0 (TID 121) in 48 ms on localhost (executor driver) (116/200)
[INFO][2021-06-08 21:56:19,730][org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 2.0 (TID 136). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,729][org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 2.0 (TID 141)
[INFO][2021-06-08 21:56:19,732][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 2.0 (TID 117) in 52 ms on localhost (executor driver) (117/200)
[INFO][2021-06-08 21:56:19,731][org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 2.0 (TID 142)
[INFO][2021-06-08 21:56:19,732][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 2.0 (TID 119) in 51 ms on localhost (executor driver) (118/200)
[INFO][2021-06-08 21:56:19,733][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 2.0 (TID 118) in 53 ms on localhost (executor driver) (119/200)
[INFO][2021-06-08 21:56:19,733][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 2.0 (TID 123) in 47 ms on localhost (executor driver) (120/200)
[INFO][2021-06-08 21:56:19,735][org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 2.0 (TID 139). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,735][org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 2.0 (TID 138). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,736][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,736][org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 2.0 (TID 140). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,736][org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 2.0 (TID 143)
[INFO][2021-06-08 21:56:19,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,737][org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 2.0 (TID 137). 2257 bytes result sent to driver
[INFO][2021-06-08 21:56:19,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,737][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,737][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,738][org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 2.0 (TID 144)
[INFO][2021-06-08 21:56:19,738][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,739][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,739][org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 2.0 (TID 145)
[INFO][2021-06-08 21:56:19,739][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,740][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,741][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,741][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,741][org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 2.0 (TID 146)
[INFO][2021-06-08 21:56:19,742][org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 2.0 (TID 147)
[INFO][2021-06-08 21:56:19,742][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,742][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,742][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,743][org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 2.0 (TID 148)
[INFO][2021-06-08 21:56:19,743][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,744][org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 2.0 (TID 141). 2374 bytes result sent to driver
[INFO][2021-06-08 21:56:19,744][org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 2.0 (TID 149)
[INFO][2021-06-08 21:56:19,743][org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 2.0 (TID 142). 2368 bytes result sent to driver
[INFO][2021-06-08 21:56:19,744][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,744][org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 2.0 (TID 143). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,745][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,745][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,745][org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 2.0 (TID 150)
[INFO][2021-06-08 21:56:19,745][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,746][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 2.0 (TID 124) in 58 ms on localhost (executor driver) (121/200)
[INFO][2021-06-08 21:56:19,745][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,747][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 2.0 (TID 126) in 58 ms on localhost (executor driver) (122/200)
[INFO][2021-06-08 21:56:19,746][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,747][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,748][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 2.0 (TID 120) in 65 ms on localhost (executor driver) (123/200)
[INFO][2021-06-08 21:56:19,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,748][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,747][org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 2.0 (TID 144). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,747][org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 2.0 (TID 145). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,748][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 2.0 (TID 127) in 51 ms on localhost (executor driver) (124/200)
[INFO][2021-06-08 21:56:19,750][org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 2.0 (TID 146). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,750][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 2.0 (TID 129) in 47 ms on localhost (executor driver) (125/200)
[INFO][2021-06-08 21:56:19,751][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 2.0 (TID 130) in 46 ms on localhost (executor driver) (126/200)
[INFO][2021-06-08 21:56:19,752][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 2.0 (TID 125) in 64 ms on localhost (executor driver) (127/200)
[INFO][2021-06-08 21:56:19,752][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 2.0 (TID 128) in 51 ms on localhost (executor driver) (128/200)
[INFO][2021-06-08 21:56:19,753][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 2.0 (TID 122) in 69 ms on localhost (executor driver) (129/200)
[INFO][2021-06-08 21:56:19,753][org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 2.0 (TID 147). 2333 bytes result sent to driver
[INFO][2021-06-08 21:56:19,753][org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 2.0 (TID 149). 2363 bytes result sent to driver
[INFO][2021-06-08 21:56:19,753][org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 2.0 (TID 150). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,753][org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 2.0 (TID 148). 2364 bytes result sent to driver
[INFO][2021-06-08 21:56:19,754][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,754][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 2.0 (TID 132) in 46 ms on localhost (executor driver) (130/200)
[INFO][2021-06-08 21:56:19,754][org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 2.0 (TID 151)
[INFO][2021-06-08 21:56:19,754][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 2.0 (TID 134) in 40 ms on localhost (executor driver) (131/200)
[INFO][2021-06-08 21:56:19,754][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 2.0 (TID 133) in 43 ms on localhost (executor driver) (132/200)
[INFO][2021-06-08 21:56:19,754][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 2.0 (TID 131) in 47 ms on localhost (executor driver) (133/200)
[INFO][2021-06-08 21:56:19,755][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,755][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 2.0 (TID 135) in 39 ms on localhost (executor driver) (134/200)
[INFO][2021-06-08 21:56:19,755][org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 2.0 (TID 152)
[INFO][2021-06-08 21:56:19,756][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 2.0 (TID 136) in 38 ms on localhost (executor driver) (135/200)
[INFO][2021-06-08 21:56:19,756][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,756][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,756][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,757][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 2.0 (TID 139) in 33 ms on localhost (executor driver) (136/200)
[INFO][2021-06-08 21:56:19,757][org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 2.0 (TID 153)
[INFO][2021-06-08 21:56:19,757][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 2.0 (TID 138) in 35 ms on localhost (executor driver) (137/200)
[INFO][2021-06-08 21:56:19,758][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,758][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,758][org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 2.0 (TID 154)
[INFO][2021-06-08 21:56:19,759][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,759][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,759][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,760][org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 2.0 (TID 155)
[INFO][2021-06-08 21:56:19,760][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,761][org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 2.0 (TID 156)
[INFO][2021-06-08 21:56:19,761][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,761][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,761][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,762][org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 2.0 (TID 151). 2365 bytes result sent to driver
[INFO][2021-06-08 21:56:19,763][org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 2.0 (TID 157)
[INFO][2021-06-08 21:56:19,763][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,764][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,763][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,764][org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 2.0 (TID 152). 2368 bytes result sent to driver
[INFO][2021-06-08 21:56:19,764][org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 2.0 (TID 158)
[INFO][2021-06-08 21:56:19,764][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,764][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,765][org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 2.0 (TID 159)
[INFO][2021-06-08 21:56:19,765][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,765][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,766][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,766][org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 2.0 (TID 153). 2257 bytes result sent to driver
[INFO][2021-06-08 21:56:19,767][org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 2.0 (TID 154). 2268 bytes result sent to driver
[INFO][2021-06-08 21:56:19,766][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,766][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,766][org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 2.0 (TID 160)
[INFO][2021-06-08 21:56:19,767][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,768][org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 2.0 (TID 161)
[INFO][2021-06-08 21:56:19,768][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,768][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,768][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,769][org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 2.0 (TID 162)
[INFO][2021-06-08 21:56:19,769][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,769][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,770][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,769][org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 2.0 (TID 156). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,771][org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 2.0 (TID 157). 2352 bytes result sent to driver
[INFO][2021-06-08 21:56:19,772][org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 2.0 (TID 158). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,770][org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 2.0 (TID 163)
[INFO][2021-06-08 21:56:19,770][org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 2.0 (TID 155). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,770][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,772][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,773][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,773][org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 2.0 (TID 164)
[INFO][2021-06-08 21:56:19,772][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,774][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,774][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,774][org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 2.0 (TID 159). 2366 bytes result sent to driver
[INFO][2021-06-08 21:56:19,774][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,775][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,775][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,775][org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 2.0 (TID 160). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,775][org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 2.0 (TID 165)
[INFO][2021-06-08 21:56:19,776][org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 2.0 (TID 166)
[INFO][2021-06-08 21:56:19,776][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,777][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,777][org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 2.0 (TID 167)
[INFO][2021-06-08 21:56:19,777][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 2.0 (TID 141) in 50 ms on localhost (executor driver) (138/200)
[INFO][2021-06-08 21:56:19,777][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,778][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 2.0 (TID 143) in 43 ms on localhost (executor driver) (139/200)
[INFO][2021-06-08 21:56:19,778][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 2.0 (TID 144) in 42 ms on localhost (executor driver) (140/200)
[INFO][2021-06-08 21:56:19,779][org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 2.0 (TID 162). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,779][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,779][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 2.0 (TID 145) in 41 ms on localhost (executor driver) (141/200)
[INFO][2021-06-08 21:56:19,779][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,779][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,779][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,780][org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 2.0 (TID 163). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,779][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 2.0 (TID 146) in 40 ms on localhost (executor driver) (142/200)
[INFO][2021-06-08 21:56:19,780][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,780][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 2.0 (TID 142) in 50 ms on localhost (executor driver) (143/200)
[INFO][2021-06-08 21:56:19,781][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 2.0 (TID 147) in 41 ms on localhost (executor driver) (144/200)
[INFO][2021-06-08 21:56:19,781][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 2.0 (TID 149) in 38 ms on localhost (executor driver) (145/200)
[INFO][2021-06-08 21:56:19,781][org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 2.0 (TID 161). 2285 bytes result sent to driver
[INFO][2021-06-08 21:56:19,782][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 2.0 (TID 148) in 41 ms on localhost (executor driver) (146/200)
[INFO][2021-06-08 21:56:19,782][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 2.0 (TID 140) in 57 ms on localhost (executor driver) (147/200)
[INFO][2021-06-08 21:56:19,782][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 2.0 (TID 150) in 38 ms on localhost (executor driver) (148/200)
[INFO][2021-06-08 21:56:19,783][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 2.0 (TID 152) in 27 ms on localhost (executor driver) (149/200)
[INFO][2021-06-08 21:56:19,783][org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 2.0 (TID 164). 2260 bytes result sent to driver
[INFO][2021-06-08 21:56:19,783][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 2.0 (TID 137) in 64 ms on localhost (executor driver) (150/200)
[INFO][2021-06-08 21:56:19,784][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,784][org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 2.0 (TID 166). 2347 bytes result sent to driver
[INFO][2021-06-08 21:56:19,784][org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 2.0 (TID 165). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,784][org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 2.0 (TID 167). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,784][org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 2.0 (TID 168)
[INFO][2021-06-08 21:56:19,785][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,785][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 2.0 (TID 151) in 32 ms on localhost (executor driver) (151/200)
[INFO][2021-06-08 21:56:19,786][org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 2.0 (TID 169)
[INFO][2021-06-08 21:56:19,786][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,787][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 2.0 (TID 153) in 31 ms on localhost (executor driver) (152/200)
[INFO][2021-06-08 21:56:19,787][org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 2.0 (TID 170)
[INFO][2021-06-08 21:56:19,787][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 2.0 (TID 154) in 30 ms on localhost (executor driver) (153/200)
[INFO][2021-06-08 21:56:19,787][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,787][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,788][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,788][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,788][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 2.0 (TID 156) in 29 ms on localhost (executor driver) (154/200)
[INFO][2021-06-08 21:56:19,788][org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 2.0 (TID 171)
[INFO][2021-06-08 21:56:19,788][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,789][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,789][org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 2.0 (TID 172)
[INFO][2021-06-08 21:56:19,789][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 2.0 (TID 157) in 28 ms on localhost (executor driver) (155/200)
[INFO][2021-06-08 21:56:19,789][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,790][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,790][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,791][org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 2.0 (TID 173)
[INFO][2021-06-08 21:56:19,791][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,791][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,792][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,792][org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 2.0 (TID 168). 2280 bytes result sent to driver
[INFO][2021-06-08 21:56:19,792][org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 2.0 (TID 174)
[INFO][2021-06-08 21:56:19,793][org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 2.0 (TID 169). 2255 bytes result sent to driver
[INFO][2021-06-08 21:56:19,792][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,793][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,793][org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 2.0 (TID 175)
[INFO][2021-06-08 21:56:19,794][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,795][org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 2.0 (TID 176)
[INFO][2021-06-08 21:56:19,795][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,795][org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 2.0 (TID 170). 2283 bytes result sent to driver
[INFO][2021-06-08 21:56:19,795][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 2.0 (TID 158) in 33 ms on localhost (executor driver) (156/200)
[INFO][2021-06-08 21:56:19,795][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,796][org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 2.0 (TID 177)
[INFO][2021-06-08 21:56:19,796][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 2.0 (TID 162) in 29 ms on localhost (executor driver) (157/200)
[INFO][2021-06-08 21:56:19,796][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,797][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,797][org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 2.0 (TID 171). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,797][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,797][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,798][org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 2.0 (TID 172). 2284 bytes result sent to driver
[INFO][2021-06-08 21:56:19,798][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,798][org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 2.0 (TID 178)
[INFO][2021-06-08 21:56:19,799][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,799][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,798][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 2.0 (TID 160) in 33 ms on localhost (executor driver) (158/200)
[INFO][2021-06-08 21:56:19,799][org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 2.0 (TID 173). 2282 bytes result sent to driver
[INFO][2021-06-08 21:56:19,800][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 2.0 (TID 155) in 42 ms on localhost (executor driver) (159/200)
[INFO][2021-06-08 21:56:19,801][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 2.0 (TID 159) in 36 ms on localhost (executor driver) (160/200)
[INFO][2021-06-08 21:56:19,801][org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 2.0 (TID 175). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,801][org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 2.0 (TID 174). 2346 bytes result sent to driver
[INFO][2021-06-08 21:56:19,802][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,802][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,802][org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 2.0 (TID 179)
[INFO][2021-06-08 21:56:19,802][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 2.0 (TID 161) in 36 ms on localhost (executor driver) (161/200)
[INFO][2021-06-08 21:56:19,802][org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 2.0 (TID 176). 2347 bytes result sent to driver
[INFO][2021-06-08 21:56:19,802][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 2.0 (TID 163) in 33 ms on localhost (executor driver) (162/200)
[INFO][2021-06-08 21:56:19,803][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,804][org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 2.0 (TID 180)
[INFO][2021-06-08 21:56:19,804][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,805][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,804][org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 2.0 (TID 177). 2372 bytes result sent to driver
[INFO][2021-06-08 21:56:19,805][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,805][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 2.0 (TID 164) in 35 ms on localhost (executor driver) (163/200)
[INFO][2021-06-08 21:56:19,805][org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 2.0 (TID 181)
[INFO][2021-06-08 21:56:19,806][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,806][org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 2.0 (TID 182)
[INFO][2021-06-08 21:56:19,806][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 2.0 (TID 165) in 33 ms on localhost (executor driver) (164/200)
[INFO][2021-06-08 21:56:19,806][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,807][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 2.0 (TID 166) in 33 ms on localhost (executor driver) (165/200)
[INFO][2021-06-08 21:56:19,807][org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 2.0 (TID 178). 2367 bytes result sent to driver
[INFO][2021-06-08 21:56:19,807][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,807][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,808][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 2.0 (TID 167) in 33 ms on localhost (executor driver) (166/200)
[INFO][2021-06-08 21:56:19,808][org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 2.0 (TID 183)
[INFO][2021-06-08 21:56:19,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,808][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,809][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,809][org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 2.0 (TID 184)
[INFO][2021-06-08 21:56:19,810][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,810][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,811][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,811][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,811][org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 2.0 (TID 185)
[INFO][2021-06-08 21:56:19,811][org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 2.0 (TID 179). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,812][org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 2.0 (TID 186)
[INFO][2021-06-08 21:56:19,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,812][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,812][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,813][org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 2.0 (TID 182). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,814][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,813][org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 2.0 (TID 187)
[INFO][2021-06-08 21:56:19,813][org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 2.0 (TID 180). 2284 bytes result sent to driver
[INFO][2021-06-08 21:56:19,814][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,815][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,814][org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 2.0 (TID 188)
[INFO][2021-06-08 21:56:19,816][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,815][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,817][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,816][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,817][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,818][org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 2.0 (TID 189)
[INFO][2021-06-08 21:56:19,818][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,818][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,819][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,819][org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 2.0 (TID 190)
[INFO][2021-06-08 21:56:19,819][org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 2.0 (TID 183). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,819][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 2.0 (TID 171) in 32 ms on localhost (executor driver) (167/200)
[INFO][2021-06-08 21:56:19,819][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 2.0 (TID 172) in 31 ms on localhost (executor driver) (168/200)
[INFO][2021-06-08 21:56:19,820][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 2.0 (TID 173) in 30 ms on localhost (executor driver) (169/200)
[INFO][2021-06-08 21:56:19,822][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 2.0 (TID 170) in 36 ms on localhost (executor driver) (170/200)
[INFO][2021-06-08 21:56:19,822][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,822][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,820][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,822][org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 2.0 (TID 186). 2288 bytes result sent to driver
[INFO][2021-06-08 21:56:19,822][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 2.0 (TID 174) in 31 ms on localhost (executor driver) (171/200)
[INFO][2021-06-08 21:56:19,822][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
[INFO][2021-06-08 21:56:19,822][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 2.0 (TID 169) in 37 ms on localhost (executor driver) (172/200)
[INFO][2021-06-08 21:56:19,822][org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 2.0 (TID 181). 2252 bytes result sent to driver
[INFO][2021-06-08 21:56:19,822][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 2.0 (TID 175) in 30 ms on localhost (executor driver) (173/200)
[INFO][2021-06-08 21:56:19,824][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 2.0 (TID 168) in 41 ms on localhost (executor driver) (174/200)
[INFO][2021-06-08 21:56:19,824][org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 2.0 (TID 187). 2256 bytes result sent to driver
[INFO][2021-06-08 21:56:19,822][org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 2.0 (TID 184). 2361 bytes result sent to driver
[INFO][2021-06-08 21:56:19,825][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,825][org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 2.0 (TID 185). 2370 bytes result sent to driver
[INFO][2021-06-08 21:56:19,825][org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 2.0 (TID 191)
[INFO][2021-06-08 21:56:19,825][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,825][org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 2.0 (TID 188). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,827][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,827][org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 2.0 (TID 190). 2264 bytes result sent to driver
[INFO][2021-06-08 21:56:19,825][org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 2.0 (TID 192)
[INFO][2021-06-08 21:56:19,828][org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 2.0 (TID 193)
[INFO][2021-06-08 21:56:19,828][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,828][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,828][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 2.0 (TID 176) in 35 ms on localhost (executor driver) (175/200)
[INFO][2021-06-08 21:56:19,828][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 2.0 (TID 177) in 34 ms on localhost (executor driver) (176/200)
[INFO][2021-06-08 21:56:19,829][org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 2.0 (TID 189). 2363 bytes result sent to driver
[INFO][2021-06-08 21:56:19,829][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,830][org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 2.0 (TID 194)
[INFO][2021-06-08 21:56:19,830][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,830][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,830][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,830][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,830][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,831][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 2.0 (TID 178) in 34 ms on localhost (executor driver) (177/200)
[INFO][2021-06-08 21:56:19,831][org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 2.0 (TID 195)
[INFO][2021-06-08 21:56:19,832][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,833][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,832][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,834][org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 2.0 (TID 196)
[INFO][2021-06-08 21:56:19,834][org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 2.0 (TID 191). 2362 bytes result sent to driver
[INFO][2021-06-08 21:56:19,834][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,835][org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 2.0 (TID 197)
[INFO][2021-06-08 21:56:19,835][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,835][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
[INFO][2021-06-08 21:56:19,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,837][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,837][org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 2.0 (TID 194). 2287 bytes result sent to driver
[INFO][2021-06-08 21:56:19,837][org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 2.0 (TID 192). 2366 bytes result sent to driver
[INFO][2021-06-08 21:56:19,835][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 2.0 (TID 179) in 34 ms on localhost (executor driver) (178/200)
[INFO][2021-06-08 21:56:19,838][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 2.0 (TID 182) in 33 ms on localhost (executor driver) (179/200)
[INFO][2021-06-08 21:56:19,838][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 2.0 (TID 180) in 35 ms on localhost (executor driver) (180/200)
[INFO][2021-06-08 21:56:19,839][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,840][org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 2.0 (TID 198)
[INFO][2021-06-08 21:56:19,840][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,840][org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 2.0 (TID 193). 2372 bytes result sent to driver
[INFO][2021-06-08 21:56:19,841][org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 2.0 (TID 199)
[INFO][2021-06-08 21:56:19,841][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,842][org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 2.0 (TID 200)
[INFO][2021-06-08 21:56:19,842][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5885 bytes)
[INFO][2021-06-08 21:56:19,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,843][org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 2.0 (TID 195). 2284 bytes result sent to driver
[INFO][2021-06-08 21:56:19,843][org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 2.0 (TID 201)
[INFO][2021-06-08 21:56:19,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,843][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 2.0 (TID 183) in 36 ms on localhost (executor driver) (181/200)
[INFO][2021-06-08 21:56:19,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,843][org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 2.0 (TID 197). 2259 bytes result sent to driver
[INFO][2021-06-08 21:56:19,843][org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 2.0 (TID 196). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:19,843][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,844][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 2.0 (TID 187) in 33 ms on localhost (executor driver) (182/200)
[INFO][2021-06-08 21:56:19,844][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 2.0 (TID 186) in 34 ms on localhost (executor driver) (183/200)
[INFO][2021-06-08 21:56:19,845][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 2.0 (TID 185) in 35 ms on localhost (executor driver) (184/200)
[INFO][2021-06-08 21:56:19,845][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 2.0 (TID 181) in 41 ms on localhost (executor driver) (185/200)
[INFO][2021-06-08 21:56:19,845][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,845][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,846][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 2.0 (TID 184) in 37 ms on localhost (executor driver) (186/200)
[INFO][2021-06-08 21:56:19,846][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 2.0 (TID 190) in 28 ms on localhost (executor driver) (187/200)
[INFO][2021-06-08 21:56:19,846][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
[INFO][2021-06-08 21:56:19,846][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 2.0 (TID 188) in 33 ms on localhost (executor driver) (188/200)
[INFO][2021-06-08 21:56:19,846][org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
[INFO][2021-06-08 21:56:19,846][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 2.0 (TID 189) in 32 ms on localhost (executor driver) (189/200)
[INFO][2021-06-08 21:56:19,847][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 2.0 (TID 191) in 23 ms on localhost (executor driver) (190/200)
[INFO][2021-06-08 21:56:19,847][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 2.0 (TID 194) in 18 ms on localhost (executor driver) (191/200)
[INFO][2021-06-08 21:56:19,848][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 2.0 (TID 192) in 23 ms on localhost (executor driver) (192/200)
[INFO][2021-06-08 21:56:19,848][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 2.0 (TID 193) in 23 ms on localhost (executor driver) (193/200)
[INFO][2021-06-08 21:56:19,849][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 2.0 (TID 195) in 19 ms on localhost (executor driver) (194/200)
[INFO][2021-06-08 21:56:19,849][org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 2.0 (TID 198). 2357 bytes result sent to driver
[INFO][2021-06-08 21:56:19,849][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 2.0 (TID 197) in 15 ms on localhost (executor driver) (195/200)
[INFO][2021-06-08 21:56:19,849][org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 2.0 (TID 199). 2360 bytes result sent to driver
[INFO][2021-06-08 21:56:19,850][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 2.0 (TID 196) in 18 ms on localhost (executor driver) (196/200)
[INFO][2021-06-08 21:56:19,850][org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 2.0 (TID 200). 2361 bytes result sent to driver
[INFO][2021-06-08 21:56:19,850][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 2.0 (TID 198) in 11 ms on localhost (executor driver) (197/200)
[INFO][2021-06-08 21:56:19,850][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 2.0 (TID 199) in 10 ms on localhost (executor driver) (198/200)
[INFO][2021-06-08 21:56:19,851][org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 2.0 (TID 201). 2359 bytes result sent to driver
[INFO][2021-06-08 21:56:19,851][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 2.0 (TID 200) in 10 ms on localhost (executor driver) (199/200)
[INFO][2021-06-08 21:56:19,851][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 2.0 (TID 201) in 9 ms on localhost (executor driver) (200/200)
[INFO][2021-06-08 21:56:19,852][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:19,852][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (collectAsList at TradingDays.java:42) finished in 0.542 s
[INFO][2021-06-08 21:56:19,852][org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collectAsList at TradingDays.java:42, took 1.443379 s
[INFO][2021-06-08 21:56:19,888][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.0318 ms
[INFO][2021-06-08 21:56:19,906][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,910][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,911][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.52.10:65292 (size: 17.2 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,911][org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at TradingDays.java:58
[INFO][2021-06-08 21:56:19,912][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 17.2 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,915][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:19,915][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.52.10:65292 (size: 12.0 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,916][org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at TradingDays.java:59
[INFO][2021-06-08 21:56:19,916][com.apex.bigdata.template.TradingDays:60] - load xtjyr competed! size:4383
[INFO][2021-06-08 21:56:19,919][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: set hive.exec.dynamic.partition.mode=nonstrict
[INFO][2021-06-08 21:56:19,949][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 1256.0 B, free 3.8 GB)
[INFO][2021-06-08 21:56:19,954][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 167.0 B, free 3.8 GB)
[INFO][2021-06-08 21:56:19,955][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.52.10:65292 (size: 167.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,955][org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DemoMoveFinfo.java:351
[INFO][2021-06-08 21:56:19,965][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 536.0 B, free 3.8 GB)
[INFO][2021-06-08 21:56:19,969][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.0 B, free 3.8 GB)
[INFO][2021-06-08 21:56:19,970][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.52.10:65292 (size: 124.0 B, free: 3.8 GB)
[INFO][2021-06-08 21:56:19,971][org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DemoMoveFinfo.java:320
[INFO][2021-06-08 21:56:20,146][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:56:20,153][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:129] -  
[INFO][2021-06-08 21:56:20,153][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:56:20,295][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.5103 ms
[INFO][2021-06-08 21:56:20,306][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:130
[INFO][2021-06-08 21:56:20,307][org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at DemoMoveFinfo.java:130) with 1 output partitions
[INFO][2021-06-08 21:56:20,308][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:56:20,308][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:56:20,308][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:56:20,309][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130), which has no missing parents
[INFO][2021-06-08 21:56:20,330][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 15.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,333][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,333][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.52.10:65292 (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,334][org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:20,334][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at DemoMoveFinfo.java:130)
[INFO][2021-06-08 21:56:20,334][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
[INFO][2021-06-08 21:56:20,337][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:56:20,339][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 202)
[INFO][2021-06-08 21:56:20,403][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:56:20,404][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 202). 2281 bytes result sent to driver
[INFO][2021-06-08 21:56:20,405][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 202) in 71 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:56:20,405][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:20,405][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at DemoMoveFinfo.java:130) finished in 0.071 s
[INFO][2021-06-08 21:56:20,405][org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at DemoMoveFinfo.java:130, took 0.098193 s
[INFO][2021-06-08 21:56:20,441][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.178 ms
[INFO][2021-06-08 21:56:20,452][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select ID,GPDM,GPJC,SGDM,FXZS,WSFX,DGSGSZ,SGSX,SGZJSX,FXJ,ZXJ,SRSPJ,SGRQ,ZQGBR,SSRQ,FXSYL,HYSYL,ZQL,MZYQY,DJZJ,XJLJBJBS,PSDXBJJS,DXSY,LXYZBSL,ZZF,tranMarketCode(JYS) as JYS,SSBK from sparktxggl
[INFO][2021-06-08 21:56:20,492][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:56:20,495][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:133] -  
[INFO][2021-06-08 21:56:20,495][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:56:20,564][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.8324 ms
[INFO][2021-06-08 21:56:20,577][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:134
[INFO][2021-06-08 21:56:20,578][org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at DemoMoveFinfo.java:134) with 1 output partitions
[INFO][2021-06-08 21:56:20,578][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:56:20,578][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:56:20,578][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:56:20,579][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134), which has no missing parents
[INFO][2021-06-08 21:56:20,580][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 19.9 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,583][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,583][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.52.10:65292 (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,584][org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:20,584][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at DemoMoveFinfo.java:134)
[INFO][2021-06-08 21:56:20,584][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
[INFO][2021-06-08 21:56:20,585][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:56:20,585][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 203)
[INFO][2021-06-08 21:56:20,632][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:56:20,634][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 203). 2366 bytes result sent to driver
[INFO][2021-06-08 21:56:20,635][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 203) in 50 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:56:20,635][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:20,635][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at DemoMoveFinfo.java:134) finished in 0.051 s
[INFO][2021-06-08 21:56:20,636][org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at DemoMoveFinfo.java:134, took 0.058018 s
[INFO][2021-06-08 21:56:20,639][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: desc adp_cfg.info_txggl
[INFO][2021-06-08 21:56:20,676][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: int
[INFO][2021-06-08 21:56:20,676][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,676][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,676][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,677][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:56:20,677][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(16,2)
[INFO][2021-06-08 21:56:20,677][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:56:20,677][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(12,2)
[INFO][2021-06-08 21:56:20,678][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,4)
[INFO][2021-06-08 21:56:20,678][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,678][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,678][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,678][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,679][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,679][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,679][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,680][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,680][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,4)
[INFO][2021-06-08 21:56:20,681][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,681][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(7,2)
[INFO][2021-06-08 21:56:20,681][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,682][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(6,0)
[INFO][2021-06-08 21:56:20,682][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,683][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,683][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(9,2)
[INFO][2021-06-08 21:56:20,684][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,684][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: string
[INFO][2021-06-08 21:56:20,684][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,685][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,685][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,685][org.apache.spark.sql.catalyst.parser.CatalystSqlParser:54] - Parsing command: decimal(8,0)
[INFO][2021-06-08 21:56:20,701][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.0715 ms
[INFO][2021-06-08 21:56:20,703][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
[INFO][2021-06-08 21:56:20,711][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select cast(id as int) as id,cast(gpdm as string) as gpdm,cast(gpjc as string) as gpjc,cast(sgdm as string) as sgdm,cast(fxzs as decimal(16,2)) as fxzs,cast(wsfx as decimal(16,2)) as wsfx,cast(dgsgsz as decimal(12,2)) as dgsgsz,cast(sgsx as decimal(12,2)) as sgsx,cast(sgzjsx as decimal(9,4)) as sgzjsx,cast(fxj as decimal(9,2)) as fxj,cast(zxj as decimal(9,2)) as zxj,cast(srspj as decimal(9,2)) as srspj,cast(sgrq as decimal(8,0)) as sgrq,cast(zqgbr as decimal(8,0)) as zqgbr,cast(ssrq as decimal(8,0)) as ssrq,cast(fxsyl as decimal(9,2)) as fxsyl,cast(hysyl as decimal(9,2)) as hysyl,cast(zql as decimal(7,4)) as zql,cast(mzyqy as decimal(9,2)) as mzyqy,cast(djzj as decimal(7,2)) as djzj,cast(xjljbjbs as decimal(9,2)) as xjljbjbs,cast(psdxbjjs as decimal(6,0)) as psdxbjjs,cast(dxsy as decimal(9,2)) as dxsy,cast(lxyzbsl as string) as lxyzbsl,cast(zzf as decimal(9,2)) as zzf,cast(jys as string) as jys,cast(ssbk as string) as ssbk,cast(null as decimal(8,0)) as wssgjkr,cast(null as decimal(8,0)) as wssgtkr,cast(null as decimal(8,0)) as zjxcgpr,cast(null as decimal(8,0)) as fxjgggr from sparktxggl
[INFO][2021-06-08 21:56:20,733][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: sparktxggl
[INFO][2021-06-08 21:56:20,737][com.apex.bigdata.publicProcess.test.DemoMoveFinfo:137] -  
[INFO][2021-06-08 21:56:20,737][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl limit 10
[INFO][2021-06-08 21:56:20,803][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.6472 ms
[INFO][2021-06-08 21:56:20,808][org.apache.spark.SparkContext:54] - Starting job: show at DemoMoveFinfo.java:138
[INFO][2021-06-08 21:56:20,808][org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at DemoMoveFinfo.java:138) with 1 output partitions
[INFO][2021-06-08 21:56:20,809][org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (show at DemoMoveFinfo.java:138)
[INFO][2021-06-08 21:56:20,809][org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
[INFO][2021-06-08 21:56:20,809][org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
[INFO][2021-06-08 21:56:20,809][org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138), which has no missing parents
[INFO][2021-06-08 21:56:20,810][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 20.6 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,813][org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.5 KB, free 3.8 GB)
[INFO][2021-06-08 21:56:20,814][org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.52.10:65292 (size: 8.5 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,814][org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO][2021-06-08 21:56:20,814][org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at show at DemoMoveFinfo.java:138)
[INFO][2021-06-08 21:56:20,814][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
[INFO][2021-06-08 21:56:20,815][org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
[INFO][2021-06-08 21:56:20,816][org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 204)
[INFO][2021-06-08 21:56:20,868][org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD:54] - closed connection
[INFO][2021-06-08 21:56:20,869][org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 204). 2315 bytes result sent to driver
[INFO][2021-06-08 21:56:20,870][org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 204) in 56 ms on localhost (executor driver) (1/1)
[INFO][2021-06-08 21:56:20,870][org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO][2021-06-08 21:56:20,870][org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (show at DemoMoveFinfo.java:138) finished in 0.056 s
[INFO][2021-06-08 21:56:20,870][org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at DemoMoveFinfo.java:138, took 0.062953 s
[INFO][2021-06-08 21:56:20,883][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.52.10:65292 in memory (size: 6.4 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,898][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4926
[INFO][2021-06-08 21:56:20,898][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4976
[INFO][2021-06-08 21:56:20,899][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.52.10:65292 in memory (size: 8.5 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,900][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4977
[INFO][2021-06-08 21:56:20,900][org.apache.spark.ContextCleaner:54] - Cleaned accumulator 4927
[INFO][2021-06-08 21:56:20,901][org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.52.10:65292 in memory (size: 8.3 KB, free: 3.8 GB)
[INFO][2021-06-08 21:56:20,906][org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.395 ms
[INFO][2021-06-08 21:56:20,909][org.apache.spark.sql.execution.SparkSqlParser:54] - Parsing command: select * from sparktxggl
