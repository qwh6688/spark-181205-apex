#\u914D\u7F6E\u89C4\u5219\u8BF4\u660E:
# \u6BCF\u9879\u914D\u7F6E\u89C4\u5219\u4E0D\u9650\u4E8E\u5C55\u793A\u90E8\u5206 \u9700\u8981\u7B26\u5408\u5F00\u5934\u4FDD\u6301\u4E00\u81F4 \u6BD4\u5982\u8FDE\u63A5bd\u7684mysql \u914D\u7F6E\u5F00\u5934\u4E3A mysql.bd.xxx
# \u76EE\u7684\uFF1A\u5DE5\u7A0B\u90E8\u7F72\u65F6\u76F4\u63A5\u586B\u5199\u6B64\u914D\u7F6E\u6587\u4EF6\u91CC\u9762\u4FE1\u606F\u5373\u53EF\uFF0C\u5982\u679C\u662F\u67D0\u53EA\u7A0B\u5E8F\u7279\u6B8A\u914D\u7F6E\u6839\u636E\u73B0\u573A\u73AF\u5883\u8FDB\u884C\u8C03\u8BD5
# \u6B64\u5904\u586B\u5199\u7684\u662F\u516C\u5171\u8BBF\u95EE\u8D44\u6E90\u7684\u914D\u7F6E\u4FE1\u606F \u5BC6\u7801\u4E00\u5F8B\u8981\u8FDB\u884C\u52A0\u5BC6\u5904\u7406

[mysql_bd]
mysql.bd.driver=com.mysql.jdbc.Driver
mysql.bd.url=jdbc:mysql://192.168.5.14:3306/pub_sys?characterEncoding=UTF-8&useSSL=false
mysql.bd.user=root
mysql.bd.password=ENC(1083061FF4033F3397FED9C2AF4AED9F)

[kerberos]
kerberos.principal=apex@APEX.COM
kerberos.keytab=/home/apex/apex.keytab
kerberos.java.security.krb5.conf=/etc/krb5.conf
kerberos.spark.submit=true
kerberos.impala=true
kerberos.hive=true

[spark]
spark.sql.warehouse.dir=hdfs://cmserver.apex.com:8020/user/hive/warehouse
spark.executor.extraJavaOptions=-XX:MaxPermSize=512m -XX:+CMSClassUnloadingEnabled -XX:MaxDirectMemorySize=1536m -Xmn100m -XX:MaxTenuringThreshold=1 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=10 -XX:+UseCompressedOops -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC -XX:+PrintGCApplicationConcurrentTime -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError
spark.driver.extraJavaOptions=-XX:PermSize=512M -XX:MaxPermSize=1024M
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.Master=local[*]
Master=local[*]
spark.default.parallelism=200
spark.memory.useLegacyMode=true
spark.debug.maxToStringFields=200
spark.sql.autoBroadcastJoinThreshold=-1
spark.sql.parquet.writeLegacyFormat=true
spark.files.fetchTimeout=9000
spark.sql.shuffle.partitions=200
spark.executor.heartbeatInterval=60s
spark.sql.parquet.cacheMatadata=true
spark.sql.codegen,aggregate.map.twolevel.enable=false
spark.sql.hive.metastorePartitionPruning=false
spark.sql.crossJoin.enabled=true
[redis]
redis.host=192.168.4.221
redis.port=6379
redis.user=
redis.password=

[kafka]
kafka.auth=kerberos
kafka.servers=master:9092
kafka.auto.offset.reset=earliest

[phoenix]
phoenix.auth=none
phoenix.driver=org.apache.phoenix.jdbc.PhoenixDriver
#phoenix.hbase.principal=hbase/_HOST@APEX.COM
phoenix.jdbc.url=jdbc:phoenix:node02:2181

#hbase \u914D\u7F6E
[hbase]

#hdfs \u914D\u7F6E
[hdfs]

#es\u914D\u7F6E
[elasticsearch]
es.nodes=192.168.0.87
es.nodes.port=9200
es.net.http.auth.user=elastic
es.net.http.auth.pass=ENC(1083061FF4033F33690DC74E6F8E4821)

#\u884C\u60C5\u7A0B\u5E8F
[hq]
hq.fix.url=120.26.161.92@7802/TCP
hq.redis.key=apex_hq

#\u96C6\u4E2D\u4EA4\u6613oracle\u5730\u5740
[ls_jzjy]
ls.jzjy.oracle.mnch.url=jdbc:oracle:thin:@114.55.175.42:1521:mnch
ls.jzjy.oracle.mnch.user=system
ls.jzjy.oracle.mnch.password=ENC(1083061FF4033F3397FED9C2AF4AED9F)

#\u4E24\u878Doracle\u5730\u5740
[ls_xy]
ls.xy.oracle.mnch.url=jdbc:oracle:thin:@114.55.175.42:1521:mnch
ls.xy.oracle.mnch.user=system
ls.xy.oracle.mnch.password=ENC(1083061FF4033F3397FED9C2AF4AED9F)